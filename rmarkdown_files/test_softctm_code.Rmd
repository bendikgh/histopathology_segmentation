---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# %load_ext autoreload
# %autoreload 2

import os

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
from typing import Any, Dict, List

import cv2
import numpy as np
import onnxruntime as ort
import torch

from torch.utils.data import DataLoader
from torch import nn
from tqdm import tqdm
from monai.losses import DiceLoss, DiceCELoss
from src.loss import DiceLossWrapper
from src.utils.constants import DATASET_PARTITION_OFFSETS
from src.trainable import SegformerSharingTrainable
from src.utils.constants import IDUN_OCELOT_DATA_PATH

def softmax(x, dim=None):
    """
    Compute the softmax function for the input array x
    along the specified dimension dim.
    """
    e_x = np.exp(x - np.max(x, axis=dim, keepdims=True))
    # Subtracting max(x) for numerical stability
    return e_x / np.sum(e_x, axis=dim, keepdims=True)

class Model:
    """
    Parameters
    ----------
    metadata: Dict
        Dataset metadata in case you wish to compute statistics

    """

    def __init__(self, metadata: Dict[str, Any]):
        self.metadata = metadata
        self.tissue_onnx = ort.InferenceSession(
            "onnx/tissue_sgm.onnx",
            providers=["CUDAExecutionProvider", "CPUExecutionProvider"],
        )

    def __call__(self, tissue_patch: np.ndarray):
        """This function detects the cells in the cell patch. Additionally
        the broader tissue context is provided.

        Parameters
        ----------
        cell_patch: np.ndarray[uint8]
            Cell patch with shape [1024, 1024, 3] with values from 0 - 255
        tissue_patch: np.ndarray[uint8]
            Tissue patch with shape [1024, 1024, 3] with values from 0 - 255
        pair_id: str
            Identification number of the patch pair

        Returns
        -------
            List[tuple]: for each predicted cell we provide the tuple (x, y, cls, score)
        """

        # meta_pair = self.metadata[pair_id]

        tissue_patch = np.transpose(tissue_patch, (1, 2, 0))

        # tissue segmentation + test time augmentation
        tissue_patch = (tissue_patch / 255.0).astype("float32")
        tissue_patch_tta = self.geometric_test_time_augmentation(tissue_patch)
        tissue_patch_tta = np.moveaxis(tissue_patch_tta, source=-1, destination=1)
        tissue_pred_tta = []

        for tissue_patch in tissue_patch_tta:
            tissue_model_input = {
                self.tissue_onnx.get_inputs()[0].name: np.expand_dims(
                    tissue_patch, axis=0
                )
            }
            tissue_pred_single = self.tissue_onnx.run(None, tissue_model_input)[0]
            tissue_pred_single = softmax(tissue_pred_single, dim=1)
            tissue_pred_tta.append(np.squeeze(tissue_pred_single))

        tissue_pred = np.expand_dims(self.reverse_tta(tissue_pred_tta), axis=0).astype(
            "float32"
        )
        return tissue_pred

    def geometric_test_time_augmentation(self, img: np.ndarray) -> List[np.ndarray]:
        """Return all 8 possible geometric transformations of an image"""

        transformed = []
        for flip in [None, 1]:
            for rotate in [
                None,
                cv2.ROTATE_90_CLOCKWISE,
                cv2.ROTATE_180,
                cv2.ROTATE_90_COUNTERCLOCKWISE,
            ]:
                t_img = cv2.flip(img, flip) if flip is not None else img
                t_img = cv2.rotate(t_img, rotate) if rotate is not None else t_img
                transformed.append(t_img)
        return transformed

    def reverse_tta(self, pred: np.ndarray) -> np.ndarray:
        """Combine test-time augmentation predictions into a single prediction"""
        i = 0
        pred = torch.Tensor(np.array(pred))
        for flip in [None, 2]:
            for rotate in [None, 1, 2, 3]:
                if rotate:
                    pred[i] = torch.rot90(pred[i], k=rotate, dims=(1, 2))
                if flip is not None:
                    pred[i] = torch.flip(pred[i], dims=[flip])
                i += 1
        mean_pred = torch.mean(pred, dim=0)
        return mean_pred.numpy()

    def crop_tissue_sample_for_cell_sgm(
        self,
        tissue_pred: np.ndarray,
        meta_pair: Dict[str, Any],
    ) -> np.ndarray:
        """Crop tissue sample to cell patch size and resolution"""
        shape = tissue_pred.shape[2:]
        tissue_pred = np.moveaxis(np.squeeze(tissue_pred), source=0, destination=-1)
        cell_x_start = meta_pair["cell"]["x_start"]
        cell_y_start = meta_pair["cell"]["y_start"]
        tissue_x_start = meta_pair["tissue"]["x_start"]
        tissue_y_start = meta_pair["tissue"]["y_start"]
        tissue_x_end = meta_pair["tissue"]["x_end"]
        tissue_y_end = meta_pair["tissue"]["y_end"]

        x_offset = int(
            shape[0] * (cell_x_start - tissue_x_start) / (tissue_x_end - tissue_x_start)
        )
        y_offset = int(
            shape[0] * (cell_y_start - tissue_y_start) / (tissue_y_end - tissue_y_start)
        )

        tissue_pred_excerpt = tissue_pred[
            y_offset : y_offset + shape[0] // 4,
            x_offset : x_offset + shape[1] // 4,
            :,
        ]
        tissue_pred_excerpt = cv2.resize(
            tissue_pred_excerpt,
            dsize=shape,
            interpolation=cv2.INTER_CUBIC,
        )
        tissue_pred_excerpt = np.expand_dims(
            np.moveaxis(tissue_pred_excerpt, source=-1, destination=0), axis=0
        )
        return tissue_pred_excerpt
```

```{python}
print(d)
```

```{python}
import json

with open('ocelot_data/metadata.json') as json_file:
    d = json.load(json_file)

model = Model(d)
```

```{python}
# class CustomDataLoader:

#     def __init__(self, tissue_path, tissue_label_path):
#         self.tissue_patches = sorted(
#             [os.path.join(tissue_path, f) for f in os.listdir(tissue_path)],
#             key=lambda x: int(os.path.basename(x).split(".")[0]),
#         )

#         self.label_patches = sorted(
#             [os.path.join(tissue_label_path, f) for f in os.listdir(tissue_label_path)],
#             key=lambda x: int(os.path.basename(x).split(".")[0]),
#         )

#         assert len(self.label_patches) == len(self.tissue_patches)

#         self.cur_idx = 0

#     def __iter__(self):
#         return self

#     def __len__(self):
#         return len(self.tissue_patches)

#     def __next__(self):
#         if not self.cur_idx < len(self.tissue_patches):
#             raise StopIteration

#         label_patch = cv2.imread(self.label_patches[self.cur_idx])
#         tissue_patch = cv2.imread(self.tissue_patches[self.cur_idx])

#         label_patch: np.ndarray = cv2.cvtColor(label_patch, cv2.COLOR_BGR2RGB)
#         tissue_patch: np.ndarray = cv2.cvtColor(tissue_patch, cv2.COLOR_BGR2RGB)

#         self.cur_idx += 1
#         return tissue_patch, label_patch, self.cur_idx - 1
```

```{python}
normalization = "off"
batch_size = 1
pretrained = "ade"
device = "cpu"
backbone_model = "b0"
pretrained_dataset = "ade"
resize = 1024
data_dir = IDUN_OCELOT_DATA_PATH

# partition = "val"
# tissue_file_path = os.path.join(data_dir, f"images/{partition}/tissue")
# label_file_path = os.path.join(data_dir, f"annotations/{partition}/tissue")

# dataloader = CustomDataLoader(tissue_file_path, label_file_path)
```

```{python}
from src.trainable import SegformerTissueTrainable

trainable = SegformerTissueTrainable(
    normalization=normalization,
    batch_size=batch_size,
    pretrained=pretrained,
    device=device,
    backbone_model=backbone_model,
    pretrained_dataset=pretrained_dataset,
    resize=resize,
    data_dir=data_dir,
)

dataloader = trainable._create_dataloader(data_dir=IDUN_OCELOT_DATA_PATH, partition="val")
```

```{python}
def run_validation(
    model: nn.Module,
    val_dataloader: DataLoader,
    loss_function,
    device,
    break_after_one_iteration: bool = False,
) -> float:
    val_loss = 0.0
    with torch.no_grad():
        for tissue, masks in tqdm(val_dataloader, total=len(val_dataloader)):

            tissue = tissue.squeeze().detach().cpu().numpy()

            masks[masks == 2] = 0

            outputs = model(tissue)
            outputs = torch.from_numpy(outputs)

            loss = loss_function(outputs, masks)

            val_loss += loss.item()
            if break_after_one_iteration:
                print("Breaking after one iteration")
                break

    if not break_after_one_iteration:
        val_loss /= len(val_dataloader)
    return val_loss


loss_function = DiceLossWrapper(softmax=True, to_onehot_y=True)

score = run_validation(model, dataloader, loss_function, device)
print(score)
```


