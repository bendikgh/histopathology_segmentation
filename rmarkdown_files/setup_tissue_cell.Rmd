---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2

import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
from PIL import Image
from src.utils import (
    read_data, 
    get_tissue_crops_scaled_tensor,
    get_partition_from_file_name
)

import torch
import albumentations as A
import matplotlib.pyplot as plt

from glob import glob
from monai.data import DataLoader
from monai.losses import DiceLoss
from torch.optim import Adam

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import TissueDataset
from src.train_utils import train

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")

```

```{python}
on_idun = os.getcwd().startswith("/cluster")

if on_idun:
  data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
else: 
  data_path = "ocelot_data/"
train_data, val_data, test_data = read_data(data_path)
total_data = {}
total_data.update(train_data)
total_data.update(val_data)
total_data.update(test_data)
```

```{python}
# train_data = {k: train_data[k] for k in sorted(train_data, key=int)}
# val_data = {k: val_data[k] for k in sorted(val_data, key=int)}
# test_data = {k: test_data[k] for k in sorted(test_data, key=int)}

total_data = {k: total_data[k] for k in sorted(total_data, key=int)}
```

## Load tissue model

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model_tissue = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_tissue.to(device)
```

```{python}
model_tissue.load_state_dict(torch.load("outputs/models/2023-12-07_22-49-54_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-290.pth"))
```

```{python}
## Changing the 
model_tissue.eval()
for key in total_data.keys():
    tissue_image = total_data[key]["tissue_image"]
    tissue_image = tissue_image.to(device).to(torch.float).unsqueeze(0)

    prediction = model_tissue(tissue_image)
    prediction = prediction.detach().cpu().squeeze(0)

    total_data[key]["tissue_annotated"] = prediction
```

```{python}
train_folder = os.path.join(data_path, "annotations/train/pred_tissue")
val_folder = os.path.join(data_path, "annotations/val/pred_tissue")
test_folder = os.path.join(data_path, "annotations/test/pred_tissue")
os.makedirs(train_folder, exist_ok=True)
os.makedirs(val_folder, exist_ok=True)
os.makedirs(test_folder, exist_ok=True)
```

```{python}
for (key, value) in total_data.items(): 
    temp_dict = {key: value}
    cropped_tensor = get_tissue_crops_scaled_tensor(data=temp_dict)
    
    cropped_tensor = cropped_tensor[:, 3:]

    partition = get_partition_from_file_name(key)
    image_folder = os.path.join(data_path, "annotations", partition, "pred_tissue")

    img = Image.fromarray(cropped_tensor.squeeze().numpy().astype("uint8").transpose(1, 2, 0))
    img.save(f"{image_folder}/{key}.png")
```
