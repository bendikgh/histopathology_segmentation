---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import albumentations as A

from torch.nn.functional import softmax, one_hot

from ocelot23algo.user.inference import EvaluationModel
from src.trainable import SegformerTissueTrainable, SegformerCellOnlyTrainable, DeeplabCellOnlyTrainable
from src.utils.utils import get_metadata_with_offset, get_point_predictions, crop_and_resize_tissue_faster
from src.utils.constants import IDUN_OCELOT_DATA_PATH as data_dir
from src.utils.metrics import predict_and_evaluate

```

```{python}
normalization = "macenko"
batch_size = 2
pretrained = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tissue_backbone_model = "b1"
cell_backbone_model = "resnet50"
pretrained_dataset = "ade"
resize = 1024

tissue_trainable = SegformerTissueTrainable(
    normalization=normalization,
    batch_size=batch_size,
    pretrained=pretrained,
    device=device,
    backbone_model=tissue_backbone_model,
    pretrained_dataset=pretrained_dataset,
    resize=resize,
)

cell_trainable = DeeplabCellOnlyTrainable(
    normalization=normalization,
    batch_size=batch_size,
    pretrained=pretrained,
    device=device,
)

# cell_trainable = SegformerCellOnlyTrainable(
#   normalization=normalization,
#   batch_size=batch_size,
#   pretrained=pretrained,
#   device=device,
#   backbone_model=cell_backbone_model,
#   pretrained_dataset=pretrained_dataset,
#   resize=resize
# )
```

```{python}
tissue_model_path = (
    "outputs/models/20240414_192040/Segformer_Tissue-Branch_backbone-b1_best.pth"
)
# cell_model_path = "outputs/models/20240408_001200/deeplabv3plus-cell-only_pretrained-1_lr-1e-04_backbone-b3_normalization-macenko_pretrained_dataset-ade_resize-1024_id-1_best.pth"
cell_model_path = "outputs/models/20240403_143651/deeplabv3plus-cell-only_pretrained-1_lr-1e-04_dropout-0.3_backbone-resnet50_normalization-macenko_id-1_best.pth"

tissue_model = tissue_trainable.create_model(
    backbone_name=tissue_backbone_model,
    pretrained=pretrained,
    device=device,
    model_path=tissue_model_path,
)

cell_model = cell_trainable.create_model(
    backbone_name=cell_backbone_model,
    pretrained=pretrained,
    device=device,
    model_path=cell_model_path,
)
```

```{python}
class NaiveEvaluationModel(EvaluationModel): 
  def __init__(self, metadata, cell_model, tissue_model, device): 
    self.metadata = metadata
    self.cell_model = cell_model
    self.tissue_model = tissue_model
    self.device = device

    self.cell_model.eval()
    self.cell_model.to(self.device)

    self.tissue_model.eval()
    self.tissue_model.to(self.device)

    self.resize_function = A.Resize(height=512, width=512)
    self.use_tissue = True


  def __call__(self, cell_patch, tissue_patch, pair_id, transform=None): 

    # Calculate the points from the cell model
    if transform is not None: 
      transformed = transform(image=cell_patch, mask=tissue_patch)
      cell_patch = transformed["image"]
    
    cell_patch = self._scale_cell_patch(cell_patch)
    cell_patch = torch.from_numpy(cell_patch).permute(2, 0, 1)
    cell_patch = cell_patch.unsqueeze(0).to(self.device)

    output = self.cell_model(cell_patch).squeeze(0).detach().cpu()
    softmaxed = softmax(output, dim=0)
    result = get_point_predictions(softmaxed)

    if not self.use_tissue: 
      return result

    # calculating tissue predictions
    meta_pair = self.metadata[pair_id]
    x_offset = meta_pair["patch_x_offset"]
    y_offset = meta_pair["patch_y_offset"]

    tissue_patch = self.resize_function(image=tissue_patch)["image"]
    tissue_patch = self._scale_tissue_patch(tissue_patch)
    tissue_patch = torch.from_numpy(tissue_patch).permute(2, 0, 1)
    tissue_patch = tissue_patch.unsqueeze(0).to(self.device)

    tissue_prediction = self.tissue_model(tissue_patch).squeeze(0)
    argmaxed = tissue_prediction.argmax(dim=0)
    cropped_tissue = crop_and_resize_tissue_faster(
      image=argmaxed, 
      x_offset=x_offset,
      y_offset=y_offset,
    )

    for idx in range(len(result)): 
      x, y, class_id, prob = result[idx]
      cropped_tissue_class = cropped_tissue[y, x]

      if cropped_tissue_class == 1: 
        result[idx] = (x, y, 2, prob) 
      elif cropped_tissue_class == 0: 
        result[idx] = (x, y, 1, prob) 


    return result
```

```{python}
val_metadata = get_metadata_with_offset(data_dir=data_dir, partition="val")
evaluation_model = NaiveEvaluationModel(
  metadata=val_metadata, 
  cell_model=cell_model, 
  tissue_model=tissue_model,
  device=device
  )
```

```{python}
transform = A.Resize(height=resize, width=resize)
```

```{python}
partition = "val"
tissue_folder = data_dir + "/" + tissue_trainable.get_tissue_folder(partition=partition)
print(tissue_folder)
result = predict_and_evaluate(
  evaluation_model=evaluation_model,
  partition=partition,
  tissue_file_folder = tissue_folder,
  transform=None,
  break_after_one_iteration=False
)
print(f"Result: {result}")
# Result (cell-only without tissue): 0.6963999999999999
# Result (cell-only with tissue help): 0.7110000000000001

```
