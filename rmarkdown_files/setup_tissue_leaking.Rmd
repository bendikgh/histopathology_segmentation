---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2

import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
from PIL import Image
from src.utils.utils import (
    read_data, 
    get_tissue_crops_scaled_tensor,
    get_partition_from_file_name
)
```

```{python}
on_idun = os.getcwd().startswith("/cluster")

if on_idun:
  data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
else: 
  data_path = "ocelot_data/"

train_data, val_data, test_data = read_data(data_path)
total_data = {}
total_data.update(train_data)
total_data.update(val_data)
total_data.update(test_data)
```

```{python}
# train_data = {k: train_data[k] for k in sorted(train_data, key=int)}
# val_data = {k: val_data[k] for k in sorted(val_data, key=int)}
# test_data = {k: test_data[k] for k in sorted(test_data, key=int)}
total_data = {k: total_data[k] for k in sorted(total_data, key=int)}
```

```{python}
# train_cropped_tissue = get_tissue_crops_scaled_tensor(
#     data=train_data
# )
# val_cropped_tissue = get_tissue_crops_scaled_tensor(
#     data=val_data
# )
# test_cropped_tissue = get_tissue_crops_scaled_tensor(
#     data=test_data
# )

# train_cropped_tissue = train_cropped_tissue[:, 3]
# val_cropped_tissue = val_cropped_tissue[:, 3]
# test_cropped_tissue = test_cropped_tissue[:, 3]
```

```{python}
# train_cropped_tissue[train_cropped_tissue == 255.] = 1.
# val_cropped_tissue[val_cropped_tissue == 255.] = 1.
# test_cropped_tissue[test_cropped_tissue == 255.] = 1.

# train_cropped_tissue -= 1
# val_cropped_tissue -= 1
# test_cropped_tissue -= 1
```

```{python}
train_folder = os.path.join(data_path, "annotations/train/cropped_tissue")
val_folder = os.path.join(data_path, "annotations/val/cropped_tissue")
test_folder = os.path.join(data_path, "annotations/test/cropped_tissue")
os.makedirs(train_folder, exist_ok=True)
os.makedirs(val_folder, exist_ok=True)
os.makedirs(test_folder, exist_ok=True)
```

```{python}
import torch
import torch.nn.functional as F
import numpy as np

convert = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])

for key, value in total_data.items():
    temp_dict = {key: value}
    cropped_tensor = get_tissue_crops_scaled_tensor(data=temp_dict)
    cropped_tensor = cropped_tensor[:, 3].squeeze()

    # Setting the background to 0, the tissue to 1 and the unknown to 2
    cropped_tensor[cropped_tensor == 255.0] = 3.0
    cropped_tensor -= 1
    one_hot = F.one_hot(cropped_tensor.to(torch.int64), num_classes=3)

    partition = get_partition_from_file_name(key)
    image_folder = os.path.join(data_path, "annotations", partition, "cropped_tissue")

    img = Image.fromarray(one_hot.numpy().astype("uint8"))
    img.save(f"{image_folder}/{key}.png")


# Adding missing images as empty images
all_keys = [int(k) for k in total_data.keys()]
all_nums = list(range(1, max(all_keys) + 1))
missing_keys = set(all_nums) - set(all_keys)
missing_keys -= set((586, 589, 609, 615))
print(missing_keys)
for key in missing_keys:
    key = str(key)
    # Adding leading zeros
    if len(key) < 3:
        key = "0" * (3 - len(key)) + key
    print(key)
    partition = get_partition_from_file_name(key)

    image_folder = os.path.join(data_path, "annotations", partition, "cropped_tissue")
    img = Image.fromarray(np.zeros((1024, 1024, 3)).astype("uint8"))
    img.save(f"{image_folder}/{key}.png")
```
