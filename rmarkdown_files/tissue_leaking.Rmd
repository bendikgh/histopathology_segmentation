---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: maptr
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import albumentations as A

from monai.data import DataLoader
from monai.losses import DiceLoss
from torch.optim import Adam
from glob import glob

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import TissueLeakingDataset

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
```

```{python}
on_idun = os.getcwd().startswith("/cluster")

if on_idun:
  data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
  print("Running on IDUN")
else: 
  data_path = "ocelot_data/"
  print("Running locally")
```

```{python}
train_cell_seg = sorted(glob(os.path.join(data_path, "annotations/train/segmented_cell/*")))
train_tissue_seg = []
train_input_img = []

for img_path in train_cell_seg: 
    ending = img_path.split("/")[-1].split(".")[0]
    tissue_seg_path = glob(os.path.join(data_path, "annotations/train/cropped_tissue/" + ending + "*"))[0]
    input_img_path = glob(os.path.join(data_path, "images/train/cell/" + ending + "*"))[0]
    train_tissue_seg.append(tissue_seg_path)
    train_input_img.append(input_img_path)


val_cell_seg = sorted(glob(os.path.join(data_path, "annotations/val/segmented_cell/*")))
val_tissue_seg = []
val_input_img = []

for img_path in val_cell_seg: 
    ending = img_path.split("/")[-1].split(".")[0]
    tissue_seg_path = glob(os.path.join(data_path, "annotations/val/cropped_tissue/" + ending + "*"))[0]
    input_img_path = glob(os.path.join(data_path, "images/val/cell/" + ending + "*"))[0]
    val_tissue_seg.append(tissue_seg_path)
    val_input_img.append(input_img_path)


test_cell_seg = sorted(glob(os.path.join(data_path, "annotations/test/segmented_cell/*")))
test_tissue_seg = []
test_input_img = []

for img_path in test_cell_seg: 
    ending = img_path.split("/")[-1].split(".")[0]
    tissue_seg_path = glob(os.path.join(data_path, "annotations/test/cropped_tissue/" + ending + "*"))[0]
    input_img_path = glob(os.path.join(data_path, "images/test/cell/" + ending + "*"))[0]
    test_tissue_seg.append(tissue_seg_path)
    test_input_img.append(input_img_path)
```

```{python}
transforms = A.Compose([
    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # You can adjust the blur limit
    A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),  # Adjust var_limit for noise intensity
    A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
], additional_targets = {
    "mask1": "mask", 
    "mask2": "mask"
}
)
```

```{python}
train_dataset = TissueLeakingDataset(input_files=train_input_img, cell_seg_files=train_cell_seg, tissue_seg_files=train_tissue_seg, transform=transforms)
val_dataset = TissueLeakingDataset(input_files=val_input_img, cell_seg_files=val_cell_seg, tissue_seg_files=val_tissue_seg)
test_dataset = TissueLeakingDataset(input_files=test_input_img, cell_seg_files=test_cell_seg, tissue_seg_files=test_tissue_seg)

train_dataloader = DataLoader(dataset=train_dataset, batch_size=2, drop_last=True)
val_dataloader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)
test_dataloader = DataLoader(dataset=test_dataset, batch_size=2, drop_last=True)
```

## Visualizing the images

```{python}
import numpy as np

lst = []

for img, seg in iter(val_dataloader):
    img, seg = img.cpu()[0].permute(1, 2, 0), seg.cpu()[0].permute(1, 2, 0)
    lst.append((img, seg))
```

```{python}
img, seg = lst[2]

print(img.size())
print(seg.size())

print(np.unique(img[:, :, 3:]))
print((img[:, :, 3:] == 1).sum())
print((img[:, :, 3:] == 0).sum())
```

```{python}
tissue_crop = img[:, :, 3:]
print(tissue_crop.size())
print(tissue_crop)
print(np.unique(tissue_crop))
```

```{python}
import matplotlib.pyplot as plt

plt.figure(figsize=(16, 8))
plt.subplot(1, 3, 1)
plt.imshow(img[:,:, :3])
plt.title("cell image")
plt.axis("off")

plt.subplot(1, 3, 2)
plt.imshow((img[:,:, 3:]*255).to(torch.uint8))
plt.title("crop tissue")
plt.axis("off")

plt.subplot(1, 3, 3)
plt.imshow(seg)
plt.title("crop tissue")
plt.axis("off")
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate,
    num_channels=4
)
model.to(device)
print()

learning_rate = 1e-4

loss_function = DiceLoss(softmax=True)
optimizer = Adam(model.parameters(), lr=learning_rate)
```

# Training the model

```{python}
from src.utils.utils_train import train
```

```{python}
num_epochs = 10
checkpoint_interval = 5
train(
    num_epochs=num_epochs,
    train_dataloader=train_dataloader,
    val_dataloader=val_dataloader,
    model=model,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False,
    dropout_rate=dropout_rate,
    backbone=backbone,
    model_name="tissue_leaking"
)
```

# Saving the model


# Running inference on the test set

```{python}
def test_model(model, test_dataloader, loss_function, device):
    model.eval()  
    test_loss = 0
    
    with torch.no_grad():  
        for inputs, labels in test_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs.to(torch.float32))
            
            loss = loss_function(outputs, labels)
            test_loss += loss.item()
    
    # Calculate average test loss
    test_loss /= len(test_dataloader)
    return test_loss

# After training, you can test the model with the test_data_loader:
test_loss = test_model(model, test_dataloader, loss_function, device)
print(f"Test Loss: {test_loss}")
```

```{python}
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np

colors = [(0, 0, 0), (1, 0, 0), (0, 1, 0)]
cmap = mcolors.ListedColormap(colors)

inputs, labels = test_data_loader.__iter__()._next_data()
outputs = model(inputs.to(device, dtype=torch.float32))

```

```{python}
cell_image = inputs[0, :3]
tissue_labels = inputs[0, 3]
output_image = outputs.argmax(1)

# Setting the correct color for the labels
label_image = labels[0].permute((1, 2, 0)).numpy()
mask = np.all(label_image == [1, 0, 0], axis=-1)
label_image[mask] = [0, 0, 0]

plt.figure(figsize=(16, 8))  # Adjust the width and height as needed

plt.subplot(1, 4, 1)
plt.title("Model Output")
plt.axis("off")
plt.imshow(output_image[0], cmap=cmap)

plt.subplot(1, 4, 4)
plt.title("tissue leaked")
plt.imshow(tissue_labels, cmap=cmap)
plt.axis("off")

plt.subplot(1, 4, 3)
plt.title("Cell data")
plt.axis("off")
plt.imshow(cell_image.permute((1, 2, 0)))

plt.subplot(1, 4, 2)
plt.title("Cell labels")
plt.imshow(label_image*255)
plt.axis("off")


plt.show()
```
