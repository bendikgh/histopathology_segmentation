---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import argparse
import os
import torch

from glob import glob
from monai.losses import DiceLoss
from monai.data import ImageDataset
from torch.utils.data import DataLoader
from torch.optim import Adam

from deeplabv3.network.modeling import _segm_resnet
from train_utils import train
```

```{python}
data_dir = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
train_seg_files = glob(os.path.join(data_dir, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_dir, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_dir, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_dir, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

# Create dataset and dataloader
train_dataset = ImageDataset(
    image_files=train_image_files, seg_files=train_seg_files
)
val_dataset = ImageDataset(image_files=val_image_files, seg_files=val_seg_files)

train_dataloader = DataLoader(
    dataset=train_dataset, batch_size=batch_size, shuffle=True
)
val_dataloader = DataLoader(dataset=val_dataset)

model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet50",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
```
