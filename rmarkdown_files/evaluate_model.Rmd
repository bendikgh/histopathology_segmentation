---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import matplotlib.pyplot as plt 
import seaborn as sns

from glob import glob
from torch.utils.data import DataLoader

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import CellOnlyDataset

sns.set_theme()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")
```

```{python}
data_dir = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
train_seg_files = glob(os.path.join(data_dir, "annotations/train/cell_mask_images/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_dir, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_dir, "annotations/val/cell_mask_images/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_dir, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_dir, "annotations/test/cell_mask_images/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_dir, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]

# Create dataset and dataloader
train_dataset = CellOnlyDataset(
    image_files=train_image_files, seg_files=train_seg_files
)
val_dataset = CellOnlyDataset(image_files=val_image_files, seg_files=val_seg_files)
test_dataset = CellOnlyDataset(image_files=test_image_files, seg_files=test_seg_files)

train_dataloader = DataLoader(
    dataset=train_dataset, shuffle=True
)
val_dataloader = DataLoader(dataset=val_dataset)
test_dataloader = DataLoader(dataset=test_dataset)
```

```{python}
model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet50",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
print() # To avoid cell output
```

```{python}
model.load_state_dict(torch.load("outputs/models/2023-11-29_16-56-45_deeplabv3plus_cell_only_lr-0.0005_dropout-0.3_backbone-resnet50_epochs-100.pth"))
model.eval()
print()
```

```{python}
it = iter(test_dataloader)
images, masks = next(it)
images, masks = images.to(device), masks.to(device)

outputs = model(images)
print(outputs)
```

```{python}
def show_batch_predictions(images, masks, outputs): 
    batch_size = images.size()[0]

    outputs = torch.argmax(outputs, dim=1)
    for i in range(batch_size): 
        plt.figure(figsize=(16, 8))
        plt.subplot(1, 3, 1)
        plt.axis("off")
        plt.imshow((images[i]*255).cpu().permute(1, 2, 0).to(torch.uint8))

        plt.subplot(1, 3, 2)
        plt.axis("off")
        plt.imshow(masks[i].cpu().permute(1, 2, 0))

        plt.subplot(1, 3, 3)
        plt.axis("off")
        plt.imshow(outputs[i].detach().cpu().squeeze())
        plt.show()

show_batch_predictions(images, masks, outputs)
```

```{python}
from monai.metrics import DiceMetric
from monai.transforms import Compose, AsDiscrete

def calculate_dice_score(dataloader, model, device): 

    dice_metric = DiceMetric(include_background=True, reduction="mean")
    post_pred = Compose([AsDiscrete(argmax=True, dim=1, to_onehot=3)])

    model.eval()
    for (images, masks) in dataloader: 
        images, masks = images.to(device), masks.to(device)
        with torch.no_grad(): 
            outputs = model(images)
        outputs = post_pred(outputs)
        dice_metric(outputs, masks)

    dice_score = dice_metric.aggregate().item()
    dice_metric.reset()

    return dice_score


```

```{python}
model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet50",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
model.eval()

model.load_state_dict(torch.load("outputs/models/2023-11-30_13-16-35_deeplabv3plus_cell_only_lr-0.0005_dropout-0.3_backbone-resnet50_epochs-300.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0005, dropout=0.3, backbone=resnet50, epochs=300")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
```

```{python}


model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet50",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
model.eval()

model.load_state_dict(torch.load("outputs/models/2023-11-29_16-44-45_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0001, dropout=0.3, backbone=resnet50 (Baseline)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")


model.load_state_dict(torch.load("outputs/models/2023-11-29_16-56-45_deeplabv3plus_cell_only_lr-0.0005_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

model.load_state_dict(torch.load("outputs/models/2023-11-29_17-23-18_deeplabv3plus_cell_only_lr-5e-05_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.00005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

model.load_state_dict(torch.load("outputs/models/2023-11-29_17-01-32_deeplabv3plus_cell_only_lr-0.0001_dropout-0.1_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0001, dropout=0.1, backbone=resnet50 (changed dropout)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

model.load_state_dict(torch.load("outputs/models/2023-11-29_17-10-59_deeplabv3plus_cell_only_lr-0.0001_dropout-0.5_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0001, dropout=0.5, backbone=resnet50 (changed dropout)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet34",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
model.eval()

model.load_state_dict(torch.load("outputs/models/2023-11-29_16-49-56_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet34_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_dataloader, model, device)
val_dice_score = calculate_dice_score(val_dataloader, model, device)
print("lr=0.0001, dropout=0.3, backbone=resnet34 (changed backbone)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
```

```{python}
baseline_training_losses = [0.6572608485513803, 0.5745230438757916, 0.5390014125376331, 0.5211421366857023, 0.5071037290047626, 0.5004768779083174, 0.48167853026973956, 0.4692953794586415, 0.4597666366976135, 0.4557831013689236, 0.4498100931547126, 0.44199558727595273, 0.43892089505584875, 0.4394994061820361, 0.429680908821067, 0.42406576932693013, 0.4170009737112084, 0.4149132924420493, 0.4180908659282996, 0.4053467147204341, 0.4022889751560834, 0.39632812568119596, 0.39747742852386164, 0.3904849077974047, 0.38658881004975765, 0.3792952286953829, 0.3781884160577034, 0.3800964385879283, 0.37282890811258435, 0.36936060810575677, 0.3682644519270683, 0.3633603161695052, 0.36237843060980035, 0.35410044996105894, 0.35049447538901346, 0.3471941984429651, 0.3432705767300664, 0.342697978627925, 0.3423216288187066, 0.3374400734901428, 0.33437560103377517, 0.33607117679654336, 0.32838924289966115, 0.3235730735623107, 0.3243653819877274, 0.3207710026478281, 0.3170901914032138, 0.31629273204170927, 0.31578901501334444, 0.31742803904475, 0.31450426031132134, 0.3150268473795482, 0.31170921362176235, 0.30176053272218123, 0.30213953889146145, 0.29993758882795063, 0.29415183377509213, 0.2935696295937713, 0.29151905495293284, 0.28804946736413606, 0.2855530721800668, 0.28564850469024816, 0.2860147737118663, 0.28253338774856257, 0.2790514215522883, 0.27610513628745564, 0.2748622352979621, 0.27847301747117725, 0.28298951715839155, 0.2784918710893514, 0.2728798973317049, 0.26961750917288724, 0.2682491656468839, 0.26547275270734516, 0.26437484701069036, 0.2603936295728294, 0.26077300249313823, 0.25823069591911474, 0.25803302350092905, 0.25653311610221863, 0.2551717359800728, 0.2529297911999177, 0.2525496723092332, 0.25161367928495215, 0.24970926040289354, 0.2483784127600339, 0.24562744400939163, 0.2441388952488802, 0.2441210308853461, 0.24062699261976747, 0.23979991522370553, 0.23995384923657592, 0.23821791489513552, 0.236085942509223, 0.2357815747358361, 0.23604166507720947, 0.23442381620407104, 0.2338462240841924, 0.235361141513805, 0.23385749635647754]
resnet34_training_losses = [0.6872260120450234, 0.6170255432323534, 0.5857228867861689, 0.5612684196355392, 0.5501959396868336, 0.5359939008342977, 0.5280529351866975, 0.5222320514065879, 0.5142820556553043, 0.5090847654002053, 0.5049685805427785, 0.5017943844503286, 0.496350066394222, 0.49308509668525385, 0.4870991220279616, 0.4890064548472969, 0.4915505951764632, 0.48593571721291057, 0.48234348272790717, 0.4733595756851897, 0.4666556934921109, 0.464861594900793, 0.46451969110235874, 0.46157316346557775, 0.4592117369174957, 0.45444366518332036, 0.44841964816560553, 0.4473380270052929, 0.4469946975610694, 0.4435866481187392, 0.438190472977502, 0.4358671228496396, 0.4340741378920419, 0.43093468826644277, 0.42955328980270696, 0.4328829950215865, 0.42428402815546307, 0.42483839757588443, 0.42441331914493013, 0.4202671452444427, 0.4190509763299202, 0.4180043059952405, 0.4114578804191278, 0.41567029210985923, 0.4152925647034937, 0.41359491433416096, 0.41435926970170467, 0.40917893696804436, 0.4086526723540559, 0.4055884875813309, 0.40200446394025063, 0.3984096767951031, 0.40022375145737005, 0.3963963067045017, 0.39919542475622527, 0.3964272713174625, 0.3945064143258698, 0.3898850588165984, 0.38695659807750155, 0.38696639817588185, 0.38514984748801406, 0.38446261140764976, 0.38452101118710574, 0.38704999186554734, 0.388939271167833, 0.39128458621550577, 0.3861465788617426, 0.38172913145045845, 0.3806346028434987, 0.37858894102427426, 0.3762216616650017, 0.37569092426981243, 0.3760213730286579, 0.3751804707001667, 0.37310587386695704, 0.372234939920659, 0.3721784687772089, 0.37012489474549587, 0.36672975092518084, 0.3657356318162412, 0.36746385450265845, 0.3642361723646826, 0.36433178977090486, 0.36401558652216076, 0.36321941991241613, 0.36032772246672184, 0.359822826726096, 0.35866824826415705, 0.36254369847628537, 0.3584324912149079, 0.3547879068218932, 0.3534984302764036, 0.3510206356948736, 0.3484931010372785, 0.3470121269323388, 0.34699309297970365, 0.3471610692082619, 0.3453745568285183, 0.34291147516698256, 0.3399872755517765]
lr_5e4_training_losses = [0.6072661702449506, 0.5257506370544434, 0.5086062165407034, 0.5024133136639228, 0.4943796465030083, 0.4909487829758571, 0.4864271200620211, 0.4837676768119519, 0.4818910470375648, 0.48315933851095344, 0.4764978871895717, 0.4746020505061516, 0.4731210218026088, 0.4664118739274832, 0.4673619311589461, 0.4602107538626744, 0.46167176686800443, 0.45970976673639735, 0.46290322496340824, 0.4526225213821118, 0.4517563861150008, 0.44787643872774563, 0.4457044679384965, 0.43762962222099305, 0.43594790788797233, 0.43910582615779, 0.43765744750316327, 0.4334067518894489, 0.4275166740784278, 0.42985988213465764, 0.42788962905223554, 0.42125114569297206, 0.4198813704343943, 0.42078745594391453, 0.4145077558664175, 0.41085752065365133, 0.41065235367188085, 0.4053032168975243, 0.4111335327992072, 0.4163307167016543, 0.40553093277491054, 0.40509393169329716, 0.4111954138829158, 0.4771738222012153, 0.4958141592832712, 0.46836190269543576, 0.4736884300525372, 0.5106584131717682, 0.5134644861404712, 0.4914126767561986, 0.48067231224133417, 0.47752766196544355, 0.4982725446040814, 0.5012565466073843, 0.4852175813454848, 0.4772261890081259, 0.4720026181294368, 0.47221076282171104, 0.4694616634112138, 0.45593533378380996, 0.4663679581422072, 0.473713678580064, 0.4884715538758498, 0.45543795915750357, 0.4564784994492164, 0.4743064298079564, 0.4612963387599358, 0.46890508074026843, 0.4720165550708771, 0.4783213936365568, 0.462803053855896, 0.45839314506604123, 0.45885564180520866, 0.4659595361122718, 0.5112855113469638, 0.5108832753621615, 0.5129480714981373, 0.4889956799837259, 0.5116833728093367, 0.4847283647610591, 0.47853698088572577, 0.46770033836364744, 0.4757083714008331, 0.46026935348143944, 0.45972548448122463, 0.47725239946292, 0.4619165599346161, 0.4543355730863718, 0.44019192594748274, 0.4478711417088142, 0.4423470506301293, 0.4363261419993181, 0.43418935262239894, 0.4640723719046666, 0.4452712347874275, 0.44026016547129704, 0.4495088435136355, 0.44417695769896876, 0.43537190831624545, 0.43157238180820756]
dr_01_training_losses = [0.6424723505973816, 0.5625283488860497, 0.5274454896266644, 0.5038184431883005, 0.4846308213013869, 0.4745161927663363, 0.4634509568031018, 0.4524431875118842, 0.4440439934913929, 0.43157871227998, 0.4281137649829571, 0.42305854237996615, 0.41789833307266233, 0.4116610105221088, 0.3982126676119291, 0.3963002883470975, 0.3857483020195594, 0.3725467819433946, 0.3729546111363631, 0.3647400214121892, 0.3570178719667288, 0.36467754130180063, 0.3498730982725437, 0.34278088143238655, 0.33555007187219765, 0.3319031394444979, 0.331945636180731, 0.323936318892699, 0.3193066622202213, 0.3281125362102802, 0.317168049628918, 0.3094749968785506, 0.3103486657142639, 0.3054293286341887, 0.3106304303957866, 0.3111842160041516, 0.3019860139259925, 0.2940264213543672, 0.28774136717502885, 0.28567806688638836, 0.2802489496194399, 0.2753591315104411, 0.2760424421383784, 0.2719213604927063, 0.269997759278004, 0.268540620803833, 0.2686081090798745, 0.2648487904897103, 0.26316752319152537, 0.2589250344496507, 0.25888334879508385, 0.2708900703833653, 0.2667536669052564, 0.2597293409017416, 0.25675069185403676, 0.25101457146497874, 0.24719882366748958, 0.24589337339768044, 0.24486602923044792, 0.24437173031843626, 0.241428198493444, 0.24173467869942006, 0.24098786046871773, 0.2379845889715048, 0.2413279891014099, 0.2384168001321646, 0.23849992958398966, 0.23215247931388708, 0.23088127707059566, 0.23001253616351347, 0.22650588578902758, 0.22610507355286524, 0.2255801438139035, 0.22408533486036153, 0.2232740166095587, 0.22672101843815584, 0.22786825608748656, 0.22931998039667423, 0.22619473659075223, 0.22316518930288462, 0.22079758987976955, 0.21858722418546678, 0.21929185356085118, 0.21483815243610968, 0.2151045153920467, 0.21266954793379858, 0.21140885800123216, 0.21167589964774938, 0.2094740622318708, 0.20814674210089903, 0.2097505000921396, 0.2080872288117042, 0.20805955265577022, 0.20490700029409847, 0.2053251516360503, 0.20665985575089088, 0.20500411104697447, 0.2063828455714079, 0.20489065589813085, 0.20437741107665575]
dr_05_training_losses = [0.6629976529341478, 0.582665765285492, 0.545095269038127, 0.5282460891283476, 0.5154537916183471, 0.49614276931836054, 0.4902894657391768, 0.48343012057817897, 0.47648549263293927, 0.4752952250150534, 0.46991646243975715, 0.46410362399541416, 0.46795884324954107, 0.4617777622663058, 0.4589665834720318, 0.45243301620850196, 0.4512303127692296, 0.4488352271226736, 0.4509577751159668, 0.44326363847805905, 0.43979927118007955, 0.43552919167738696, 0.4365945394222553, 0.4348621794810662, 0.431173516695316, 0.42492373218903173, 0.41848987340927124, 0.4176449326368479, 0.4150855564154111, 0.41263885681445783, 0.4088142748062427, 0.4074793558854323, 0.4035005720762106, 0.39851702176607573, 0.4004115315584036, 0.396188322855876, 0.39763806416438174, 0.38744638791451086, 0.3894844820866218, 0.38679290138758143, 0.3806902032632094, 0.38019024041982796, 0.37819511752862195, 0.37139306572767405, 0.37056841621032127, 0.3639032441836137, 0.36855982633737416, 0.36213031319471506, 0.3586469664023473, 0.35859943009339845, 0.35752631150759184, 0.3553837015078618, 0.34955817002516526, 0.3460166335105896, 0.3425415066572336, 0.3378442239302855, 0.3366494818375661, 0.3360259292217401, 0.33141372341376085, 0.32647159443451806, 0.3269584197264451, 0.3426657924285302, 0.330259145452426, 0.3234402500666105, 0.3229072378231929, 0.32019518315792084, 0.3172503003707299, 0.3155729768367914, 0.31555285499646113, 0.3104526881988232, 0.31026825125400836, 0.3134690541487474, 0.3058379418574847, 0.30507112924869245, 0.3015504130950341, 0.3034164233849599, 0.3073023864856133, 0.2987839724008854, 0.2950754816715534, 0.29264171031805186, 0.2933803209891686, 0.28862730379288015, 0.28626376000734477, 0.28494251714302943, 0.28342520548747135, 0.28256372740635505, 0.2974704045515794, 0.28527709199832035, 0.28435735885913554, 0.2786407291889191, 0.2763969302177429, 0.27292711345049053, 0.27497361027277434, 0.2721131730538148, 0.2686155101427665, 0.2659758175794895, 0.27672566656882946, 0.273012048464555, 0.26928963225621444, 0.27105975517859826]
lr_5e5_training_losses = [0.7301189578496493, 0.6408751597771278, 0.588036046578334, 0.5666293767782358, 0.5460132699746352, 0.532283297410378, 0.5253624255840595, 0.5158265677782206, 0.5056280136108399, 0.4959407852246211, 0.49572589168181785, 0.48531691294450024, 0.48665588727364173, 0.4808688411345849, 0.47453103707386896, 0.47302866257154025, 0.4737242015508505, 0.465962722668281, 0.45634328356155984, 0.45121101232675404, 0.44790594623639035, 0.45001061237775364, 0.43966193382556623, 0.43678944477668175, 0.4340656936168671, 0.4305158459223234, 0.42689524247096133, 0.42022930062734165, 0.4200902003508348, 0.4182013754661267, 0.4134397978966053, 0.4111252968127911, 0.4105463789059566, 0.4089530532176678, 0.39494705291894766, 0.3945713075307699, 0.3968220632809859, 0.3904352944630843, 0.3888224056133857, 0.3833926063317519, 0.3806767647082989, 0.38145394508655256, 0.3811381729749533, 0.3794428752018855, 0.37996749648681055, 0.37170523955271795, 0.3667223783639761, 0.37140721541184646, 0.36212872175069954, 0.3614451046173389, 0.3615988002373622, 0.3594167993618892, 0.3546666736786182, 0.3546450688288762, 0.3482409440554105, 0.34996915046985333, 0.34327315458884605, 0.3456285256605882, 0.342610024030392, 0.3431194007396698, 0.3373250200198247, 0.33502820890683394, 0.33430860248895794, 0.3332898071179023, 0.3345961272716522, 0.32785974282484787, 0.3315298075859363, 0.33026555776596067, 0.3267104827440702, 0.3264635031039898, 0.32669670513043036, 0.3219055567796414, 0.32247389532052556, 0.3179852918936656, 0.3240271190038094, 0.317278885612121, 0.31272368866663713, 0.3133987754583359, 0.3119717994561562, 0.30685853430858023, 0.3044797585560725, 0.303449825827892, 0.308233900482838, 0.3035122247842642, 0.30084237868969255, 0.2993692508110633, 0.30049266333763414, 0.29828210725234106, 0.3077105315831991, 0.29834106518672066, 0.2987250571067517, 0.29877767012669487, 0.2929730887596424, 0.2903938868871102, 0.2967125482284106, 0.29424996078014376, 0.28873163094887366, 0.2898672266648366, 0.28835541262076453, 0.28726682387865504]
plt.figure(figsize=(20, 6))
plt.plot(baseline_training_losses, label="Baseline")
plt.plot(resnet34_training_losses, label="ResNet34")
plt.plot(lr_5e4_training_losses, label="Learning Rate: 5e-4", ls=":")
plt.plot(lr_5e5_training_losses, label="Learning Rate: 5e-5", ls=":")
plt.plot(dr_01_training_losses, label="Dropout Rate: 0.1", ls=":")
plt.plot(dr_05_training_losses, label="Dropout Rate: 0.5", ls=":")
plt.title("Training Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

```{python}
baseline_val_losses = [0.60840795106358, 0.5429483155409495, 0.5239383098151948, 0.526654753420088, 0.5041655252377192, 0.492653273873859, 0.49022511144479114, 0.4829270276758406, 0.49687332411607105, 0.48246579037772286, 0.49013176891538834, 0.4966228488418791, 0.48499537342124516, 0.4831855876578225, 0.48939737180868786, 0.48045238355795544, 0.4795576681693395, 0.4776704791519377, 0.48258199128839707, 0.47439517577489215, 0.48484256698025596, 0.5035728199614419, 0.4805670711729262, 0.4825870676173104, 0.477879845433765, 0.47858672506279415, 0.48104334043131936, 0.5109313180049261, 0.48019394112957847, 0.4797976828283734, 0.48243216011259293, 0.48552236954371136, 0.48502929011980694, 0.4818113115098741, 0.4995023078388638, 0.47946276101801133, 0.4830912931097878, 0.4845019082228343, 0.49555356634987724, 0.47898129291004604, 0.48427486585246193, 0.484182756808069, 0.48976856138971114, 0.48245936466587913, 0.49592169953717125, 0.4944054451253679, 0.49157055219014484, 0.4869065549638536, 0.4914136694537269, 0.4898167633348041, 0.4998532765441471, 0.4856710152493583, 0.49110059440135956, 0.48510156240728164, 0.48458204170068103, 0.49132682383060455, 0.48806262347433305, 0.4776354365878635, 0.48732950124475694, 0.487478483054373, 0.49700521263811326, 0.49245628383424545, 0.4937627696328693, 0.49487918615341187, 0.4920561611652374, 0.5002572867605422, 0.49379371106624603, 0.4868348207738664, 0.4986979448133045, 0.4977603091133965, 0.4975006977717082, 0.49822143382496303, 0.4972820050186581, 0.5003975745704439, 0.5006928725375069, 0.49993158214622074, 0.49590154820018345, 0.5065073437160916, 0.4964037819041146, 0.5042407827244865, 0.5057758473687701, 0.498639487557941, 0.5095162457889981, 0.49527355862988365, 0.49337677160898846, 0.5049712161223093, 0.5022668027215533, 0.4961111479335361, 0.4948828054798974, 0.50186787545681, 0.501279718346066, 0.49893396264976925, 0.5017570339971118, 0.5015290462308459, 0.507232000430425, 0.4983510176340739, 0.4995574702819188, 0.4986801693836848, 0.4971669730212953, 0.5200306690401502]
resnet34_val_losses = [0.6479305095142789, 0.5851743651760949, 0.5749597118960487, 0.5443180269665189, 0.5351917478773329, 0.5188629875580469, 0.5075605064630508, 0.5079574882984161, 0.5046803918149736, 0.5069421943691041, 0.5394362873501248, 0.5023437589406967, 0.5115151090754403, 0.49411434100733864, 0.4931743840376536, 0.49873526725504136, 0.504378961192237, 0.49580510291788316, 0.5062619066900678, 0.4904010064072079, 0.5049165553516812, 0.4881614115503099, 0.49648647838168675, 0.5224088297949897, 0.4938216954469681, 0.4928745958540175, 0.48618243634700775, 0.503975025481648, 0.4892648094230228, 0.4849962161646949, 0.4927241305510203, 0.49625275532404584, 0.49711232218477464, 0.49265507691436344, 0.4942572663227717, 0.49109935263792676, 0.49346286058425903, 0.5119731078545252, 0.49069228437211776, 0.5005770557456546, 0.4992987679110633, 0.49458155367109513, 0.48866913219292957, 0.4975917720132404, 0.49245941307809615, 0.5108056250545714, 0.4959100931882858, 0.494288381603029, 0.4966651317146089, 0.48878742423322463, 0.487047263317638, 0.4920492900742425, 0.5018739567862617, 0.49149104124969906, 0.49950230452749467, 0.49605408476458657, 0.4980175776614083, 0.49098536206616294, 0.4874786304103004, 0.48981455630726284, 0.4859892941183514, 0.4895765847629971, 0.4920102424091763, 0.48255785637431675, 0.4840092841121886, 0.4931340101692412, 0.48309837612840867, 0.49077100886238945, 0.5037042631043328, 0.49576403697331745, 0.48892109592755634, 0.48625228305657703, 0.4942687220043606, 0.4832698686255349, 0.49822086426946854, 0.49254460963937974, 0.4861295637157228, 0.491831479801072, 0.4983040574524138, 0.5031453669071198, 0.486175161268976, 0.48999497294425964, 0.49195362130800885, 0.48538874089717865, 0.49376865890291, 0.48648017479313743, 0.4926496065325207, 0.49386389719115364, 0.5010960168308682, 0.49056896070639294, 0.4919681085480584, 0.49025794863700867, 0.48984379404120976, 0.4949248714579476, 0.4852694521347682, 0.48733946018748814, 0.48834316266907585, 0.4904641658067703, 0.49223065707418656, 0.49246832231680554]
lr_5e4_val_losses = [0.5592848347580951, 0.5204323905965557, 0.5123542845249176, 0.5017993631570236, 0.5101420063039531, 0.497563264940096, 0.503772444051245, 0.4999838886053666, 0.49625931356264197, 0.5163415488989457, 0.49951956712681317, 0.5497297229974166, 0.5028746568638346, 0.49798593443372974, 0.4977877658346425, 0.5027901387732961, 0.5313205965187239, 0.495165730300157, 0.4990771425806958, 0.48651999623879144, 0.4848874781442725, 0.5046358264010885, 0.48614579568738525, 0.49583210763723956, 0.4790711467680724, 0.49096778553465137, 0.49480453263158386, 0.4889793810637101, 0.4933717315611632, 0.5176204637340878, 0.49933646684107574, 0.4765363776165506, 0.49804891192394757, 0.4909623330054076, 0.4865029039590255, 0.506966479446577, 0.49671846757764404, 0.4856673194014508, 0.4967158929161403, 0.4827235159666642, 0.4855582636335622, 0.49169665315876837, 0.504583477973938, 0.4857289596744206, 0.5295891243478527, 0.4848623172096584, 0.4670641072418379, 0.4998877566793691, 0.4989310956519583, 0.48815879225730896, 0.480265472246253, 0.4699232021103735, 0.5620398236357648, 0.4975461376749951, 0.4917077979315882, 0.5010478898234989, 0.4845267715661422, 0.47510225228641345, 0.46798844829849573, 0.4746204692384471, 0.4742528899856236, 0.5120999826037366, 0.4734195691087972, 0.46180112076842267, 0.4902901571729909, 0.4724540243978086, 0.4501438451849896, 0.48707366378411004, 0.4922903685466103, 0.5267645159493322, 0.45520375863365503, 0.4564103937667349, 0.46363420071809186, 0.46505281588305597, 0.5530329761297806, 0.4865991667560909, 0.5246739193149235, 0.5003063834231832, 0.49455684682597284, 0.47794006570525793, 0.4763218501339788, 0.46240552611972974, 0.4699456717657006, 0.44769557662632153, 0.4555250302605007, 0.4770201483498449, 0.44267766242441925, 0.44390926024188165, 0.4317301434019338, 0.47516987375591113, 0.4442095043866531, 0.43955153356427734, 0.4408353696698728, 0.4643060564994812, 0.44393271985261334, 0.44488820822342584, 0.4618488213290339, 0.44601526726847107, 0.43636247256527777, 0.44641677063444385]
dr_01_val_losses = [0.6008842120999875, 0.5480406180672024, 0.5422163527944813, 0.49701535313025763, 0.49285556699918665, 0.4915411161339801, 0.5096147773058518, 0.48137185884558636, 0.4804496220920397, 0.4938030087429544, 0.483905052361281, 0.4797625502814417, 0.48859499459681305, 0.48648903033007745, 0.4911773917467698, 0.4839066228140955, 0.48598487351251685, 0.472272576197334, 0.4891619941462641, 0.4845914672250333, 0.49569701241410297, 0.5056132790835007, 0.4895874831987464, 0.49446259633354517, 0.4894469121228094, 0.4844447788984879, 0.485700284657271, 0.4867602586746216, 0.48651175784028095, 0.49780708421831543, 0.4958085223384526, 0.48645974242168927, 0.4985744577387105, 0.4899365396603294, 0.4977764409521352, 0.48915339423262555, 0.48654113645138947, 0.4926087130670962, 0.4942035506600919, 0.4935620349386464, 0.4946037453153859, 0.5022225794584855, 0.5029017238513284, 0.4939666468164195, 0.5015176988166311, 0.4954736997251925, 0.5123465100060338, 0.4984282592068548, 0.49712217372396716, 0.5026267676249795, 0.5014311075210571, 0.5005734316680742, 0.5080522221067677, 0.503759301227072, 0.497819633587547, 0.5022123404171156, 0.5078766047954559, 0.49733533807422803, 0.508085723804391, 0.5029722555823948, 0.5048083377921063, 0.5102187213690385, 0.5121302410312321, 0.5049666321795919, 0.5191069958002671, 0.5043770800466123, 0.49995829100194183, 0.5105563842731974, 0.5150958481042281, 0.5063606435837953, 0.5042785911456399, 0.505567615446837, 0.5090557388637377, 0.5123519223669301, 0.508670476467713, 0.5001509850439818, 0.511633883351865, 0.5176278002884077, 0.5162689932014631, 0.5170796345109525, 0.5188220661619435, 0.5294564612533735, 0.5006838298362234, 0.5109113973119984, 0.5111673163331073, 0.5159131055292876, 0.5099537165268607, 0.509310976318691, 0.5070798513681992, 0.5086164280124332, 0.5102068652277407, 0.5163646664308466, 0.5244878465714662, 0.5132305453652921, 0.5192036045634228, 0.5067108247591101, 0.5083148855230083, 0.5154116011184194, 0.5141145366689434, 0.510390078244002]
dr_05_val_losses = [0.6116480905076732, 0.5534445151038792, 0.5308985917464547, 0.5183331603589265, 0.5218370310638262, 0.4926857909430628, 0.4859575888384943, 0.48187208823535754, 0.4832209465296372, 0.4850508479968361, 0.47444728664729907, 0.47999183509660803, 0.4763698772243831, 0.4806006745151851, 0.4700928848722707, 0.4774874604266623, 0.4805824393811433, 0.47680796618046967, 0.4715485093386277, 0.47647175192832947, 0.47212648262148316, 0.48352200440738513, 0.4749179430629896, 0.5127216098101243, 0.48291659355163574, 0.48201701045036316, 0.4696046204670616, 0.47213112530500995, 0.47072399440019025, 0.4744732626106428, 0.46772441008816595, 0.4694055228129677, 0.4813056380852409, 0.4786907006864962, 0.4724110105763311, 0.4886847566003385, 0.48858662662298785, 0.47801391974739404, 0.48306607811347296, 0.48583355157271674, 0.4846701311028522, 0.4758081747137982, 0.4900988729103752, 0.4770811290844627, 0.47908774795739545, 0.48495041805764905, 0.4893916923066844, 0.48588130396345386, 0.4877054471036662, 0.4738668760527735, 0.4914087070071179, 0.4766254321388576, 0.4927354118098383, 0.4859368166197901, 0.48256878230882727, 0.4857688287030096, 0.48488234177879663, 0.48913594562074414, 0.4874281598174054, 0.49011777017427527, 0.5032662827035655, 0.48561762338099274, 0.4886206349600916, 0.49377306129621423, 0.49568350677904877, 0.49521710950395337, 0.4852106376834538, 0.4903168496878251, 0.4923950213453044, 0.5013800587343133, 0.4882458007853964, 0.4921993742818418, 0.48835958346076636, 0.5006897086682527, 0.491235736919486, 0.49016302953595703, 0.4826265132945517, 0.4884930628797282, 0.4834093153476715, 0.48800477385520935, 0.48713941548181616, 0.4866813680400019, 0.49027612934941833, 0.49543642609015753, 0.4947005108646724, 0.4977489295213119, 0.49205988775128906, 0.4907188635805379, 0.49086191602375195, 0.4966067619945692, 0.4894207754860754, 0.4900977469008902, 0.4966790015282838, 0.506294459104538, 0.4961901721747025, 0.4889224417831587, 0.5039513175902159, 0.5088390254456064, 0.49674629517223523, 0.5028636636941329]
lr_5e5_val_losses = [0.6395230707914933, 0.5788890175197435, 0.5654616019000178, 0.530392613099969, 0.560567311618639, 0.5031236073245173, 0.5158926080102506, 0.5091045356315115, 0.4905661059462506, 0.49458976413892664, 0.4883125864941141, 0.4813560014185698, 0.48392189067343006, 0.49434789885645325, 0.4848318087018054, 0.49487841647604236, 0.47775572538375854, 0.48574616468471027, 0.4830673233322475, 0.480646269476932, 0.4749528027099112, 0.4687778638756793, 0.47202378381853516, 0.4863577109316121, 0.4771648476953092, 0.47395872551461926, 0.4824054655821427, 0.4780061594817949, 0.4723177072794541, 0.4816020182941271, 0.5098864500937255, 0.47966586895610974, 0.47672169364016986, 0.4842252174149389, 0.4791116882925448, 0.4818290433158045, 0.47945881149043207, 0.4905021268388499, 0.48420248472172284, 0.5119452269180961, 0.48243542728216754, 0.5066832627939142, 0.4898434981055882, 0.4913243418154509, 0.48495507888171985, 0.475020012129908, 0.5036402383576268, 0.4874648179696954, 0.4870617000953011, 0.4972728996173195, 0.4903245503487794, 0.49694606273070624, 0.4890834585480068, 0.484900018443232, 0.4991320047689521, 0.4902264540610106, 0.49189966787462647, 0.4932963446430538, 0.48358100263968756, 0.5114469411580459, 0.5010307703329169, 0.4913434554701266, 0.4931241196134816, 0.5079047939051753, 0.49460291473761847, 0.48871315043905506, 0.49859253738237463, 0.49372537498888763, 0.4922169485817785, 0.4886250871679057, 0.49203580358754034, 0.49252272170522937, 0.510130015404328, 0.5203589084355728, 0.492258669241615, 0.49670044753862463, 0.5055901732133783, 0.4895334697288016, 0.4990205894345823, 0.5020537052465521, 0.49679118394851685, 0.5000593960285187, 0.50204471271971, 0.49280379647793976, 0.4900589468686477, 0.4988186022509699, 0.49112763093865436, 0.4883274604444918, 0.5078274789063827, 0.4932604833789494, 0.5030162451059922, 0.5125801342984905, 0.5052386794401251, 0.49087833839914075, 0.49457840427108435, 0.5112568567628446, 0.5018871763478154, 0.4878528105176013, 0.4961485085280045, 0.5065098145733709]
plt.figure(figsize=(20, 6))
plt.plot(baseline_val_losses, label="Baseline")
plt.plot(resnet34_val_losses, label="ResNet34")
plt.plot(lr_5e4_val_losses, label="Learning Rate: 5e-4", ls=":")
plt.plot(lr_5e5_val_losses, label="Learning Rate: 5e-5", ls=":")
plt.plot(dr_01_val_losses, label="Dropout Rate: 0.1", ls=":")
plt.plot(dr_05_val_losses, label="Dropout Rate: 0.5", ls=":")
plt.title("Validation Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

```{python}
last_model_val_losses = [0.6049017439717832, 0.519922963950945, 0.5063159608322642, 0.5085233307403066, 0.5045329539672189, 0.4983352357926576, 0.49518869104592694, 0.5047840255758037, 0.49491770889448083, 0.49265258078989776, 0.5029927090458248, 0.5024358254411946, 0.4910455436810203, 0.5015795502973639, 0.5261653985666193, 0.4884042986061262, 0.49137787585673126, 0.48826932388803235, 0.4965472325034764, 0.4868599111619203, 0.48922446370124817, 0.4913356174593386, 0.48172003549078235, 0.4794893394345823, 0.49809591666511865, 0.48947404260220734, 0.49828459128089575, 0.4892854366613471, 0.48987059619115747, 0.49576274856277136, 0.4842828525149304, 0.4951716933561408, 0.4884427643340567, 0.4867242885672528, 0.5139863154162532, 0.49195605516433716, 0.5395539091980975, 0.49192993278088776, 0.4803786005662835, 0.49699066903280176, 0.49830378527226654, 0.532919695843821, 0.4799793181212052, 0.581059463646101, 0.5050228587959124, 0.4750261812106423, 0.48037787494452105, 0.5132542926332225, 0.504413419443628, 0.47267863154411316, 0.543215732211652, 0.4710790683393893, 0.4672018159990725, 0.46574397320332733, 0.4574091939822487, 0.49074219879896747, 0.5439517588719077, 0.4751303934532663, 0.47275105248326843, 0.4651272750419119, 0.5600734275320302, 0.45826707326847577, 0.46377301734426746, 0.44939050207967346, 0.4712134716303452, 0.4794651088507279, 0.4563754537831182, 0.4493063273637191, 0.4434604567030202, 0.44416585305462714, 0.477234053870906, 0.4992089854634326, 0.5142686367034912, 0.5001839477082958, 0.47052187893701636, 0.4659275049748628, 0.45217917276465375, 0.4518412831036941, 0.4492315973924554, 0.44511638646540436, 0.45517218890397443, 0.46252815749334253, 0.47913806723511737, 0.5032636095648226, 0.5073019136553225, 0.47217105652975, 0.49718161899110547, 0.4875262379646301, 0.4782433224760968, 0.47855283125587134, 0.47860520948534424, 0.4719513175280198, 0.5002991310928179, 0.4702229292496391, 0.47057200773902563, 0.4625303071478139, 0.4674557291943094, 0.4633916551652162, 0.4670858499796494, 0.47241005560626154, 0.4573242560676906, 0.5029502575812133, 0.4654967901499375, 0.450431482947391, 0.5030885261038075, 0.4754903303540271, 0.47645951353985333, 0.47498085706130316, 0.46961601013722626, 0.471826266983281, 0.47486318323923193, 0.4980042732280234, 0.5005560400693313, 0.4710543052009914, 0.47439588152843976, 0.4942555440508801, 0.4613861247249272, 0.47357105560924695, 0.44606459270352905, 0.46032721840817, 0.46754043905631354, 0.4643697246261265, 0.46966151698775915, 0.4605106646599977, 0.45222972009492957, 0.47115836972775665, 0.45358671831048053, 0.4493124044459799, 0.45354070222896076, 0.44627665695936786, 0.4716722757919975, 0.4671963518080504, 0.47021911973538605, 0.4649030592130578, 0.5134015407251276, 0.5363554604675459, 0.4971503822699837, 0.4719108161718949, 0.4619701414004616, 0.47602347057798633, 0.47660888277966046, 0.46921236100404157, 0.4711660107840662, 0.4784838958926823, 0.4754891019800435, 0.466800666373709, 0.4769707633101422, 0.4808281439801921, 0.4810719943564871, 0.5067507818989132, 0.46326808825783106, 0.44582978927570843, 0.4352203361366106, 0.5505002529724784, 0.4792952071065488, 0.4973919663740241, 0.4902438625045445, 0.47875266489775287, 0.48141790343367535, 0.4966495244399361, 0.5115012552427209, 0.46897654559301294, 0.4675346574057703, 0.5009068665297135, 0.4779612512692161, 0.4836664834748144, 0.5012441601442255, 0.5273145022599594, 0.47296197777209076, 0.48241324528403906, 0.46288868655329163, 0.49091466743013135, 0.4642895460128784, 0.4605865634006003, 0.45497933807580365, 0.4487302355144335, 0.4477075079213018, 0.47016734532687976, 0.4582688821398694, 0.44649273804996326, 0.4741616456404976, 0.4379755323347838, 0.4475618419439896, 0.42838567884072015, 0.425501665343409, 0.44385610196901404, 0.42818985166757, 0.4713211733361949, 0.4537075330381808, 0.4440037115760472, 0.4584129038064376, 0.49501699338788574, 0.43996537509171857, 0.4811550015988557, 0.46661708665930707, 0.4974943153236223, 0.45892041273739026, 0.5201382753641709, 0.529518266086993, 0.4877455908319224, 0.4784256453099458, 0.5057571504427039, 0.5015422377897345, 0.47463466550992883, 0.4720427406870801, 0.4689993171588234, 0.48109147730080976, 0.4703812702842381, 0.4582373279592265, 0.45791660054870276, 0.4635118427483932, 0.4632690186085908, 0.4586738257304482, 0.4750387746354808, 0.46648879932320636, 0.4648415031640426, 0.45608691028926684, 0.45385881999264593, 0.45904346393502277, 0.46575055174205615, 0.46802679352138354, 0.4571467638015747, 0.46955855255541595, 0.4557063773922298, 0.4579011292561241, 0.4465570294338724, 0.4611761634764464, 0.4482757332532302, 0.457231184710627, 0.5006470032360243, 0.4526809790860052, 0.48649481327637384, 0.45085086381953693, 0.5320408888485121, 0.46685808637867804, 0.4664837070133375, 0.4735993639282558, 0.4621138974376347, 0.4518204460973325, 0.45979464183682983, 0.4572184824425241, 0.4478760335756385, 0.45333287638166675, 0.44803323175596155, 0.4466447907945384, 0.4597794296948806, 0.4593146132386249, 0.44932734966278076, 0.46683628792348114, 0.46561069851336273, 0.45138800921647443, 0.4539560364640277, 0.45352318235065625, 0.45240272257639014, 0.4670010338658872, 0.4549903532733088, 0.4514758703501328, 0.4423616826534271, 0.44446199873219366, 0.4546135391878045, 0.4652615954046664, 0.442236118990442, 0.4420281376527703, 0.4418731370697851, 0.4384632136510766, 0.43328633515731146, 0.48499803698581195, 0.4511923232804174, 0.44015153724214306, 0.44097505056339764, 0.43316013527953107, 0.4353576535763948, 0.44699741705604223, 0.4424125150493953, 0.4374986653742583, 0.42680347224940424, 0.4863245163274848, 0.46368701043336286, 0.4602175562278084, 0.44978447971136676, 0.4508146604766016, 0.44751940343690955, 0.4483949477257936, 0.44581311293270276, 0.4495025069817253, 0.44082103604855744, 0.44496722454610077, 0.44856462271317193, 0.4411946301874907, 0.4381773083106331, 0.441381793955098, 0.44421220603196515, 0.4362629302169966, 0.4374658271022465, 0.4465095465597899, 0.48726101154866425, 0.4508731598439424, 0.44463754088982294, 0.4398050204567287, 0.4512647597686104]
last_model_tensor = torch.tensor(last_model_val_losses)
print(torch.argmin(last_model_tensor))
print(last_model_tensor[269])

```

```{python}
training_losses = [0.6316346296897302, 0.5366551252511832, 0.5106021981972915, 0.50520809338643, 0.4987622394011571, 0.49271270907842196, 0.48783080211052526, 0.4857872192676251, 0.47911374752338115, 0.478646352657905, 0.4732719247157757, 0.473300557411634, 0.4648080908335172, 0.46550355278528655, 0.4654495752774752, 0.4708814909824958, 0.45927738547325136, 0.456130745777717, 0.4575432685705332, 0.44979021916022666, 0.4510059824356666, 0.4490613960302793, 0.44309219534580524, 0.44209815126198987, 0.433956987124223, 0.434637864277913, 0.43261617513803335, 0.4344032535186181, 0.4282211808057932, 0.4209388366112342, 0.42249957231374885, 0.4164505793498113, 0.41928618412751417, 0.40503008915827826, 0.40787858687914336, 0.40801861652961147, 0.41049228127186116, 0.4766622680884141, 0.442674673979099, 0.4378407849715306, 0.4592828140808986, 0.4582326843188359, 0.44190739072286167, 0.4421157208772806, 0.5031604647636414, 0.48143864411574144, 0.47702657121878406, 0.4624262644694402, 0.46725110961840705, 0.47312275171279905, 0.45782563915619484, 0.4781262260216933, 0.46950299189640926, 0.4540823996067047, 0.45525037921392003, 0.4580627895318545, 0.47592659776027385, 0.4891749592927786, 0.4785011291503906, 0.47586962580680847, 0.4645425989077641, 0.46866457095512976, 0.4517251840004554, 0.4466210718338306, 0.46455991864204405, 0.4686507610174326, 0.4595250776180854, 0.4510198042942927, 0.4342156483576848, 0.42994703421225916, 0.46090286924288826, 0.4653559615978828, 0.4516547184724074, 0.4677696480200841, 0.45439600256773144, 0.4603676681335156, 0.4405940518929408, 0.4534986161268674, 0.4353779435157776, 0.4257257374433371, 0.42899324756402235, 0.4305850932231316, 0.45572930391018207, 0.5345699700025411, 0.5106028520143949, 0.505143907895455, 0.4990681969202482, 0.49558417476140537, 0.4864596453996805, 0.47850685165478635, 0.4759684892801138, 0.47328014006981484, 0.46645202178221484, 0.474095075405561, 0.46929970887991096, 0.47055706473497244, 0.4711708210981809, 0.47355660796165466, 0.4620501261491042, 0.48296190546109125, 0.4711689357574169, 0.4671051011635707, 0.4680796843308669, 0.4661215635446402, 0.48626384414159335, 0.48247973460417526, 0.46826627529584447, 0.48175222323491024, 0.4831755560178023, 0.46429839180066035, 0.4612057424508608, 0.4630724663917835, 0.4707651945260855, 0.455501494040856, 0.45836724455539996, 0.46923589385472814, 0.4709477268732511, 0.46399112527187053, 0.44366790102078363, 0.4508803092516386, 0.444034736431562, 0.43698305854430564, 0.4450157417700841, 0.4437791934380165, 0.4285166552433601, 0.43950483753130987, 0.44074972776266247, 0.4408219731771029, 0.45428918095735404, 0.44163540601730344, 0.43429079972780665, 0.4495753600047185, 0.44591583426182085, 0.43853619373761693, 0.4282243306820209, 0.4307048430809608, 0.49305625374500567, 0.4737203079920549, 0.4745353295252873, 0.46317981068904585, 0.4456535729078146, 0.4566732420371129, 0.452697997368299, 0.4456126378132747, 0.43432828371341414, 0.4811448574066162, 0.4678522178759942, 0.4617129651399759, 0.46615491326038655, 0.48301326770048875, 0.4582780888447395, 0.4488138941618112, 0.4352078194801624, 0.44525747345044064, 0.5029348492622375, 0.47941768857148975, 0.5007240052406604, 0.5053324644382183, 0.48019031377939075, 0.48401660598241364, 0.4827365756034851, 0.4800055742263794, 0.4645588090786567, 0.47947461880170383, 0.47367441929303683, 0.47392712969046374, 0.5018906286129585, 0.4979902730538295, 0.4879959904230558, 0.47755544414887063, 0.46400383298213665, 0.45861034851807814, 0.4568755259880653, 0.45246631571879753, 0.44817915421265825, 0.4504302822626554, 0.4389192365683042, 0.45559589129227857, 0.44819201643650347, 0.44397147389558644, 0.4434652864933014, 0.4462529787650475, 0.4364850903932865, 0.43790050928409285, 0.43346176881056564, 0.4353658506503472, 0.45062846128757184, 0.442545805986111, 0.46394796600708593, 0.44148976986224836, 0.437573734155068, 0.43209658356813285, 0.45787528478182277, 0.4523011409319364, 0.4597320501620953, 0.46453257844998286, 0.47122046030484716, 0.4897103460935446, 0.5310389206959651, 0.5240140704008249, 0.49007984629044166, 0.4774592055724217, 0.49184932571191053, 0.48174828245089607, 0.4715242917721088, 0.4698879952614124, 0.4792408443414248, 0.4709540903568268, 0.46553810972433823, 0.4657757011743692, 0.4732242212845729, 0.46789654126534097, 0.45971823380543636, 0.459198004924334, 0.4578235351122343, 0.45150824647683363, 0.4526163834791917, 0.44165961604851944, 0.44498730576955353, 0.4484166117814871, 0.4551098520939167, 0.4462677767643562, 0.4405572162224696, 0.4494261251046107, 0.44054122475477364, 0.4435463167153872, 0.4405635884174934, 0.4424138243381794, 0.4378276389378768, 0.44291285826609683, 0.4417843873684223, 0.44429404735565187, 0.4738652678636404, 0.4733197725736178, 0.4861888587474823, 0.4634119790333968, 0.45636252623337964, 0.4620646412555988, 0.4630438772531656, 0.4605173619893881, 0.45829875194109404, 0.44601716353343085, 0.44660393779094404, 0.45092622683598443, 0.443128528044774, 0.4582628107987917, 0.45971633470975437, 0.4567227267302, 0.46350575593801646, 0.4608558741899637, 0.45466679907762086, 0.44988934489396903, 0.45017829583241387, 0.4502838474053603, 0.4529503405094147, 0.4554544448852539, 0.4483715272866763, 0.4428384780883789, 0.440097202704503, 0.4414688330430251, 0.43909516563782325, 0.43354901808958785, 0.4459256722376897, 0.4396266941840832, 0.44330410728087793, 0.4313758680453667, 0.4433531628205226, 0.46205048973743734, 0.4386434408334585, 0.4282728286889883, 0.43366410915668197, 0.43157330063673166, 0.4460720465733455, 0.42952033969072195, 0.43127444799129777, 0.4336574852466583, 0.4403018364539513, 0.4897451359492082, 0.4746906239252824, 0.46119944820037256, 0.4598890620928544, 0.4496460914611816, 0.45084150571089526, 0.4523039634411152, 0.44591378432053785, 0.4396845028950618, 0.43709466411517217, 0.44086134571295515, 0.44304096011015087, 0.4465093805239751, 0.4410027242623843, 0.4352069304539607, 0.4338506680268508, 0.42820232052069446, 0.44200316530007583, 0.4771202876017644, 0.4693432995906243, 0.441590003325389, 0.4455451433475201, 0.4524235289830428]
val_losses = [0.6049017439717832, 0.519922963950945, 0.5063159608322642, 0.5085233307403066, 0.5045329539672189, 0.4983352357926576, 0.49518869104592694, 0.5047840255758037, 0.49491770889448083, 0.49265258078989776, 0.5029927090458248, 0.5024358254411946, 0.4910455436810203, 0.5015795502973639, 0.5261653985666193, 0.4884042986061262, 0.49137787585673126, 0.48826932388803235, 0.4965472325034764, 0.4868599111619203, 0.48922446370124817, 0.4913356174593386, 0.48172003549078235, 0.4794893394345823, 0.49809591666511865, 0.48947404260220734, 0.49828459128089575, 0.4892854366613471, 0.48987059619115747, 0.49576274856277136, 0.4842828525149304, 0.4951716933561408, 0.4884427643340567, 0.4867242885672528, 0.5139863154162532, 0.49195605516433716, 0.5395539091980975, 0.49192993278088776, 0.4803786005662835, 0.49699066903280176, 0.49830378527226654, 0.532919695843821, 0.4799793181212052, 0.581059463646101, 0.5050228587959124, 0.4750261812106423, 0.48037787494452105, 0.5132542926332225, 0.504413419443628, 0.47267863154411316, 0.543215732211652, 0.4710790683393893, 0.4672018159990725, 0.46574397320332733, 0.4574091939822487, 0.49074219879896747, 0.5439517588719077, 0.4751303934532663, 0.47275105248326843, 0.4651272750419119, 0.5600734275320302, 0.45826707326847577, 0.46377301734426746, 0.44939050207967346, 0.4712134716303452, 0.4794651088507279, 0.4563754537831182, 0.4493063273637191, 0.4434604567030202, 0.44416585305462714, 0.477234053870906, 0.4992089854634326, 0.5142686367034912, 0.5001839477082958, 0.47052187893701636, 0.4659275049748628, 0.45217917276465375, 0.4518412831036941, 0.4492315973924554, 0.44511638646540436, 0.45517218890397443, 0.46252815749334253, 0.47913806723511737, 0.5032636095648226, 0.5073019136553225, 0.47217105652975, 0.49718161899110547, 0.4875262379646301, 0.4782433224760968, 0.47855283125587134, 0.47860520948534424, 0.4719513175280198, 0.5002991310928179, 0.4702229292496391, 0.47057200773902563, 0.4625303071478139, 0.4674557291943094, 0.4633916551652162, 0.4670858499796494, 0.47241005560626154, 0.4573242560676906, 0.5029502575812133, 0.4654967901499375, 0.450431482947391, 0.5030885261038075, 0.4754903303540271, 0.47645951353985333, 0.47498085706130316, 0.46961601013722626, 0.471826266983281, 0.47486318323923193, 0.4980042732280234, 0.5005560400693313, 0.4710543052009914, 0.47439588152843976, 0.4942555440508801, 0.4613861247249272, 0.47357105560924695, 0.44606459270352905, 0.46032721840817, 0.46754043905631354, 0.4643697246261265, 0.46966151698775915, 0.4605106646599977, 0.45222972009492957, 0.47115836972775665, 0.45358671831048053, 0.4493124044459799, 0.45354070222896076, 0.44627665695936786, 0.4716722757919975, 0.4671963518080504, 0.47021911973538605, 0.4649030592130578, 0.5134015407251276, 0.5363554604675459, 0.4971503822699837, 0.4719108161718949, 0.4619701414004616, 0.47602347057798633, 0.47660888277966046, 0.46921236100404157, 0.4711660107840662, 0.4784838958926823, 0.4754891019800435, 0.466800666373709, 0.4769707633101422, 0.4808281439801921, 0.4810719943564871, 0.5067507818989132, 0.46326808825783106, 0.44582978927570843, 0.4352203361366106, 0.5505002529724784, 0.4792952071065488, 0.4973919663740241, 0.4902438625045445, 0.47875266489775287, 0.48141790343367535, 0.4966495244399361, 0.5115012552427209, 0.46897654559301294, 0.4675346574057703, 0.5009068665297135, 0.4779612512692161, 0.4836664834748144, 0.5012441601442255, 0.5273145022599594, 0.47296197777209076, 0.48241324528403906, 0.46288868655329163, 0.49091466743013135, 0.4642895460128784, 0.4605865634006003, 0.45497933807580365, 0.4487302355144335, 0.4477075079213018, 0.47016734532687976, 0.4582688821398694, 0.44649273804996326, 0.4741616456404976, 0.4379755323347838, 0.4475618419439896, 0.42838567884072015, 0.425501665343409, 0.44385610196901404, 0.42818985166757, 0.4713211733361949, 0.4537075330381808, 0.4440037115760472, 0.4584129038064376, 0.49501699338788574, 0.43996537509171857, 0.4811550015988557, 0.46661708665930707, 0.4974943153236223, 0.45892041273739026, 0.5201382753641709, 0.529518266086993, 0.4877455908319224, 0.4784256453099458, 0.5057571504427039, 0.5015422377897345, 0.47463466550992883, 0.4720427406870801, 0.4689993171588234, 0.48109147730080976, 0.4703812702842381, 0.4582373279592265, 0.45791660054870276, 0.4635118427483932, 0.4632690186085908, 0.4586738257304482, 0.4750387746354808, 0.46648879932320636, 0.4648415031640426, 0.45608691028926684, 0.45385881999264593, 0.45904346393502277, 0.46575055174205615, 0.46802679352138354, 0.4571467638015747, 0.46955855255541595, 0.4557063773922298, 0.4579011292561241, 0.4465570294338724, 0.4611761634764464, 0.4482757332532302, 0.457231184710627, 0.5006470032360243, 0.4526809790860052, 0.48649481327637384, 0.45085086381953693, 0.5320408888485121, 0.46685808637867804, 0.4664837070133375, 0.4735993639282558, 0.4621138974376347, 0.4518204460973325, 0.45979464183682983, 0.4572184824425241, 0.4478760335756385, 0.45333287638166675, 0.44803323175596155, 0.4466447907945384, 0.4597794296948806, 0.4593146132386249, 0.44932734966278076, 0.46683628792348114, 0.46561069851336273, 0.45138800921647443, 0.4539560364640277, 0.45352318235065625, 0.45240272257639014, 0.4670010338658872, 0.4549903532733088, 0.4514758703501328, 0.4423616826534271, 0.44446199873219366, 0.4546135391878045, 0.4652615954046664, 0.442236118990442, 0.4420281376527703, 0.4418731370697851, 0.4384632136510766, 0.43328633515731146, 0.48499803698581195, 0.4511923232804174, 0.44015153724214306, 0.44097505056339764, 0.43316013527953107, 0.4353576535763948, 0.44699741705604223, 0.4424125150493953, 0.4374986653742583, 0.42680347224940424, 0.4863245163274848, 0.46368701043336286, 0.4602175562278084, 0.44978447971136676, 0.4508146604766016, 0.44751940343690955, 0.4483949477257936, 0.44581311293270276, 0.4495025069817253, 0.44082103604855744, 0.44496722454610077, 0.44856462271317193, 0.4411946301874907, 0.4381773083106331, 0.441381793955098, 0.44421220603196515, 0.4362629302169966, 0.4374658271022465, 0.4465095465597899, 0.48726101154866425, 0.4508731598439424, 0.44463754088982294, 0.4398050204567287, 0.4512647597686104]
plt.figure(figsize=(20, 6))
plt.plot(training_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss for experiment 2")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```
