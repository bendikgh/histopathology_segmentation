---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
import torch
import albumentations as A
import matplotlib.pyplot as plt

from glob import glob
from monai.data import DataLoader
from monai.losses import DiceLoss
from monai.metrics import DiceMetric
from monai.transforms import Compose, AsDiscrete

from torch.optim import Adam

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import TissueDataset, CellTissueDataset
from src.train_utils import train
```

```{python}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"

train_seg_files = glob(os.path.join(data_path, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_path, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_path, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_path, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_path, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_path, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
train_tissue_seg_files = glob(os.path.join(data_path, "annotations/train/tissue/*"))
train_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_tissue_seg_files
]
train_tissue_image_files = [
    os.path.join(data_path, "images/train/tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]
train_tissue_predicted = [
    os.path.join(data_path, "annotations/train/pred_tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]


val_tissue_seg_files = glob(os.path.join(data_path, "annotations/val/tissue/*"))
val_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_tissue_seg_files
]
val_tissue_image_files = [
    os.path.join(data_path, "images/val/tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]
val_tissue_predicted = [
    os.path.join(data_path, "annotations/val/pred_tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]



test_tissue_seg_files = glob(os.path.join(data_path, "annotations/test/tissue/*"))
test_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_tissue_seg_files
]
test_tissue_image_files = [
    os.path.join(data_path, "images/test/tissue", image_number + ".jpg")
    for image_number in test_tissue_image_numbers
]
test_tissue_predicted = [
    os.path.join(data_path, "annotations/test/pred_tissue", image_number + ".jpg")
    for image_number in test_tissue_image_numbers
]

def calculate_dice_score(dataloader, model, device): 

    dice_metric = DiceMetric(include_background=True, reduction="mean")
    post_pred = Compose([AsDiscrete(argmax=True, dim=1, to_onehot=3)])

    model.eval()
    for (images, masks) in dataloader: 
        images, masks = images.to(device), masks.to(device)
        with torch.no_grad(): 
            outputs = model(images)
        outputs = post_pred(outputs)
        dice_metric(outputs, masks)

    dice_score = dice_metric.aggregate().item()
    dice_metric.reset()

    return dice_score


transforms = A.Compose([
    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # You can adjust the blur limit
    A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),  # Adjust var_limit for noise intensity
    A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
], additional_targets = {
    "mask1": "mask", 
    "mask2": "mask"
}
)
```

```{python}

# dataloader for tissue-model
train_tissue_dataset = TissueDataset(image_files=train_tissue_image_files, seg_files=train_tissue_seg_files, transform=transforms)
val_tissue_dataset = TissueDataset(image_files=val_tissue_image_files, seg_files=val_tissue_seg_files)
test_tissue_dataset = TissueDataset(image_files=test_tissue_image_files, seg_files=test_tissue_seg_files)

train_tissue_dataloader = DataLoader(dataset=train_tissue_dataset, batch_size=2, drop_last=True)
val_tissue_dataloader = DataLoader(dataset=val_tissue_dataset)
test_tissue_dataloader = DataLoader(dataset=test_tissue_dataset)
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model_tissue = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_tissue.to(device)

model_tissue.load_state_dict(torch.load("outputs/models/2023-12-07_22-49-54_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)
print("lr=0.0001, dropout=0.3, backbone=resnet50 (Baseline)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")


model_tissue.load_state_dict(torch.load("outputs/models/2023-12-08_22-19-39_deeplabv3plus_tissue_branch_lr-1e-05_dropout-0.1_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)
print("lr=0.0005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

model_tissue.load_state_dict(torch.load("outputs/models/2023-12-09_13-56-10_deeplabv3plus_tissue_branch_lr-0.0001_dropout-0.5_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)
print("lr=0.00005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
```

```{python}
training_losses_01_e5 = [0.6760178451240063, 0.6283668023347855, 0.6189012670516968, 0.6056847624480725, 0.5988180582225323, 0.5894803062081337, 0.5889860284328461, 0.5852472296357155, 0.5754608425498009, 0.5733441370725632, 0.5669056445360183, 0.5679075828194619, 0.5644334869086742, 0.5599455334246158, 0.5581196920573711, 0.5626593473553657, 0.5567940774559975, 0.5498311734199524, 0.5429686622321606, 0.5468052105605602, 0.5433215552568436, 0.5429336677491665, 0.5432416704297066, 0.5382907401025295, 0.5349717877805233, 0.534958818256855, 0.5346143671870232, 0.5293791945278644, 0.5247422239184379, 0.5262467519938946, 0.523743993639946, 0.5212730453908443, 0.5284235242009163, 0.5218965509533882, 0.5182860699295998, 0.5149880431592464, 0.5160851773619651, 0.5138096189498902, 0.5099452608823776, 0.5120469097793102, 0.5122914385795593, 0.503730402737856, 0.5101686152815819, 0.5027919359505176, 0.4988692307472229, 0.5013318420946598, 0.5012523183971643, 0.4976007981598377, 0.4994832041859627, 0.4896462225168943, 0.4958011893928051, 0.4942212633788586, 0.4954705898463726, 0.4979757995903492, 0.4924667826294899, 0.4846217975020409, 0.4936311114579439, 0.48434083715081216, 0.4846542318165302, 0.48247533150017263, 0.48261797726154326, 0.48782682470977307, 0.4809047397226095, 0.48206855557858946, 0.4811512811481953, 0.48181213609874246, 0.480568528175354, 0.4736129146814346, 0.47797522753477095, 0.477864408493042, 0.4759064969420433, 0.47800201296806333, 0.4785067146271467, 0.4767740681767464, 0.46719554051756856, 0.4640746007859707, 0.46968367740511896, 0.46644951701164244, 0.4661111431568861, 0.463744380325079, 0.4675267045199871, 0.4639004284888506, 0.45929656326770785, 0.4600951910763979, 0.4573476668447256, 0.45803395271301267, 0.4596943213045597, 0.4598559562116861, 0.45568885989487173, 0.4603027317672968, 0.4521827052533627, 0.4539269534498453, 0.4544250251352787, 0.4531278321146965, 0.45195868879556655, 0.45218412674963476, 0.4463946535438299, 0.45048472471535206, 0.4493952213972807, 0.4429223261028528, 0.44327609352767466, 0.44706981055438516, 0.44250812388956545, 0.4450576370954514, 0.4404706683754921, 0.44335350915789606, 0.4379950001090765, 0.4388030954450369, 0.43949663050472737, 0.4453110512346029, 0.44211589694023135, 0.4345696340501308, 0.43635180689394476, 0.43380490750074385, 0.4364210842549801, 0.4315920700132847, 0.43095513589680196, 0.4343961954861879, 0.4320741707831621, 0.43156116977334025, 0.4302061618864536, 0.42619125977158545, 0.42819126456975937, 0.43091967560350897, 0.42736244671046736, 0.43276346802711485, 0.42662077985703944, 0.4269057808071375, 0.42469360619783403, 0.421780329272151, 0.4259609819948673, 0.42286244690418245, 0.4211556640267372, 0.4188082570582628, 0.4214020937681198, 0.42150381945073606, 0.42103091441094875, 0.42346545033156874, 0.4206902128458023, 0.41912030838429926, 0.41777819372713565, 0.4200278735905886, 0.4170443057268858, 0.416195427775383, 0.4162632369250059, 0.42007380329072475, 0.4144430811703205, 0.41456301264464857, 0.41365242049098017, 0.4098920428007841, 0.41064439944922926, 0.41333047606050966, 0.4131052170693874, 0.40651904568076136, 0.4105176051706076, 0.4076971685141325, 0.4082929078489542, 0.40735443904995916, 0.40891775108873846, 0.4120578733831644, 0.40462806992232797, 0.4047673360258341, 0.4036571519076824, 0.40751058541238305, 0.40646923303604127, 0.40407378785312176, 0.40432945907115936, 0.40053551822900774, 0.4054542544484139, 0.40735264025628565, 0.3987497514486313, 0.4030453479290009, 0.4010337220132351, 0.4024202033132315, 0.4054672732949257, 0.4049015253782272, 0.40216673880815507, 0.4016965028643608, 0.39920970059931277, 0.3965177556872368, 0.3993443933874369, 0.3965770542621613, 0.39684692561626433, 0.39667854182422163, 0.39373133040964603, 0.39701855957508086, 0.3942671808600426, 0.3910766465216875, 0.3949131850153208, 0.3959275697171688, 0.39606350563466547, 0.39190308935940266, 0.39185296326875685, 0.38950066491961477, 0.3896936234086752, 0.3881589944660664, 0.38804771631956103, 0.3927041612565517, 0.3892855293303728, 0.3920840292423964, 0.3926057770103216, 0.3888204777240753, 0.3930870693922043, 0.38659932896494864, 0.38544076032936575, 0.3889122546464205, 0.3846548317372799, 0.39133773345500233, 0.38505752123892306, 0.38624959453940394, 0.3917762690782547, 0.38537910625338556, 0.3852053686231375, 0.38347756542265415, 0.3837549510598183, 0.38494287136942146, 0.38644103981554506, 0.3809550625085831, 0.38092911913990973, 0.3864098920673132, 0.38487601578235625, 0.38556373573839664, 0.38235287815332414, 0.3825975998491049, 0.38093394711613654, 0.38030407853424547, 0.3832602445781231, 0.38099320642650125, 0.3772708899527788, 0.3800229436904192, 0.37914230838418006, 0.37635059133172033, 0.37528641857206824, 0.3795157435536385, 0.3767896796017885, 0.37855854593217375, 0.37208116695284843, 0.3740115124732256, 0.37630096659064294, 0.3785699825361371, 0.3722706422954798, 0.3755905408412218, 0.3801930178701878, 0.3769207614660263, 0.37615900628268717, 0.3714590096846223, 0.3703236036002636, 0.3698807402327657, 0.3701217220723629, 0.36882312305271625, 0.3725447418540716, 0.37157544583082197, 0.36834049224853516, 0.3705364073067903, 0.3715913374722004, 0.3677611146122217, 0.3707184560596943, 0.3709777706861496, 0.3698690494894981, 0.37038573414087295, 0.3693812830001116, 0.37200513780117034, 0.3668948321789503, 0.3712270656600595, 0.3655724070221186, 0.3658788716048002, 0.36933613657951353, 0.36767830736935136, 0.36268393486738204, 0.3655410803854465, 0.3620913379266858, 0.36914046175777915, 0.3671708256751299, 0.3648065435141325, 0.36008495796471834, 0.3655753517895937, 0.3656556211784482, 0.3638717646151781, 0.3620382358878851, 0.3636048141866922, 0.3606983757391572, 0.36150302611291407, 0.35911358922719955, 0.367096503674984, 0.3616193337738514, 0.3630022720992565, 0.35861676938831805, 0.35747863702476024, 0.3607505879551172, 0.3633171758055687, 0.36089465126395226, 0.3652922338247299, 0.35727896109223367, 0.35885349549353124, 0.359466852247715, 0.35832229871302845, 0.3576656820997596, 0.35890561655163766, 0.36213452711701394, 0.3555854331701994]
training_losses_03_e4 = [0.6377815628051757, 0.6059734432399273, 0.590821613818407, 0.5712891797721386, 0.5712862102687359, 0.5654898694157601, 0.565285691767931, 0.563297304213047, 0.553656240850687, 0.5508803363144398, 0.5523784719407558, 0.5466656649112701, 0.544693968296051, 0.5420596651732922, 0.5440559732913971, 0.544414628893137, 0.536523692458868, 0.5317785897105932, 0.5348353417217732, 0.5263301396369934, 0.5271237802505493, 0.5266878898441791, 0.5305304397642613, 0.5195005333423615, 0.5241142293065786, 0.5331965786218643, 0.5153780496120453, 0.5193031169474125, 0.5184791991114617, 0.5155639296770096, 0.5096967269480228, 0.5184535540640354, 0.5092710943520069, 0.5106850631535054, 0.5147987473011016, 0.502492643892765, 0.502475102469325, 0.505776246637106, 0.5099077728390694, 0.4991920728236437, 0.5130861069262028, 0.5040742922574282, 0.501481217443943, 0.4967557418346405, 0.5007512950897217, 0.4890888991206884, 0.4999270425736904, 0.4972155563533306, 0.49535338655114175, 0.4981259298324585, 0.4916591188311577, 0.49952440448105334, 0.4927095017582178, 0.4895165640860796, 0.5002042967826128, 0.4946031378209591, 0.49366553671658037, 0.49171479992568495, 0.49091118179261684, 0.49453128799796103, 0.4922934745252132, 0.4855763327330351, 0.4972301494330168, 0.4893512385338545, 0.48536124639213085, 0.4898102250695229, 0.5204466248303652, 0.4906792064756155, 0.4837149415910244, 0.4790689507126808, 0.4821527437865734, 0.48662997588515283, 0.48564422748982905, 0.4776880444586277, 0.4841087339818478, 0.4877268972247839, 0.4846574659645557, 0.4815856602787971, 0.5012881903350354, 0.48911954239010813, 0.4863907770067453, 0.4758448687940836, 0.4727740943431854, 0.47661700904369353, 0.47588325902819634, 0.49999722369015215, 0.4777309760451317, 0.4738358999043703, 0.4694503654539585, 0.46841491959989073, 0.4743210136890411, 0.4712062932550907, 0.4869456046074629, 0.4768123444914818, 0.4674240829050541, 0.4626352223008871, 0.4644208028912544, 0.47369625508785246, 0.48407292149960995, 0.4667682637274265, 0.48174102425575255, 0.4663602022081614, 0.45830663964152335, 0.46022829741239546, 0.4577199594676495, 0.4890021587908268, 0.48227440409362315, 0.4566120444238186, 0.462772209495306, 0.45648628011345865, 0.45896361574530603, 0.46128088630735875, 0.48924243047833443, 0.4605031944811344, 0.46398802429437636, 0.45681733570992944, 0.4623651577532291, 0.4564772615581751, 0.46063005343079566, 0.4579595246911049, 0.457303713709116, 0.4589031147956848, 0.45208398550748824, 0.4589352695643902, 0.455834823846817, 0.4582113669067621, 0.4660412539541721, 0.4519029694795609, 0.44859266459941866, 0.45302178293466566, 0.4574365516752005, 0.4656405449658632, 0.46336465403437616, 0.45308669328689577, 0.4566919633001089, 0.44667860850691793, 0.4598775514960289, 0.444922082349658, 0.45218870997428895, 0.4477448383718729, 0.4460842790454626, 0.4488857600092888, 0.44475452065467835, 0.45035070419311524, 0.44726663500070574, 0.4451882902532816, 0.44113002605736257, 0.4472432482987642, 0.4370318948477507, 0.4343709796667099, 0.4375425408780575, 0.4711594747006893, 0.47554585583508013, 0.45762021109461787, 0.45836350798606873, 0.4564807651937008, 0.45362245179712773, 0.4510880170762539, 0.4597684272378683, 0.45416865050792693, 0.4560093470662832, 0.4510184449702501, 0.44799619674682617, 0.4506046833097935, 0.4389206253737211, 0.4359822018444538, 0.43806075543165207, 0.44403731875121594, 0.45282613500952723, 0.4369612926244736, 0.45598123252391815, 0.4472072067856789, 0.42943765558302405, 0.42458994016051294, 0.4312879889458418, 0.43254250831902025, 0.4382817866653204, 0.4628045567125082, 0.5018086359277367, 0.4981046371161938, 0.5684782381355763, 0.5133485133945942, 0.5316275380551815, 0.5170635338872671, 0.4914216161519289, 0.4756293100491166, 0.4901875049620867, 0.4601170665025711, 0.45685355946421624, 0.4956151109933853, 0.4792950823158026, 0.47302985161542893, 0.45513567466288807, 0.472862488143146, 0.4639650437235832, 0.44687065087258815, 0.4896829080581665, 0.47778374902904036, 0.4566824364289641, 0.44020837277173996, 0.4299636426195502, 0.44303503666073085, 0.4799391891434789, 0.5364043817669153, 0.49201217357069255, 0.4604913033545017, 0.4946860785037279, 0.4583289762958884, 0.4390909633040428, 0.4453952471911907, 0.466344228759408, 0.5723239415884018, 0.5686424069479108, 0.5841795209050179, 0.5682730854302644, 0.5343514594435692, 0.5114027810096741, 0.4861444701999426, 0.47973911963403226, 0.47359894089400767, 0.45603138230741025, 0.49194451458752153, 0.46178891804069283, 0.4585450867563486, 0.42387934602797034, 0.45617425840348, 0.5194702396169305, 0.47097007650882006, 0.4605268250033259, 0.4420962827652693, 0.49203965947031975, 0.4521082966774702, 0.42925920311361554, 0.4447686482965946, 0.46328412659466267, 0.4823494533449411, 0.4578806775435805, 0.5105443441867829, 0.44794262006878854, 0.43863685585558415, 0.47803151302039626, 0.5590668387711049, 0.5596745593473316, 0.5466940335184336, 0.5369085131958127, 0.524919743090868, 0.4966980609670281, 0.4902417477965355, 0.47161789298057555, 0.4575433617830276, 0.4577233768999577, 0.523239947669208, 0.4800522403046489, 0.5065815112367272, 0.5455203757062554, 0.4975975930690765, 0.46850264087319377, 0.4734596624225378, 0.45230991318821906, 0.4840252172574401, 0.4575458180904388, 0.4671538146585226, 0.44754450883716346, 0.43294791944324973, 0.4433683126419783, 0.45786334715783594, 0.43300708681344985, 0.4323624530434608, 0.4205475926399231, 0.44029337625950576, 0.4333029257133603, 0.5088842822983861, 0.4649844725430012, 0.4697112184762955, 0.45822789646685125, 0.4275662387162447, 0.4354124150425196, 0.4584627451747656, 0.496833098679781, 0.4570057071745396, 0.45537380397319793, 0.43207717310637234, 0.49333218462765216, 0.4929084214568138, 0.4574182102829218, 0.47364044781774284, 0.48320292714983226, 0.5742028927057982, 0.5523052585870027, 0.520981904938817, 0.47635960578918457, 0.4979624949395657, 0.4965540799126029, 0.4679086600244045, 0.5255564369261265, 0.5288546577468515, 0.5630260391533375, 0.5541914678364992, 0.5445256062597036, 0.5366250418871641]
training_losses_05_e4 = [0.6533284509181976, 0.6107789556682109, 0.5983250005543232, 0.587052844017744, 0.5814013662934303, 0.5723004989326, 0.5763407631218433, 0.5733415161073208, 0.5643847233057022, 0.5633981041610241, 0.5571352070569993, 0.5570451828837395, 0.560302102714777, 0.5571731662750244, 0.5529105231165886, 0.5480043116211891, 0.5478477357327938, 0.5450358779728413, 0.539754729270935, 0.54738603875041, 0.5394885279238224, 0.5366729421913624, 0.5338123093545437, 0.5477326491475105, 0.5271148823201657, 0.527990717291832, 0.5256101086735725, 0.5334628643095494, 0.5264496989548206, 0.5203805390000343, 0.5306262376904488, 0.5249956068396568, 0.5214411763846875, 0.5247334323078394, 0.5217962907999754, 0.5168427859991789, 0.5046518974006176, 0.5183774910122156, 0.5080645595490932, 0.5143847344070673, 0.5160705065727234, 0.5081856228411198, 0.5208098754286766, 0.5174749591201544, 0.5129893745481968, 0.5107467602193355, 0.5187401503324509, 0.5055638844519854, 0.5045673821866512, 0.5070112942159176, 0.5144325292110443, 0.4999060595780611, 0.5110806592553854, 0.5016362275928259, 0.5021925891935826, 0.5007676193863153, 0.5036693467199802, 0.5017408800125122, 0.5068646934628487, 0.5012179841846227, 0.509585408270359, 0.4951365856826305, 0.4980676257610321, 0.49193301424384117, 0.4925361534953117, 0.5114632192254066, 0.5060778574645519, 0.4938987404108047, 0.5066115505248309, 0.5001183652877808, 0.49559985995292666, 0.48814248487353323, 0.48894992731511594, 0.489824166893959, 0.4877505496889353, 0.4943033031374216, 0.4806549758464098, 0.4829236775636673, 0.4865170009434223, 0.48431423790752887, 0.49897076837718485, 0.4927697066962719, 0.4991640555858612, 0.49350399650633336, 0.48456523261964324, 0.4906422944366932, 0.48055190704762935, 0.4922700433433056, 0.48087099350988866, 0.4789573273807764, 0.48585671581327916, 0.487334490865469, 0.496955236941576, 0.48303329914808274, 0.48756315670907496, 0.48408065393567085, 0.48103328347206115, 0.4750734702497721, 0.4833320944011211, 0.48220333650708197, 0.47569800809025764, 0.49214099258184435, 0.4795524401217699, 0.4812269984185696, 0.47670592680573465, 0.4754019956290722, 0.4780159068107605, 0.4737160028517246, 0.46982575453817843, 0.47969167307019234, 0.49175479002296923, 0.4823537730425596, 0.47876307010650637, 0.47542561881244183, 0.4784137148410082, 0.4735044613480568, 0.48696004047989844, 0.4748636135458946, 0.4737693653255701, 0.473209994956851, 0.4664189191162586, 0.46409889571368695, 0.46494069069623944, 0.47362754538655283, 0.47173741288483145, 0.4637825168669224, 0.465793589502573, 0.46733760327100754, 0.4638973194360733, 0.4659607424587011, 0.4625399924814701, 0.4669642543047667, 0.46444686748087405, 0.46271333664655684, 0.4657075674831867, 0.4776114442944527, 0.47540762327611447, 0.46432208083570004, 0.45735677249729634, 0.4541984904557467, 0.4623390534520149, 0.4672757039219141, 0.4557393793016672, 0.4566070703417063, 0.45072941586375237, 0.45894741274416445, 0.4611425144970417, 0.4731499388813972, 0.4713783143460751, 0.4653513895720243, 0.4630346379429102, 0.4686661113798618, 0.46760082960128785, 0.45731890715658663, 0.4715490463376045, 0.4680357578396797, 0.45796477630734445, 0.4508568187057972, 0.4515632738918066, 0.4654892391711474, 0.45759457141160964, 0.4524922359734774, 0.45443109177052976, 0.4463064617663622, 0.4444242064654827, 0.4478015860915184, 0.4511886668205261, 0.4502785383164883, 0.449346669614315, 0.45221192456781867, 0.45556355960667133, 0.45691175691783426, 0.4438472856581211, 0.45059146113693715, 0.45278302557766437, 0.44309232085943223, 0.4379144664853811, 0.46106124244630337, 0.4519511199742556, 0.4495412157475948]

plt.figure(figsize=(20, 6))
plt.plot(training_losses_01_e5[:100], label="Dropout: 01 LR: e-5")
plt.plot(training_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(training_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.title("Training Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

```{python}
val_losses_01_e5 = [0.6244556057627184, 0.6068543926642759, 0.5836414179227648, 0.578305623392119, 0.574001145406361, 0.5774814129745873, 0.5570091772688567, 0.5653928839159708, 0.5553600301925283, 0.6053782518762741, 0.5715386119202106, 0.5856596598007383, 0.5603360112783683, 0.5654478241709897, 0.5541492770188046, 0.5293215407724798, 0.5311742435841664, 0.532211706259825, 0.5288212706137748, 0.5434330958519539, 0.5336875647959047, 0.539018380924733, 0.5466139595003894, 0.5482473168929998, 0.5414841596009957, 0.5389758710661073, 0.5333166916440003, 0.5327825968282937, 0.5420707279313219, 0.5496890921227253, 0.5468578896600834, 0.5431916661506152, 0.5558491018566772, 0.5223662237616351, 0.5501358964799965, 0.5306240185333865, 0.5377021813697188, 0.5620619041206193, 0.5282722342840946, 0.5475936738679009, 0.5331507644949168, 0.5615825931521228, 0.5350360397222268, 0.5495010355528254, 0.535374885601719, 0.5402758864373186, 0.5543221561578069, 0.5771770689391742, 0.5447853661149088, 0.5434787832472446, 0.5856820377555206, 0.5463606128944968, 0.5597499240271366, 0.5637402845560199, 0.5241179933948238, 0.5275556304811562, 0.5384256653759601, 0.5595673269381488, 0.5332390309250268, 0.5661697159283352, 0.5798506139621248, 0.5658703178819948, 0.552201085064533, 0.5817285447660154, 0.5803612563079291, 0.6058828287968671, 0.5833925638538208, 0.60335482145748, 0.5814266726918464, 0.572388949511695, 0.5788875396234275, 0.5946822047886187, 0.6171240495504254, 0.5947765686216145, 0.5779010673073957, 0.5995470975002233, 0.599196190164037, 0.5679141770314126, 0.607246259812021, 0.5509415708319114, 0.5804716522676231, 0.6109614063353435, 0.571700506184223, 0.5890013917084158, 0.6028810907019316, 0.619321756010508, 0.6031911564569403, 0.6204928507770064, 0.5978120153185225, 0.5876486839821738, 0.6207669418658653, 0.6071919117965837, 0.5993977469684434, 0.6090380729985063, 0.6253451508109586, 0.5895560638312876, 0.6080493875881181, 0.5824666903184278, 0.5972056515025397, 0.5780795667945904, 0.57181809276995, 0.6217459098701059, 0.5986530362036977, 0.5554723976737391, 0.5905991830747493, 0.5912474428650236, 0.6016366457852134, 0.6049039221375528, 0.6094511655995446, 0.5997727147854157, 0.5659591009582046, 0.5651850785217146, 0.6060574942261633, 0.594832526941369, 0.5974403882983828, 0.5720995128372289, 0.6055036919177884, 0.5614880160258634, 0.6115396473094494, 0.6155472293387364, 0.6010559585190167, 0.6146966177616676, 0.6068375489137469, 0.6096917292932524, 0.6358873176313665, 0.6005944942470884, 0.6034697814144357, 0.6248788167960453, 0.6361225807899524, 0.6005496713366821, 0.6161076222022954, 0.6130588217808383, 0.6199545892920807, 0.6025726309005361, 0.5955086500540266, 0.5933389711554033, 0.5951087403036383, 0.5986786590222894, 0.5666915638385898, 0.566533559865325, 0.5880188201248211, 0.5957497743359448, 0.5772432745808233, 0.600278080379876, 0.598058203928662, 0.6066851409247321, 0.6300064327507994, 0.6094717774948064, 0.5803119751223682, 0.6185155713210141, 0.6102335875867492, 0.6208151317860958, 0.5973182438063795, 0.6186987374820848, 0.6113723219902574, 0.6292862955236087, 0.6069205985642481, 0.61778466985391, 0.5915997586328617, 0.5912680158214848, 0.6136958836203944, 0.5901877612528139, 0.6093091429585088, 0.6061998963573553, 0.591072333555152, 0.6196955383694085, 0.6162960503223168, 0.6247392266336149, 0.623413613134057, 0.6280971160770332, 0.6435235887765884, 0.6022234428538024, 0.6070670844429601, 0.5895858428774089, 0.6215176177720954, 0.6056329664522714, 0.612533696158959, 0.6187673653781849, 0.5942484395999978, 0.6284226364027845, 0.6130587904557695, 0.639423941608763, 0.6452841058264683, 0.6532735380813153, 0.6160226438167321, 0.6216698357441129, 0.6305188426788706, 0.6101577149255433, 0.6209599804269136, 0.6119323168357793, 0.6226474664507121, 0.6261174338359903, 0.661318222754193, 0.6288469818821789, 0.6178254367661302, 0.6335285609438471, 0.6801976894375181, 0.6504761175300083, 0.6546624433385194, 0.6389694057241844, 0.6235136731262625, 0.6231259494802378, 0.6327320180670188, 0.6264802182677889, 0.6228264891100626, 0.6313904852327639, 0.5985393027101991, 0.6610489854568711, 0.6602889667027187, 0.6447741002061941, 0.6272193822112396, 0.6424184522054491, 0.6646083621648107, 0.6636686461032743, 0.6579224464014499, 0.6478829744414691, 0.6543841440312184, 0.6421096372778399, 0.6473481619227541, 0.644784094860954, 0.6350058728325976, 0.6192762580883764, 0.641334646592175, 0.6565081190018758, 0.6293256704824685, 0.6840014077016037, 0.6533851662691492, 0.6516758055582533, 0.6367086504932737, 0.6148596270748611, 0.6320591079492639, 0.632389672916301, 0.6230556397107396, 0.6382430851677038, 0.6596680020328856, 0.6456712171109054, 0.6507371561805697, 0.623650440769474, 0.6479321646429327, 0.6515817096198562, 0.6556209800017141, 0.6166788870400756, 0.6472057270525146, 0.6328647132337528, 0.6225067967341629, 0.6373488696387214, 0.6223078368734705, 0.6253658489589273, 0.6502868362913167, 0.6431251552200665, 0.6173194653361384, 0.6540969765751902, 0.6529228934551564, 0.6624235252684357, 0.6224618158201232, 0.6229130809542036, 0.6286953450557312, 0.6149921052864868, 0.632713118520477, 0.6173923564530963, 0.6218166820472106, 0.606447197769943, 0.6111651528492315, 0.6412309639862854, 0.6354130366749137, 0.6323037230185349, 0.6155955725918604, 0.6377525944126784, 0.6095452901846083, 0.6265355781482084, 0.6237869089754828, 0.6090853000082395, 0.6278835695753567, 0.643819215687087, 0.6515691373270737, 0.6360713464282725, 0.6158879071548004, 0.6230736827328257, 0.6281943505045271, 0.6419019528331548, 0.6141437566669209, 0.6110342924829817, 0.6178026062293644, 0.6141965362059809, 0.6137233933495072, 0.656990912137893, 0.6156815463850397, 0.6243536181197278, 0.646428702562286, 0.6412770669145959, 0.6318333540519658, 0.6229752243072743, 0.6665298987341871, 0.6652956856584625, 0.6389245400341214, 0.6470611541738893, 0.6423324753333183, 0.6378775122609451, 0.6596223327134104, 0.6343806608695618]
val_losses_03_e4 = [0.6756902813476368, 0.6447698587048662, 0.5784846375675967, 0.5593729689173454, 0.6238896796738145, 0.5521230777032184, 0.5721430643631594, 0.5651514591091741, 0.577448274206071, 0.5514343342859379, 0.618131708054647, 0.6360507671632906, 0.5925329078505509, 0.6130207964103588, 0.535706770354814, 0.5813626263045917, 0.5539108154765011, 0.5456066102224545, 0.5672188673141229, 0.5156495747339986, 0.5658513112877407, 0.6062531610474969, 0.5621194071578284, 0.563272840567749, 0.5533110567905607, 0.5471697233236619, 0.5272094859694042, 0.5401285399485679, 0.553138024180475, 0.5278362594816807, 0.538744232515349, 0.5305637319157593, 0.5432638967559286, 0.5451707887823565, 0.5353627442008387, 0.5291802067391194, 0.5216470331388668, 0.532170845753085, 0.5397122712248433, 0.5380478034706881, 0.5285928628958054, 0.5574221618636681, 0.5206251490290148, 0.544372010187511, 0.546507761317448, 0.5337148718807819, 0.5552859236724186, 0.5298582897351606, 0.5463962213401377, 0.5592176839165444, 0.5717737713869471, 0.5859370967985069, 0.563552257353372, 0.572380937255212, 0.5903504667055868, 0.5626266717258162, 0.5553192816076488, 0.5358396521667494, 0.5687058632173677, 0.6057831927807662, 0.559937164840037, 0.5557683370191685, 0.5766001952825671, 0.554670561621659, 0.5369631688307671, 0.6370895968301453, 0.6704295782277184, 0.5434727884122055, 0.5609006221494536, 0.5426577578713424, 0.5816096087006757, 0.5613352171260945, 0.5439551187692767, 0.5628716322409846, 0.6006439331456692, 0.5843324824406283, 0.5392818697830186, 0.5745754789044387, 0.5449128940592717, 0.5663226170696481, 0.5298285097101308, 0.5368276283036183, 0.5465853667824808, 0.5525836417057218, 0.541211293887918, 0.5810756851939389, 0.5631464047588571, 0.5519742047699698, 0.5812724330564485, 0.5962848321799814, 0.5800703014553028, 0.5733789995203923, 0.5706282312417552, 0.567855201063365, 0.5339387351796575, 0.5457071676088946, 0.5879064044595634, 0.6375515937370105, 0.5595572847519478, 0.6110296863926589, 0.5974359916944574, 0.60043084958609, 0.6019651677704205, 0.5850601696620022, 0.5692365743818074, 0.5490666399471951, 0.5776882446812888, 0.5777020301044422, 0.5819544249424969, 0.571994390148316, 0.5776178509432034, 0.6303039765270957, 0.597030386655, 0.5939250725464229, 0.5914030708100674, 0.5813902935189922, 0.5437921920832056, 0.6153398730459004, 0.5465818759951279, 0.6058577305644098, 0.5795948433614996, 0.5861522775061809, 0.5549199946605377, 0.5775311991681148, 0.5616573702244863, 0.5760531373267627, 0.5509039534486994, 0.5739639612444996, 0.5493927897110472, 0.5738133050664498, 0.5931146666951423, 0.5758782667617728, 0.5918734766488528, 0.5587256990209983, 0.5756056815603353, 0.5411184593273776, 0.5754358237677247, 0.5722818025489793, 0.5800368611829995, 0.5620192454679169, 0.5531202715678807, 0.5737497726061048, 0.5866203122112873, 0.5708306664532988, 0.5944854526841727, 0.5557045143668669, 0.5764419235234713, 0.5783285269119444, 0.5945975686946925, 0.5895095750363204, 0.5716037233598041, 0.5644503726358832, 0.618653406844522, 0.5513610470033911, 0.5674368176799621, 0.605613004225884, 0.5882419314045105, 0.5579800210947538, 0.5828579511955707, 0.5380947904212632, 0.561203915272316, 0.5771476958137359, 0.5865690585253013, 0.5574073050796551, 0.5512299565938268, 0.5550252853953925, 0.5656464121637553, 0.5905012888629941, 0.5707498309168503, 0.5724693786923902, 0.6065762184397148, 0.5601830244281866, 0.5788142328714803, 0.5755001276078886, 0.5628887336619579, 0.6043857869005551, 0.588349437082771, 0.6225136880742481, 0.6421846625517954, 0.6245179721120283, 0.5788700147701876, 0.737305438159591, 0.5716335462392682, 0.7310338820854243, 0.6525301404678039, 0.7045971009418042, 0.6604934002748484, 0.6082739459642832, 0.6840649332416101, 0.6024634648217156, 0.5939333676802416, 0.6059748393437759, 0.589174055908779, 0.5700567813902876, 0.5953955706106975, 0.6200192476721331, 0.6823375447679576, 0.6120845980765502, 0.5772549577438049, 0.5576318604667692, 0.569980044856015, 0.6531403848364351, 0.5770574443443359, 0.609011745193408, 0.5597897002343463, 0.5875590973400041, 0.5986744328571932, 0.5649750211673795, 0.626722321023036, 0.5669681496211212, 0.586636292238305, 0.6533800512059408, 0.6381032901832079, 0.6383209140134474, 0.6268051058841706, 0.5555359027246759, 0.6512598165123841, 0.6452196498397108, 0.6074285242545654, 0.6043951691937273, 0.6061202602511541, 0.5751032402145418, 0.6191927487477601, 0.6150585456013146, 0.5559743315771306, 0.682510264639328, 0.6036824328477756, 0.5249756360001672, 0.552065710703049, 0.5521641512154409, 0.48081851001313225, 0.4893718619458255, 0.5843586488076462, 0.5932361074299197, 0.5188632733630483, 0.5694359153081, 0.6742538555985772, 0.5612875608197094, 0.5808601342345567, 0.5394065333054449, 0.6092944259772948, 0.6040009467139711, 0.5907828166105977, 0.5659890563992632, 0.5733881762631945, 0.5815116760214637, 0.5310146219103876, 0.5302240012118417, 0.5618848916700613, 0.5665671621108543, 0.6293197198461632, 0.5405179430394141, 0.5977630913626886, 0.5814689708654298, 0.5605312147781794, 0.6575157681520838, 0.5671799221731652, 0.5765777445633956, 0.5432715249540162, 0.5628247242556871, 0.6056850485672605, 0.5098665912075953, 0.5470326423940849, 0.564281087903501, 0.5438414134559104, 0.5337930704929705, 0.5242687257142401, 0.5387855556656596, 0.5410988582245762, 0.522192033537983, 0.5246677561470495, 0.5667317879461023, 0.5361012667978715, 0.48585259804214476, 0.49885737574223193, 0.5140389775078539, 0.5296593475319294, 0.542971557177912, 0.5692691054657428, 0.5511191637015057, 0.4833762986351344, 0.5161863471906237, 0.5346019611257539, 0.5635662736372434, 0.5446670630588729, 0.5350232208079665, 0.6022679820303282, 0.5636356823019492, 0.5229274285532522, 0.5222959302891673, 0.5202323568559128, 0.5528144729905143, 0.5464128706188893, 0.5434020082328046, 0.5123158592749267, 0.5362281110659015, 0.5806639833316897, 0.581881632189974, 0.599778297173753, 0.5857916045472447]
val_losses_05_e4 = [0.5977624928864249, 0.5771655255425585, 0.5953775445257661, 0.5928439415284317, 0.5528305133763891, 0.5848028262818816, 0.5857290293831025, 0.5723953459167133, 0.5710493475198746, 0.5919734509321894, 0.5611137549807556, 0.579986428148555, 0.6509781344963687, 0.5459538367542908, 0.5374621068039079, 0.5488112548189442, 0.546562664591483, 0.5589793404958544, 0.6154108700090951, 0.5494831529629491, 0.5693454245363709, 0.5480730363922398, 0.5560585320213415, 0.606562853947173, 0.5450109678463344, 0.5430570852800007, 0.578323513378192, 0.6033858755861756, 0.5503094459537172, 0.559648377943213, 0.5671653230912495, 0.5507321799323507, 0.6003795936159844, 0.5744239025524933, 0.5756104240452287, 0.6054707229354955, 0.5920074015420719, 0.5615763012727681, 0.5616998859565624, 0.5994104306845769, 0.5475960315143975, 0.5659958452638918, 0.5747383664341739, 0.5582932896205108, 0.5574108120733804, 0.5379756765208975, 0.5648864555532915, 0.5349843366085177, 0.5520481442230462, 0.6005730813872205, 0.6155499942111273, 0.5642245883924247, 0.5788738451843715, 0.5390765714819414, 0.5666071537637363, 0.5726931307220111, 0.5539144782798133, 0.5780259164145393, 0.5504599887959278, 0.5369425696613145, 0.5571764950117055, 0.5436495766587501, 0.5389167188945478, 0.5388835461905402, 0.5531337973627731, 0.5535196260596714, 0.5639540449763737, 0.5399940906867494, 0.535193367378555, 0.547124096620692, 0.5587303983251544, 0.5149633880079227, 0.5309203547717881, 0.5306796964502682, 0.5389145589875479, 0.5433423947678865, 0.5490047798430833, 0.537039710113602, 0.5493356524592768, 0.5664258813553483, 0.5516579737410928, 0.5541133620660671, 0.5740191959334116, 0.5738034677984071, 0.5277600307969281, 0.5655930179042102, 0.555626796653671, 0.5768570818387679, 0.5738985407961547, 0.6007532765612985, 0.5623970644099869, 0.6140912676597163, 0.5865765585951561, 0.5502162091705921, 0.58705449833052, 0.5728525914197421, 0.5875620447153592, 0.5455798339234651, 0.5316349688890206, 0.529464841976653, 0.597501233328868, 0.5695028367051242, 0.5588308458563185, 0.5693718389655552, 0.5820215864338144, 0.5525828103949554, 0.581964083505373, 0.5806879829751314, 0.5835552951932823, 0.5836054922020348, 0.5790376487004496, 0.5796612267294069, 0.600391698470951, 0.5766839863610094, 0.5612427189837407, 0.5934007605061914, 0.5747890786750474, 0.5579111114905698, 0.5651346504905798, 0.5271851238760635, 0.5484017481769088, 0.5759551058502963, 0.5626381250628589, 0.5805758561966193, 0.5699895939035137, 0.5689836998272987, 0.5326194558700506, 0.5381367088016802, 0.5706369327585192, 0.5476145530051558, 0.599505764289494, 0.6096121247885001, 0.569212907966036, 0.5646458393248328, 0.576134149393026, 0.6473767191824251, 0.6040177196264267, 0.602314833633221, 0.5797374161490558, 0.6074808638026244, 0.5902396274091554, 0.5795859896788632, 0.5868929359164551, 0.6148955993843774, 0.5902183178785073, 0.5828540870090471, 0.5695856274479497, 0.6046258411268248, 0.5910232728415162, 0.5796862601363746, 0.5744502716255884, 0.6423626529039258, 0.5940411691247982, 0.5957139819642924, 0.6008491318156249, 0.60257096207925, 0.5904438663138091, 0.5986692294152114, 0.5772784585065215, 0.6033101682245297, 0.6382673939649206, 0.598614500821942, 0.594399074459598, 0.588400178799664, 0.5682313590154161, 0.587433031005581, 0.5958026227724813, 0.5872575790777693, 0.5963523689195187, 0.5926747096933588, 0.5725596236051435, 0.5681258196378276, 0.5846319990436526, 0.5465760068954343, 0.5595425550084915, 0.5635856718477541, 0.5787848530024507, 0.581515882137048, 0.5941440036697109, 0.6065460802429784]

plt.figure(figsize=(20, 6))
plt.plot(val_losses_01_e5[:100], label="Dropout: 01 LR: e-5")
plt.plot(val_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(val_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.title("Validation Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```
