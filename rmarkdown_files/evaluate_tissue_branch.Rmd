---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
import torch
import albumentations as A
import matplotlib.pyplot as plt

from glob import glob
from monai.data import DataLoader
from monai.losses import DiceLoss
from monai.metrics import DiceMetric, MeanIoU
from monai.transforms import Compose, AsDiscrete

from torch.optim import Adam

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import TissueDataset, CellTissueDataset
from src.train_utils import train
```

```{python}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"

train_seg_files = glob(os.path.join(data_path, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_path, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_path, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_path, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_path, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_path, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
train_tissue_seg_files = glob(os.path.join(data_path, "annotations/train/tissue/*"))
train_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_tissue_seg_files
]
train_tissue_image_files = [
    os.path.join(data_path, "images/train/tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]
train_tissue_predicted = [
    os.path.join(data_path, "annotations/train/pred_tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]


val_tissue_seg_files = glob(os.path.join(data_path, "annotations/val/tissue/*"))
val_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_tissue_seg_files
]
val_tissue_image_files = [
    os.path.join(data_path, "images/val/tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]
val_tissue_predicted = [
    os.path.join(data_path, "annotations/val/pred_tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]



test_tissue_seg_files = glob(os.path.join(data_path, "annotations/test/tissue/*"))
test_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_tissue_seg_files
]
test_tissue_image_files = [
    os.path.join(data_path, "images/test/tissue", image_number + ".jpg")
    for image_number in test_tissue_image_numbers
]
test_tissue_predicted = [
    os.path.join(data_path, "annotations/test/pred_tissue", image_number + ".jpg")
    for image_number in test_tissue_image_numbers
]

def calculate_dice_score(dataloader, model, device): 

    dice_metric = DiceMetric(include_background=True, reduction="mean")
    post_pred = Compose([AsDiscrete(argmax=True, dim=1, to_onehot=3)])

    model.eval()
    for (images, masks) in dataloader: 
        images, masks = images.to(device), masks.to(device)
        with torch.no_grad(): 
            outputs = model(images)
        outputs = post_pred(outputs)
        dice_metric(outputs, masks)

    dice_score = dice_metric.aggregate().item()
    dice_metric.reset()

    return dice_score

def calculate_miou(dataloader, model, device): 
    iou_metric = MeanIoU(include_background=True, reduction="mean")
    post_pred = AsDiscrete(argmax=True, to_onehot=3, dim=1)

    model.eval()
    with torch.no_grad():
        for (images, masks) in dataloader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            outputs = post_pred(outputs)
            iou_metric(outputs, masks)

    miou = iou_metric.aggregate().item()
    iou_metric.reset()

    return miou


transforms = A.Compose([
    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # You can adjust the blur limit
    A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),  # Adjust var_limit for noise intensity
    A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
], additional_targets = {
    "mask1": "mask", 
    "mask2": "mask"
}
)
```

```{python}

# dataloader for tissue-model
train_tissue_dataset = TissueDataset(image_files=train_tissue_image_files, seg_files=train_tissue_seg_files, transform=transforms)
val_tissue_dataset = TissueDataset(image_files=val_tissue_image_files, seg_files=val_tissue_seg_files)
test_tissue_dataset = TissueDataset(image_files=test_tissue_image_files, seg_files=test_tissue_seg_files)

train_tissue_dataloader = DataLoader(dataset=train_tissue_dataset, batch_size=2, drop_last=True)
val_tissue_dataloader = DataLoader(dataset=val_tissue_dataset)
test_tissue_dataloader = DataLoader(dataset=test_tissue_dataset)
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model_tissue = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_tissue.to(device)

model_tissue.load_state_dict(torch.load("outputs/models/2023-12-07_22-49-54_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-100.pth"))

test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)

test_miou = calculate_miou(test_tissue_dataloader, model_tissue, device)
val_miou = calculate_miou(val_tissue_dataloader, model_tissue, device)

print("lr=0.0001, dropout=0.3, backbone=resnet50 (Baseline)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
print(f"mIoU on test set: {test_miou}")
print(f"mIoU on validation set: {val_miou}")


model_tissue.load_state_dict(torch.load("outputs/models/2023-12-08_22-19-39_deeplabv3plus_tissue_branch_lr-1e-05_dropout-0.1_backbone-resnet50_epochs-100.pth"))

test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)

test_miou = calculate_miou(test_tissue_dataloader, model_tissue, device)
val_miou = calculate_miou(val_tissue_dataloader, model_tissue, device)

print("lr=0.0005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
print(f"mIoU on test set: {test_miou}")
print(f"mIoU on validation set: {val_miou}")

model_tissue.load_state_dict(torch.load("outputs/models/2023-12-09_13-56-10_deeplabv3plus_tissue_branch_lr-0.0001_dropout-0.5_backbone-resnet50_epochs-100.pth"))

test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)

test_miou = calculate_miou(test_tissue_dataloader, model_tissue, device)
val_miou = calculate_miou(val_tissue_dataloader, model_tissue, device)

print("lr=0.00005, dropout=0.3, backbone=resnet50 (changed lr)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
print(f"mIoU on test set: {test_miou}")
print(f"mIoU on validation set: {val_miou}")
```

```{python}
training_losses_01_e5 = [0.6760178451240063, 0.6283668023347855, 0.6189012670516968, 0.6056847624480725, 0.5988180582225323, 0.5894803062081337, 0.5889860284328461, 0.5852472296357155, 0.5754608425498009, 0.5733441370725632, 0.5669056445360183, 0.5679075828194619, 0.5644334869086742, 0.5599455334246158, 0.5581196920573711, 0.5626593473553657, 0.5567940774559975, 0.5498311734199524, 0.5429686622321606, 0.5468052105605602, 0.5433215552568436, 0.5429336677491665, 0.5432416704297066, 0.5382907401025295, 0.5349717877805233, 0.534958818256855, 0.5346143671870232, 0.5293791945278644, 0.5247422239184379, 0.5262467519938946, 0.523743993639946, 0.5212730453908443, 0.5284235242009163, 0.5218965509533882, 0.5182860699295998, 0.5149880431592464, 0.5160851773619651, 0.5138096189498902, 0.5099452608823776, 0.5120469097793102, 0.5122914385795593, 0.503730402737856, 0.5101686152815819, 0.5027919359505176, 0.4988692307472229, 0.5013318420946598, 0.5012523183971643, 0.4976007981598377, 0.4994832041859627, 0.4896462225168943, 0.4958011893928051, 0.4942212633788586, 0.4954705898463726, 0.4979757995903492, 0.4924667826294899, 0.4846217975020409, 0.4936311114579439, 0.48434083715081216, 0.4846542318165302, 0.48247533150017263, 0.48261797726154326, 0.48782682470977307, 0.4809047397226095, 0.48206855557858946, 0.4811512811481953, 0.48181213609874246, 0.480568528175354, 0.4736129146814346, 0.47797522753477095, 0.477864408493042, 0.4759064969420433, 0.47800201296806333, 0.4785067146271467, 0.4767740681767464, 0.46719554051756856, 0.4640746007859707, 0.46968367740511896, 0.46644951701164244, 0.4661111431568861, 0.463744380325079, 0.4675267045199871, 0.4639004284888506, 0.45929656326770785, 0.4600951910763979, 0.4573476668447256, 0.45803395271301267, 0.4596943213045597, 0.4598559562116861, 0.45568885989487173, 0.4603027317672968, 0.4521827052533627, 0.4539269534498453, 0.4544250251352787, 0.4531278321146965, 0.45195868879556655, 0.45218412674963476, 0.4463946535438299, 0.45048472471535206, 0.4493952213972807, 0.4429223261028528, 0.44327609352767466, 0.44706981055438516, 0.44250812388956545, 0.4450576370954514, 0.4404706683754921, 0.44335350915789606, 0.4379950001090765, 0.4388030954450369, 0.43949663050472737, 0.4453110512346029, 0.44211589694023135, 0.4345696340501308, 0.43635180689394476, 0.43380490750074385, 0.4364210842549801, 0.4315920700132847, 0.43095513589680196, 0.4343961954861879, 0.4320741707831621, 0.43156116977334025, 0.4302061618864536, 0.42619125977158545, 0.42819126456975937, 0.43091967560350897, 0.42736244671046736, 0.43276346802711485, 0.42662077985703944, 0.4269057808071375, 0.42469360619783403, 0.421780329272151, 0.4259609819948673, 0.42286244690418245, 0.4211556640267372, 0.4188082570582628, 0.4214020937681198, 0.42150381945073606, 0.42103091441094875, 0.42346545033156874, 0.4206902128458023, 0.41912030838429926, 0.41777819372713565, 0.4200278735905886, 0.4170443057268858, 0.416195427775383, 0.4162632369250059, 0.42007380329072475, 0.4144430811703205, 0.41456301264464857, 0.41365242049098017, 0.4098920428007841, 0.41064439944922926, 0.41333047606050966, 0.4131052170693874, 0.40651904568076136, 0.4105176051706076, 0.4076971685141325, 0.4082929078489542, 0.40735443904995916, 0.40891775108873846, 0.4120578733831644, 0.40462806992232797, 0.4047673360258341, 0.4036571519076824, 0.40751058541238305, 0.40646923303604127, 0.40407378785312176, 0.40432945907115936, 0.40053551822900774, 0.4054542544484139, 0.40735264025628565, 0.3987497514486313, 0.4030453479290009, 0.4010337220132351, 0.4024202033132315, 0.4054672732949257, 0.4049015253782272, 0.40216673880815507, 0.4016965028643608, 0.39920970059931277, 0.3965177556872368, 0.3993443933874369, 0.3965770542621613, 0.39684692561626433, 0.39667854182422163, 0.39373133040964603, 0.39701855957508086, 0.3942671808600426, 0.3910766465216875, 0.3949131850153208, 0.3959275697171688, 0.39606350563466547, 0.39190308935940266, 0.39185296326875685, 0.38950066491961477, 0.3896936234086752, 0.3881589944660664, 0.38804771631956103, 0.3927041612565517, 0.3892855293303728, 0.3920840292423964, 0.3926057770103216, 0.3888204777240753, 0.3930870693922043, 0.38659932896494864, 0.38544076032936575, 0.3889122546464205, 0.3846548317372799, 0.39133773345500233, 0.38505752123892306, 0.38624959453940394, 0.3917762690782547, 0.38537910625338556, 0.3852053686231375, 0.38347756542265415, 0.3837549510598183, 0.38494287136942146, 0.38644103981554506, 0.3809550625085831, 0.38092911913990973, 0.3864098920673132, 0.38487601578235625, 0.38556373573839664, 0.38235287815332414, 0.3825975998491049, 0.38093394711613654, 0.38030407853424547, 0.3832602445781231, 0.38099320642650125, 0.3772708899527788, 0.3800229436904192, 0.37914230838418006, 0.37635059133172033, 0.37528641857206824, 0.3795157435536385, 0.3767896796017885, 0.37855854593217375, 0.37208116695284843, 0.3740115124732256, 0.37630096659064294, 0.3785699825361371, 0.3722706422954798, 0.3755905408412218, 0.3801930178701878, 0.3769207614660263, 0.37615900628268717, 0.3714590096846223, 0.3703236036002636, 0.3698807402327657, 0.3701217220723629, 0.36882312305271625, 0.3725447418540716, 0.37157544583082197, 0.36834049224853516, 0.3705364073067903, 0.3715913374722004, 0.3677611146122217, 0.3707184560596943, 0.3709777706861496, 0.3698690494894981, 0.37038573414087295, 0.3693812830001116, 0.37200513780117034, 0.3668948321789503, 0.3712270656600595, 0.3655724070221186, 0.3658788716048002, 0.36933613657951353, 0.36767830736935136, 0.36268393486738204, 0.3655410803854465, 0.3620913379266858, 0.36914046175777915, 0.3671708256751299, 0.3648065435141325, 0.36008495796471834, 0.3655753517895937, 0.3656556211784482, 0.3638717646151781, 0.3620382358878851, 0.3636048141866922, 0.3606983757391572, 0.36150302611291407, 0.35911358922719955, 0.367096503674984, 0.3616193337738514, 0.3630022720992565, 0.35861676938831805, 0.35747863702476024, 0.3607505879551172, 0.3633171758055687, 0.36089465126395226, 0.3652922338247299, 0.35727896109223367, 0.35885349549353124, 0.359466852247715, 0.35832229871302845, 0.3576656820997596, 0.35890561655163766, 0.36213452711701394, 0.3555854331701994]
training_losses_03_e4 = [0.6377815628051757, 0.6059734432399273, 0.590821613818407, 0.5712891797721386, 0.5712862102687359, 0.5654898694157601, 0.565285691767931, 0.563297304213047, 0.553656240850687, 0.5508803363144398, 0.5523784719407558, 0.5466656649112701, 0.544693968296051, 0.5420596651732922, 0.5440559732913971, 0.544414628893137, 0.536523692458868, 0.5317785897105932, 0.5348353417217732, 0.5263301396369934, 0.5271237802505493, 0.5266878898441791, 0.5305304397642613, 0.5195005333423615, 0.5241142293065786, 0.5331965786218643, 0.5153780496120453, 0.5193031169474125, 0.5184791991114617, 0.5155639296770096, 0.5096967269480228, 0.5184535540640354, 0.5092710943520069, 0.5106850631535054, 0.5147987473011016, 0.502492643892765, 0.502475102469325, 0.505776246637106, 0.5099077728390694, 0.4991920728236437, 0.5130861069262028, 0.5040742922574282, 0.501481217443943, 0.4967557418346405, 0.5007512950897217, 0.4890888991206884, 0.4999270425736904, 0.4972155563533306, 0.49535338655114175, 0.4981259298324585, 0.4916591188311577, 0.49952440448105334, 0.4927095017582178, 0.4895165640860796, 0.5002042967826128, 0.4946031378209591, 0.49366553671658037, 0.49171479992568495, 0.49091118179261684, 0.49453128799796103, 0.4922934745252132, 0.4855763327330351, 0.4972301494330168, 0.4893512385338545, 0.48536124639213085, 0.4898102250695229, 0.5204466248303652, 0.4906792064756155, 0.4837149415910244, 0.4790689507126808, 0.4821527437865734, 0.48662997588515283, 0.48564422748982905, 0.4776880444586277, 0.4841087339818478, 0.4877268972247839, 0.4846574659645557, 0.4815856602787971, 0.5012881903350354, 0.48911954239010813, 0.4863907770067453, 0.4758448687940836, 0.4727740943431854, 0.47661700904369353, 0.47588325902819634, 0.49999722369015215, 0.4777309760451317, 0.4738358999043703, 0.4694503654539585, 0.46841491959989073, 0.4743210136890411, 0.4712062932550907, 0.4869456046074629, 0.4768123444914818, 0.4674240829050541, 0.4626352223008871, 0.4644208028912544, 0.47369625508785246, 0.48407292149960995, 0.4667682637274265, 0.48174102425575255, 0.4663602022081614, 0.45830663964152335, 0.46022829741239546, 0.4577199594676495, 0.4890021587908268, 0.48227440409362315, 0.4566120444238186, 0.462772209495306, 0.45648628011345865, 0.45896361574530603, 0.46128088630735875, 0.48924243047833443, 0.4605031944811344, 0.46398802429437636, 0.45681733570992944, 0.4623651577532291, 0.4564772615581751, 0.46063005343079566, 0.4579595246911049, 0.457303713709116, 0.4589031147956848, 0.45208398550748824, 0.4589352695643902, 0.455834823846817, 0.4582113669067621, 0.4660412539541721, 0.4519029694795609, 0.44859266459941866, 0.45302178293466566, 0.4574365516752005, 0.4656405449658632, 0.46336465403437616, 0.45308669328689577, 0.4566919633001089, 0.44667860850691793, 0.4598775514960289, 0.444922082349658, 0.45218870997428895, 0.4477448383718729, 0.4460842790454626, 0.4488857600092888, 0.44475452065467835, 0.45035070419311524, 0.44726663500070574, 0.4451882902532816, 0.44113002605736257, 0.4472432482987642, 0.4370318948477507, 0.4343709796667099, 0.4375425408780575, 0.4711594747006893, 0.47554585583508013, 0.45762021109461787, 0.45836350798606873, 0.4564807651937008, 0.45362245179712773, 0.4510880170762539, 0.4597684272378683, 0.45416865050792693, 0.4560093470662832, 0.4510184449702501, 0.44799619674682617, 0.4506046833097935, 0.4389206253737211, 0.4359822018444538, 0.43806075543165207, 0.44403731875121594, 0.45282613500952723, 0.4369612926244736, 0.45598123252391815, 0.4472072067856789, 0.42943765558302405, 0.42458994016051294, 0.4312879889458418, 0.43254250831902025, 0.4382817866653204, 0.4628045567125082, 0.5018086359277367, 0.4981046371161938, 0.5684782381355763, 0.5133485133945942, 0.5316275380551815, 0.5170635338872671, 0.4914216161519289, 0.4756293100491166, 0.4901875049620867, 0.4601170665025711, 0.45685355946421624, 0.4956151109933853, 0.4792950823158026, 0.47302985161542893, 0.45513567466288807, 0.472862488143146, 0.4639650437235832, 0.44687065087258815, 0.4896829080581665, 0.47778374902904036, 0.4566824364289641, 0.44020837277173996, 0.4299636426195502, 0.44303503666073085, 0.4799391891434789, 0.5364043817669153, 0.49201217357069255, 0.4604913033545017, 0.4946860785037279, 0.4583289762958884, 0.4390909633040428, 0.4453952471911907, 0.466344228759408, 0.5723239415884018, 0.5686424069479108, 0.5841795209050179, 0.5682730854302644, 0.5343514594435692, 0.5114027810096741, 0.4861444701999426, 0.47973911963403226, 0.47359894089400767, 0.45603138230741025, 0.49194451458752153, 0.46178891804069283, 0.4585450867563486, 0.42387934602797034, 0.45617425840348, 0.5194702396169305, 0.47097007650882006, 0.4605268250033259, 0.4420962827652693, 0.49203965947031975, 0.4521082966774702, 0.42925920311361554, 0.4447686482965946, 0.46328412659466267, 0.4823494533449411, 0.4578806775435805, 0.5105443441867829, 0.44794262006878854, 0.43863685585558415, 0.47803151302039626, 0.5590668387711049, 0.5596745593473316, 0.5466940335184336, 0.5369085131958127, 0.524919743090868, 0.4966980609670281, 0.4902417477965355, 0.47161789298057555, 0.4575433617830276, 0.4577233768999577, 0.523239947669208, 0.4800522403046489, 0.5065815112367272, 0.5455203757062554, 0.4975975930690765, 0.46850264087319377, 0.4734596624225378, 0.45230991318821906, 0.4840252172574401, 0.4575458180904388, 0.4671538146585226, 0.44754450883716346, 0.43294791944324973, 0.4433683126419783, 0.45786334715783594, 0.43300708681344985, 0.4323624530434608, 0.4205475926399231, 0.44029337625950576, 0.4333029257133603, 0.5088842822983861, 0.4649844725430012, 0.4697112184762955, 0.45822789646685125, 0.4275662387162447, 0.4354124150425196, 0.4584627451747656, 0.496833098679781, 0.4570057071745396, 0.45537380397319793, 0.43207717310637234, 0.49333218462765216, 0.4929084214568138, 0.4574182102829218, 0.47364044781774284, 0.48320292714983226, 0.5742028927057982, 0.5523052585870027, 0.520981904938817, 0.47635960578918457, 0.4979624949395657, 0.4965540799126029, 0.4679086600244045, 0.5255564369261265, 0.5288546577468515, 0.5630260391533375, 0.5541914678364992, 0.5445256062597036, 0.5366250418871641]
training_losses_05_e4 = [0.6533284509181976, 0.6107789556682109, 0.5983250005543232, 0.587052844017744, 0.5814013662934303, 0.5723004989326, 0.5763407631218433, 0.5733415161073208, 0.5643847233057022, 0.5633981041610241, 0.5571352070569993, 0.5570451828837395, 0.560302102714777, 0.5571731662750244, 0.5529105231165886, 0.5480043116211891, 0.5478477357327938, 0.5450358779728413, 0.539754729270935, 0.54738603875041, 0.5394885279238224, 0.5366729421913624, 0.5338123093545437, 0.5477326491475105, 0.5271148823201657, 0.527990717291832, 0.5256101086735725, 0.5334628643095494, 0.5264496989548206, 0.5203805390000343, 0.5306262376904488, 0.5249956068396568, 0.5214411763846875, 0.5247334323078394, 0.5217962907999754, 0.5168427859991789, 0.5046518974006176, 0.5183774910122156, 0.5080645595490932, 0.5143847344070673, 0.5160705065727234, 0.5081856228411198, 0.5208098754286766, 0.5174749591201544, 0.5129893745481968, 0.5107467602193355, 0.5187401503324509, 0.5055638844519854, 0.5045673821866512, 0.5070112942159176, 0.5144325292110443, 0.4999060595780611, 0.5110806592553854, 0.5016362275928259, 0.5021925891935826, 0.5007676193863153, 0.5036693467199802, 0.5017408800125122, 0.5068646934628487, 0.5012179841846227, 0.509585408270359, 0.4951365856826305, 0.4980676257610321, 0.49193301424384117, 0.4925361534953117, 0.5114632192254066, 0.5060778574645519, 0.4938987404108047, 0.5066115505248309, 0.5001183652877808, 0.49559985995292666, 0.48814248487353323, 0.48894992731511594, 0.489824166893959, 0.4877505496889353, 0.4943033031374216, 0.4806549758464098, 0.4829236775636673, 0.4865170009434223, 0.48431423790752887, 0.49897076837718485, 0.4927697066962719, 0.4991640555858612, 0.49350399650633336, 0.48456523261964324, 0.4906422944366932, 0.48055190704762935, 0.4922700433433056, 0.48087099350988866, 0.4789573273807764, 0.48585671581327916, 0.487334490865469, 0.496955236941576, 0.48303329914808274, 0.48756315670907496, 0.48408065393567085, 0.48103328347206115, 0.4750734702497721, 0.4833320944011211, 0.48220333650708197, 0.47569800809025764, 0.49214099258184435, 0.4795524401217699, 0.4812269984185696, 0.47670592680573465, 0.4754019956290722, 0.4780159068107605, 0.4737160028517246, 0.46982575453817843, 0.47969167307019234, 0.49175479002296923, 0.4823537730425596, 0.47876307010650637, 0.47542561881244183, 0.4784137148410082, 0.4735044613480568, 0.48696004047989844, 0.4748636135458946, 0.4737693653255701, 0.473209994956851, 0.4664189191162586, 0.46409889571368695, 0.46494069069623944, 0.47362754538655283, 0.47173741288483145, 0.4637825168669224, 0.465793589502573, 0.46733760327100754, 0.4638973194360733, 0.4659607424587011, 0.4625399924814701, 0.4669642543047667, 0.46444686748087405, 0.46271333664655684, 0.4657075674831867, 0.4776114442944527, 0.47540762327611447, 0.46432208083570004, 0.45735677249729634, 0.4541984904557467, 0.4623390534520149, 0.4672757039219141, 0.4557393793016672, 0.4566070703417063, 0.45072941586375237, 0.45894741274416445, 0.4611425144970417, 0.4731499388813972, 0.4713783143460751, 0.4653513895720243, 0.4630346379429102, 0.4686661113798618, 0.46760082960128785, 0.45731890715658663, 0.4715490463376045, 0.4680357578396797, 0.45796477630734445, 0.4508568187057972, 0.4515632738918066, 0.4654892391711474, 0.45759457141160964, 0.4524922359734774, 0.45443109177052976, 0.4463064617663622, 0.4444242064654827, 0.4478015860915184, 0.4511886668205261, 0.4502785383164883, 0.449346669614315, 0.45221192456781867, 0.45556355960667133, 0.45691175691783426, 0.4438472856581211, 0.45059146113693715, 0.45278302557766437, 0.44309232085943223, 0.4379144664853811, 0.46106124244630337, 0.4519511199742556, 0.4495412157475948]

plt.figure(figsize=(20, 6))
plt.plot(training_losses_01_e5[:100], label="Dropout: 01 LR: e-5")
plt.plot(training_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(training_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.title("Training Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

```{python}
val_losses_01_e5 = [0.6244556057627184, 0.6068543926642759, 0.5836414179227648, 0.578305623392119, 0.574001145406361, 0.5774814129745873, 0.5570091772688567, 0.5653928839159708, 0.5553600301925283, 0.6053782518762741, 0.5715386119202106, 0.5856596598007383, 0.5603360112783683, 0.5654478241709897, 0.5541492770188046, 0.5293215407724798, 0.5311742435841664, 0.532211706259825, 0.5288212706137748, 0.5434330958519539, 0.5336875647959047, 0.539018380924733, 0.5466139595003894, 0.5482473168929998, 0.5414841596009957, 0.5389758710661073, 0.5333166916440003, 0.5327825968282937, 0.5420707279313219, 0.5496890921227253, 0.5468578896600834, 0.5431916661506152, 0.5558491018566772, 0.5223662237616351, 0.5501358964799965, 0.5306240185333865, 0.5377021813697188, 0.5620619041206193, 0.5282722342840946, 0.5475936738679009, 0.5331507644949168, 0.5615825931521228, 0.5350360397222268, 0.5495010355528254, 0.535374885601719, 0.5402758864373186, 0.5543221561578069, 0.5771770689391742, 0.5447853661149088, 0.5434787832472446, 0.5856820377555206, 0.5463606128944968, 0.5597499240271366, 0.5637402845560199, 0.5241179933948238, 0.5275556304811562, 0.5384256653759601, 0.5595673269381488, 0.5332390309250268, 0.5661697159283352, 0.5798506139621248, 0.5658703178819948, 0.552201085064533, 0.5817285447660154, 0.5803612563079291, 0.6058828287968671, 0.5833925638538208, 0.60335482145748, 0.5814266726918464, 0.572388949511695, 0.5788875396234275, 0.5946822047886187, 0.6171240495504254, 0.5947765686216145, 0.5779010673073957, 0.5995470975002233, 0.599196190164037, 0.5679141770314126, 0.607246259812021, 0.5509415708319114, 0.5804716522676231, 0.6109614063353435, 0.571700506184223, 0.5890013917084158, 0.6028810907019316, 0.619321756010508, 0.6031911564569403, 0.6204928507770064, 0.5978120153185225, 0.5876486839821738, 0.6207669418658653, 0.6071919117965837, 0.5993977469684434, 0.6090380729985063, 0.6253451508109586, 0.5895560638312876, 0.6080493875881181, 0.5824666903184278, 0.5972056515025397, 0.5780795667945904, 0.57181809276995, 0.6217459098701059, 0.5986530362036977, 0.5554723976737391, 0.5905991830747493, 0.5912474428650236, 0.6016366457852134, 0.6049039221375528, 0.6094511655995446, 0.5997727147854157, 0.5659591009582046, 0.5651850785217146, 0.6060574942261633, 0.594832526941369, 0.5974403882983828, 0.5720995128372289, 0.6055036919177884, 0.5614880160258634, 0.6115396473094494, 0.6155472293387364, 0.6010559585190167, 0.6146966177616676, 0.6068375489137469, 0.6096917292932524, 0.6358873176313665, 0.6005944942470884, 0.6034697814144357, 0.6248788167960453, 0.6361225807899524, 0.6005496713366821, 0.6161076222022954, 0.6130588217808383, 0.6199545892920807, 0.6025726309005361, 0.5955086500540266, 0.5933389711554033, 0.5951087403036383, 0.5986786590222894, 0.5666915638385898, 0.566533559865325, 0.5880188201248211, 0.5957497743359448, 0.5772432745808233, 0.600278080379876, 0.598058203928662, 0.6066851409247321, 0.6300064327507994, 0.6094717774948064, 0.5803119751223682, 0.6185155713210141, 0.6102335875867492, 0.6208151317860958, 0.5973182438063795, 0.6186987374820848, 0.6113723219902574, 0.6292862955236087, 0.6069205985642481, 0.61778466985391, 0.5915997586328617, 0.5912680158214848, 0.6136958836203944, 0.5901877612528139, 0.6093091429585088, 0.6061998963573553, 0.591072333555152, 0.6196955383694085, 0.6162960503223168, 0.6247392266336149, 0.623413613134057, 0.6280971160770332, 0.6435235887765884, 0.6022234428538024, 0.6070670844429601, 0.5895858428774089, 0.6215176177720954, 0.6056329664522714, 0.612533696158959, 0.6187673653781849, 0.5942484395999978, 0.6284226364027845, 0.6130587904557695, 0.639423941608763, 0.6452841058264683, 0.6532735380813153, 0.6160226438167321, 0.6216698357441129, 0.6305188426788706, 0.6101577149255433, 0.6209599804269136, 0.6119323168357793, 0.6226474664507121, 0.6261174338359903, 0.661318222754193, 0.6288469818821789, 0.6178254367661302, 0.6335285609438471, 0.6801976894375181, 0.6504761175300083, 0.6546624433385194, 0.6389694057241844, 0.6235136731262625, 0.6231259494802378, 0.6327320180670188, 0.6264802182677889, 0.6228264891100626, 0.6313904852327639, 0.5985393027101991, 0.6610489854568711, 0.6602889667027187, 0.6447741002061941, 0.6272193822112396, 0.6424184522054491, 0.6646083621648107, 0.6636686461032743, 0.6579224464014499, 0.6478829744414691, 0.6543841440312184, 0.6421096372778399, 0.6473481619227541, 0.644784094860954, 0.6350058728325976, 0.6192762580883764, 0.641334646592175, 0.6565081190018758, 0.6293256704824685, 0.6840014077016037, 0.6533851662691492, 0.6516758055582533, 0.6367086504932737, 0.6148596270748611, 0.6320591079492639, 0.632389672916301, 0.6230556397107396, 0.6382430851677038, 0.6596680020328856, 0.6456712171109054, 0.6507371561805697, 0.623650440769474, 0.6479321646429327, 0.6515817096198562, 0.6556209800017141, 0.6166788870400756, 0.6472057270525146, 0.6328647132337528, 0.6225067967341629, 0.6373488696387214, 0.6223078368734705, 0.6253658489589273, 0.6502868362913167, 0.6431251552200665, 0.6173194653361384, 0.6540969765751902, 0.6529228934551564, 0.6624235252684357, 0.6224618158201232, 0.6229130809542036, 0.6286953450557312, 0.6149921052864868, 0.632713118520477, 0.6173923564530963, 0.6218166820472106, 0.606447197769943, 0.6111651528492315, 0.6412309639862854, 0.6354130366749137, 0.6323037230185349, 0.6155955725918604, 0.6377525944126784, 0.6095452901846083, 0.6265355781482084, 0.6237869089754828, 0.6090853000082395, 0.6278835695753567, 0.643819215687087, 0.6515691373270737, 0.6360713464282725, 0.6158879071548004, 0.6230736827328257, 0.6281943505045271, 0.6419019528331548, 0.6141437566669209, 0.6110342924829817, 0.6178026062293644, 0.6141965362059809, 0.6137233933495072, 0.656990912137893, 0.6156815463850397, 0.6243536181197278, 0.646428702562286, 0.6412770669145959, 0.6318333540519658, 0.6229752243072743, 0.6665298987341871, 0.6652956856584625, 0.6389245400341214, 0.6470611541738893, 0.6423324753333183, 0.6378775122609451, 0.6596223327134104, 0.6343806608695618]
val_losses_03_e4 = [0.6756902813476368, 0.6447698587048662, 0.5784846375675967, 0.5593729689173454, 0.6238896796738145, 0.5521230777032184, 0.5721430643631594, 0.5651514591091741, 0.577448274206071, 0.5514343342859379, 0.618131708054647, 0.6360507671632906, 0.5925329078505509, 0.6130207964103588, 0.535706770354814, 0.5813626263045917, 0.5539108154765011, 0.5456066102224545, 0.5672188673141229, 0.5156495747339986, 0.5658513112877407, 0.6062531610474969, 0.5621194071578284, 0.563272840567749, 0.5533110567905607, 0.5471697233236619, 0.5272094859694042, 0.5401285399485679, 0.553138024180475, 0.5278362594816807, 0.538744232515349, 0.5305637319157593, 0.5432638967559286, 0.5451707887823565, 0.5353627442008387, 0.5291802067391194, 0.5216470331388668, 0.532170845753085, 0.5397122712248433, 0.5380478034706881, 0.5285928628958054, 0.5574221618636681, 0.5206251490290148, 0.544372010187511, 0.546507761317448, 0.5337148718807819, 0.5552859236724186, 0.5298582897351606, 0.5463962213401377, 0.5592176839165444, 0.5717737713869471, 0.5859370967985069, 0.563552257353372, 0.572380937255212, 0.5903504667055868, 0.5626266717258162, 0.5553192816076488, 0.5358396521667494, 0.5687058632173677, 0.6057831927807662, 0.559937164840037, 0.5557683370191685, 0.5766001952825671, 0.554670561621659, 0.5369631688307671, 0.6370895968301453, 0.6704295782277184, 0.5434727884122055, 0.5609006221494536, 0.5426577578713424, 0.5816096087006757, 0.5613352171260945, 0.5439551187692767, 0.5628716322409846, 0.6006439331456692, 0.5843324824406283, 0.5392818697830186, 0.5745754789044387, 0.5449128940592717, 0.5663226170696481, 0.5298285097101308, 0.5368276283036183, 0.5465853667824808, 0.5525836417057218, 0.541211293887918, 0.5810756851939389, 0.5631464047588571, 0.5519742047699698, 0.5812724330564485, 0.5962848321799814, 0.5800703014553028, 0.5733789995203923, 0.5706282312417552, 0.567855201063365, 0.5339387351796575, 0.5457071676088946, 0.5879064044595634, 0.6375515937370105, 0.5595572847519478, 0.6110296863926589, 0.5974359916944574, 0.60043084958609, 0.6019651677704205, 0.5850601696620022, 0.5692365743818074, 0.5490666399471951, 0.5776882446812888, 0.5777020301044422, 0.5819544249424969, 0.571994390148316, 0.5776178509432034, 0.6303039765270957, 0.597030386655, 0.5939250725464229, 0.5914030708100674, 0.5813902935189922, 0.5437921920832056, 0.6153398730459004, 0.5465818759951279, 0.6058577305644098, 0.5795948433614996, 0.5861522775061809, 0.5549199946605377, 0.5775311991681148, 0.5616573702244863, 0.5760531373267627, 0.5509039534486994, 0.5739639612444996, 0.5493927897110472, 0.5738133050664498, 0.5931146666951423, 0.5758782667617728, 0.5918734766488528, 0.5587256990209983, 0.5756056815603353, 0.5411184593273776, 0.5754358237677247, 0.5722818025489793, 0.5800368611829995, 0.5620192454679169, 0.5531202715678807, 0.5737497726061048, 0.5866203122112873, 0.5708306664532988, 0.5944854526841727, 0.5557045143668669, 0.5764419235234713, 0.5783285269119444, 0.5945975686946925, 0.5895095750363204, 0.5716037233598041, 0.5644503726358832, 0.618653406844522, 0.5513610470033911, 0.5674368176799621, 0.605613004225884, 0.5882419314045105, 0.5579800210947538, 0.5828579511955707, 0.5380947904212632, 0.561203915272316, 0.5771476958137359, 0.5865690585253013, 0.5574073050796551, 0.5512299565938268, 0.5550252853953925, 0.5656464121637553, 0.5905012888629941, 0.5707498309168503, 0.5724693786923902, 0.6065762184397148, 0.5601830244281866, 0.5788142328714803, 0.5755001276078886, 0.5628887336619579, 0.6043857869005551, 0.588349437082771, 0.6225136880742481, 0.6421846625517954, 0.6245179721120283, 0.5788700147701876, 0.737305438159591, 0.5716335462392682, 0.7310338820854243, 0.6525301404678039, 0.7045971009418042, 0.6604934002748484, 0.6082739459642832, 0.6840649332416101, 0.6024634648217156, 0.5939333676802416, 0.6059748393437759, 0.589174055908779, 0.5700567813902876, 0.5953955706106975, 0.6200192476721331, 0.6823375447679576, 0.6120845980765502, 0.5772549577438049, 0.5576318604667692, 0.569980044856015, 0.6531403848364351, 0.5770574443443359, 0.609011745193408, 0.5597897002343463, 0.5875590973400041, 0.5986744328571932, 0.5649750211673795, 0.626722321023036, 0.5669681496211212, 0.586636292238305, 0.6533800512059408, 0.6381032901832079, 0.6383209140134474, 0.6268051058841706, 0.5555359027246759, 0.6512598165123841, 0.6452196498397108, 0.6074285242545654, 0.6043951691937273, 0.6061202602511541, 0.5751032402145418, 0.6191927487477601, 0.6150585456013146, 0.5559743315771306, 0.682510264639328, 0.6036824328477756, 0.5249756360001672, 0.552065710703049, 0.5521641512154409, 0.48081851001313225, 0.4893718619458255, 0.5843586488076462, 0.5932361074299197, 0.5188632733630483, 0.5694359153081, 0.6742538555985772, 0.5612875608197094, 0.5808601342345567, 0.5394065333054449, 0.6092944259772948, 0.6040009467139711, 0.5907828166105977, 0.5659890563992632, 0.5733881762631945, 0.5815116760214637, 0.5310146219103876, 0.5302240012118417, 0.5618848916700613, 0.5665671621108543, 0.6293197198461632, 0.5405179430394141, 0.5977630913626886, 0.5814689708654298, 0.5605312147781794, 0.6575157681520838, 0.5671799221731652, 0.5765777445633956, 0.5432715249540162, 0.5628247242556871, 0.6056850485672605, 0.5098665912075953, 0.5470326423940849, 0.564281087903501, 0.5438414134559104, 0.5337930704929705, 0.5242687257142401, 0.5387855556656596, 0.5410988582245762, 0.522192033537983, 0.5246677561470495, 0.5667317879461023, 0.5361012667978715, 0.48585259804214476, 0.49885737574223193, 0.5140389775078539, 0.5296593475319294, 0.542971557177912, 0.5692691054657428, 0.5511191637015057, 0.4833762986351344, 0.5161863471906237, 0.5346019611257539, 0.5635662736372434, 0.5446670630588729, 0.5350232208079665, 0.6022679820303282, 0.5636356823019492, 0.5229274285532522, 0.5222959302891673, 0.5202323568559128, 0.5528144729905143, 0.5464128706188893, 0.5434020082328046, 0.5123158592749267, 0.5362281110659015, 0.5806639833316897, 0.581881632189974, 0.599778297173753, 0.5857916045472447]
val_losses_05_e4 = [0.5977624928864249, 0.5771655255425585, 0.5953775445257661, 0.5928439415284317, 0.5528305133763891, 0.5848028262818816, 0.5857290293831025, 0.5723953459167133, 0.5710493475198746, 0.5919734509321894, 0.5611137549807556, 0.579986428148555, 0.6509781344963687, 0.5459538367542908, 0.5374621068039079, 0.5488112548189442, 0.546562664591483, 0.5589793404958544, 0.6154108700090951, 0.5494831529629491, 0.5693454245363709, 0.5480730363922398, 0.5560585320213415, 0.606562853947173, 0.5450109678463344, 0.5430570852800007, 0.578323513378192, 0.6033858755861756, 0.5503094459537172, 0.559648377943213, 0.5671653230912495, 0.5507321799323507, 0.6003795936159844, 0.5744239025524933, 0.5756104240452287, 0.6054707229354955, 0.5920074015420719, 0.5615763012727681, 0.5616998859565624, 0.5994104306845769, 0.5475960315143975, 0.5659958452638918, 0.5747383664341739, 0.5582932896205108, 0.5574108120733804, 0.5379756765208975, 0.5648864555532915, 0.5349843366085177, 0.5520481442230462, 0.6005730813872205, 0.6155499942111273, 0.5642245883924247, 0.5788738451843715, 0.5390765714819414, 0.5666071537637363, 0.5726931307220111, 0.5539144782798133, 0.5780259164145393, 0.5504599887959278, 0.5369425696613145, 0.5571764950117055, 0.5436495766587501, 0.5389167188945478, 0.5388835461905402, 0.5531337973627731, 0.5535196260596714, 0.5639540449763737, 0.5399940906867494, 0.535193367378555, 0.547124096620692, 0.5587303983251544, 0.5149633880079227, 0.5309203547717881, 0.5306796964502682, 0.5389145589875479, 0.5433423947678865, 0.5490047798430833, 0.537039710113602, 0.5493356524592768, 0.5664258813553483, 0.5516579737410928, 0.5541133620660671, 0.5740191959334116, 0.5738034677984071, 0.5277600307969281, 0.5655930179042102, 0.555626796653671, 0.5768570818387679, 0.5738985407961547, 0.6007532765612985, 0.5623970644099869, 0.6140912676597163, 0.5865765585951561, 0.5502162091705921, 0.58705449833052, 0.5728525914197421, 0.5875620447153592, 0.5455798339234651, 0.5316349688890206, 0.529464841976653, 0.597501233328868, 0.5695028367051242, 0.5588308458563185, 0.5693718389655552, 0.5820215864338144, 0.5525828103949554, 0.581964083505373, 0.5806879829751314, 0.5835552951932823, 0.5836054922020348, 0.5790376487004496, 0.5796612267294069, 0.600391698470951, 0.5766839863610094, 0.5612427189837407, 0.5934007605061914, 0.5747890786750474, 0.5579111114905698, 0.5651346504905798, 0.5271851238760635, 0.5484017481769088, 0.5759551058502963, 0.5626381250628589, 0.5805758561966193, 0.5699895939035137, 0.5689836998272987, 0.5326194558700506, 0.5381367088016802, 0.5706369327585192, 0.5476145530051558, 0.599505764289494, 0.6096121247885001, 0.569212907966036, 0.5646458393248328, 0.576134149393026, 0.6473767191824251, 0.6040177196264267, 0.602314833633221, 0.5797374161490558, 0.6074808638026244, 0.5902396274091554, 0.5795859896788632, 0.5868929359164551, 0.6148955993843774, 0.5902183178785073, 0.5828540870090471, 0.5695856274479497, 0.6046258411268248, 0.5910232728415162, 0.5796862601363746, 0.5744502716255884, 0.6423626529039258, 0.5940411691247982, 0.5957139819642924, 0.6008491318156249, 0.60257096207925, 0.5904438663138091, 0.5986692294152114, 0.5772784585065215, 0.6033101682245297, 0.6382673939649206, 0.598614500821942, 0.594399074459598, 0.588400178799664, 0.5682313590154161, 0.587433031005581, 0.5958026227724813, 0.5872575790777693, 0.5963523689195187, 0.5926747096933588, 0.5725596236051435, 0.5681258196378276, 0.5846319990436526, 0.5465760068954343, 0.5595425550084915, 0.5635856718477541, 0.5787848530024507, 0.581515882137048, 0.5941440036697109, 0.6065460802429784]

plt.figure(figsize=(20, 6))
plt.plot(val_losses_01_e5[:100], label="Dropout: 01 LR: e-5")
plt.plot(val_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(val_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.title("Validation Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

## Evaluate cell-branch

```{python}
import seaborn as sns
sns.set_theme()
```

```{python}
training_losses_03_e4 = [0.675698807044905, 0.612693149216321, 0.5822500270240161, 0.55538758696342, 0.5417858331787343, 0.5343149754465842, 0.5245050222289805, 0.5180810300671325, 0.5142211330180265, 0.5118341385101786, 0.5096369476950898, 0.5080417035793772, 0.5045821453843798, 0.5042865537867254, 0.5051766591412681, 0.5015803751896839, 0.4978071536336626, 0.4976462405555102, 0.5009146144195479, 0.494302964940363, 0.4928907520916997, 0.4952956358997189, 0.4908441639676386, 0.4913695247805848, 0.4900263122149876, 0.4884096554347447, 0.4867439896476512, 0.4879794370154945, 0.4866973125204748, 0.4829795731573689, 0.48123342163708743, 0.4836369929265003, 0.4811498796453281, 0.48147047721609776, 0.47665706885104275, 0.4797660659770576, 0.47762949065286286, 0.47715271370751516, 0.47806144916281407, 0.47441054120355725, 0.4741459908534069, 0.47273080993671807, 0.4740006066098505, 0.4726093289803486, 0.46670978349082326, 0.4709784467609561, 0.47071326204708647, 0.4671992343299243, 0.46566829876023896, 0.4620323108167064, 0.4621849589201869, 0.46365699841051683, 0.4630254853744896, 0.46131438381817874, 0.4573461966855185, 0.45613120648325706, 0.45762452300713985, 0.45636457995492585, 0.4541787073320272, 0.4537952627454485, 0.4516971403238725, 0.45226901830459126, 0.4486257330495484, 0.4494794071937094, 0.4487500056928518, 0.44584276055803107, 0.4441651099798631, 0.44267880490847994, 0.4436746014624226, 0.44071826034662676, 0.43925706950985655, 0.4383760222366878, 0.4353641685174436, 0.43761750325864673, 0.4392012467189711, 0.435373559290049, 0.43389135964062747, 0.43562206321833086, 0.4336777372019632, 0.43275579810142517, 0.43036800501297934, 0.42853729761376674, 0.4248321123269139, 0.4229474256233293, 0.42438507566646655, 0.42190547439516807, 0.427480939699679, 0.4244727559235631, 0.42219060416124304, 0.41900118577237033, 0.41676089532521304, 0.4170994290283748, 0.4219626607943554, 0.41741084444279575, 0.4157008334082, 0.41636309210135014, 0.41498585440674607, 0.4128233249090156, 0.41163738588897547, 0.40901332546253594]
training_losses_05_e4 = [0.692860026748813, 0.6282237403246821, 0.5864698230003824, 0.5659790902721639, 0.5505157502330079, 0.5398973919907395, 0.5304317018207239, 0.5271968008304129, 0.5219072869845799, 0.5191776381463421, 0.5126556498663766, 0.5124870368412563, 0.512597204471121, 0.5105448340883061, 0.5097444233845692, 0.5047129714975551, 0.5062123743855224, 0.502318550129326, 0.5025190492065585, 0.4999410443159999, 0.4972131641543641, 0.4959335661664301, 0.4987358986114969, 0.49637774119571765, 0.49398826822942615, 0.49577553114112544, 0.49361458846500944, 0.49325562374932425, 0.4918017521196482, 0.48939589030888614, 0.48755315797669546, 0.4898426417185336, 0.48740015102892503, 0.4864226105261822, 0.48536273897910603, 0.48240275346502964, 0.4825655501715991, 0.4832718554808169, 0.48329702810365327, 0.48280938000095136, 0.4810353213427018, 0.47977769922237007, 0.4770133878503527, 0.47662119780267986, 0.4786968200790639, 0.4775685680155851, 0.47362663064684185, 0.4756065229980313, 0.4720883703961664, 0.4718800539873084, 0.46759830993049, 0.46908022067984756, 0.47045591960147937, 0.4662098239879219, 0.46517957959856304, 0.4670723098881391, 0.4651537172648372, 0.46287382926259724, 0.46181236967748523, 0.4583603557275266, 0.45936885172007036, 0.4567416754304146, 0.45598496162161534, 0.45276701876095365, 0.4664054969135596, 0.458146764307606, 0.4575128409327293, 0.4575727241379874, 0.4497524755341666, 0.4489652265091332, 0.45225267385949897, 0.44827273852971133, 0.44622356490213044, 0.45022388258758855, 0.44760157624069524, 0.44369197135068933, 0.4426819274620134, 0.4430526233449274, 0.4399057194894674, 0.43847543791848786, 0.4409788159691558, 0.43722868695551037, 0.4365321714050916, 0.434842764114847, 0.4349771433947038, 0.4373075341691776, 0.429138115474156, 0.43065380076972803, 0.43371221058222714, 0.433493971824646, 0.43118070522133184, 0.43156011189733234, 0.4271415934270742, 0.4286344890691796, 0.42809729490961346, 0.42667695636651953, 0.42590161124054265, 0.4230644325820767, 0.4223482043159251, 0.4159974924155644]
training_losses_03_e5 = [0.800453921970056, 0.7199268961439327, 0.6947891748681361, 0.6754362096591872, 0.6645641059291606, 0.6545197124383888, 0.6471955326138711, 0.6406530677055826, 0.6322150339885634, 0.6251123584046656, 0.6166531942328628, 0.6093864173305278, 0.6043623393895675, 0.5997733449449345, 0.5958099438219654, 0.588973192536101, 0.583137650879062, 0.5769800653263014, 0.5740834802997355, 0.5686096670676251, 0.5655296663848721, 0.5646744771879546, 0.5629409636769976, 0.5582302954732156, 0.5568266048723337, 0.5541286894253322, 0.549862767968859, 0.548338706396064, 0.5457244405941087, 0.5454189084014114, 0.5422123184009474, 0.5397129387271647, 0.539799270581226, 0.5392862029221593, 0.5364813719476972, 0.5366351026661542, 0.534922290213254, 0.5339802284629978, 0.531195625966909, 0.5294159559571013, 0.5294425627406762, 0.5284927432634392, 0.5276881067120299, 0.5267049773615233, 0.523356915736685, 0.5236320848367653, 0.522468106479061, 0.5222305777121563, 0.5192871343116371, 0.5206653487925627, 0.5184468687797079, 0.5175386071205139, 0.5173244683109984, 0.5161538860019372, 0.5148319516863141, 0.514515185234498, 0.5132179029133855, 0.5125433072751883, 0.5129199873427955, 0.512168361824386, 0.5109730137854206, 0.51001910530791, 0.5106566225995823, 0.5102218498989027, 0.5075029353706204, 0.5070797369188192, 0.5063100031444004, 0.5059519975769277, 0.5046572843376471, 0.5042212502080567, 0.5032916440039265, 0.5044004175127769, 0.5051844071368782, 0.5017319072266014, 0.50262998683112, 0.5026405271218748, 0.5010540710420025, 0.49998390370485735, 0.5016342650870887, 0.5010945267823278, 0.4995407790553813, 0.4995385706424713, 0.4976437858172825, 0.49788971397341514, 0.496819550285534, 0.498362875714594, 0.4954999831258034, 0.49378893934950535, 0.4958008095926168, 0.49454519274283426, 0.4942911638289082, 0.4924416310933171, 0.49394537173971836, 0.49325589014559373, 0.4918589068918812, 0.4917321630886623, 0.49122813100717505, 0.4900609504203407, 0.48969416107450214, 0.48942056967287645]

plt.figure(figsize=(20, 6))
plt.plot(training_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(training_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.plot(training_losses_03_e5[:100], label="Dropout: 03 LR: e-5")
plt.title("Training Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```

```{python}
val_losses_03_e4 = [0.6174275605347905, 0.5730789621380994, 0.5440935949339484, 0.5169024071554198, 0.5011517422912765, 0.503347889785349, 0.5017863092196249, 0.48883477157919947, 0.49073249319173995, 0.4847927857054411, 0.5013142661021573, 0.4869071549742761, 0.4829547226864056, 0.48118528810730815, 0.4812036189284638, 0.4781301861261799, 0.47820868631348995, 0.4773386960482075, 0.4824320249748926, 0.480206734072553, 0.48086952271252653, 0.47951198559607905, 0.4752156147121513, 0.47731513154767724, 0.4770038314979442, 0.4767560262749665, 0.47668815594520014, 0.47646944366232324, 0.47661291117215676, 0.4759363449402969, 0.4739391425230207, 0.47416514288770023, 0.4768753347605684, 0.4784325915966591, 0.47680291729251834, 0.4864626239686117, 0.4780594114839596, 0.4764542971214239, 0.4750240205848304, 0.47884714146600155, 0.4746546366789045, 0.48098647833740626, 0.4732058111333499, 0.47332065275115687, 0.4758382058926742, 0.47036058232732064, 0.47655311705422226, 0.47198429943001186, 0.4721818142128687, 0.4771453076905578, 0.4771994130454794, 0.4769522321485255, 0.4726017563447465, 0.4725753936889398, 0.47386161711094155, 0.4745679291060371, 0.4758194748067508, 0.47499856592094813, 0.4751710208663105, 0.47638567324972503, 0.4819096933751211, 0.4760606945866216, 0.4785442532849138, 0.4792356636837451, 0.4821936307597334, 0.47896383039272616, 0.4814981783393526, 0.4804186122695895, 0.47883591773736217, 0.48718848715733437, 0.47505854472626735, 0.4738781782832459, 0.47380198157616776, 0.4727738995621674, 0.48362602413135725, 0.47474323854829276, 0.47177966580773795, 0.4835026535021998, 0.4742894381502249, 0.4799186295836511, 0.4801142957523791, 0.4747737493828265, 0.4722931424196619, 0.47320797887161703, 0.47623883024619446, 0.4857254639594224, 0.4763428392636515, 0.4755068745491278, 0.4811605993848648, 0.4771341235533248, 0.47665159045344724, 0.4790970700500655, 0.46856369589367053, 0.484639449058658, 0.4786745477331816, 0.48043131817431345, 0.47619453899181674, 0.48189009084318674, 0.4807591090237137, 0.478564030932684]
val_losses_05_e4 = [0.6419082292675102, 0.5979892206888129, 0.5495867942371507, 0.536054374310222, 0.5343823228439275, 0.515336011665581, 0.5027524302475643, 0.5025390621519437, 0.4945000536250372, 0.495796812711841, 0.49392085223302357, 0.4865180602038864, 0.5083552305280727, 0.4852011936859493, 0.4852613932894964, 0.4828927123198544, 0.4877191314297001, 0.48113271376512345, 0.48751464725410854, 0.48301353876608133, 0.4868165080564736, 0.4916001534374961, 0.48565538347202497, 0.482910132321128, 0.48476578501889306, 0.4838913150512389, 0.48043671293850365, 0.4804275712392626, 0.4822854608514883, 0.47970550969569353, 0.4809284512579006, 0.4770965639257083, 0.47673737959270057, 0.4806039148438586, 0.47587763458272836, 0.47887827227585505, 0.4768334296497985, 0.47617465975510814, 0.4804375497964177, 0.47467990186962766, 0.4758885796487766, 0.48008138441691434, 0.48197491456122293, 0.4885203296685741, 0.4766237605227171, 0.47868284169774855, 0.4766858298413075, 0.474678636684905, 0.4801744605502943, 0.4781792683758005, 0.47962573975542167, 0.47714987767003747, 0.4807060099866268, 0.4837931131359434, 0.48030488791256926, 0.47925038124523023, 0.4890371062894807, 0.48433075747350707, 0.4852750588507548, 0.4811188063047228, 0.48111725049297305, 0.48762423474423205, 0.48361797924459415, 0.4836765579933668, 0.48451707745990613, 0.4856702433015308, 0.482368578876022, 0.4826834330158512, 0.481168753256763, 0.4824243420667022, 0.48505131497870396, 0.48307614300372825, 0.492097839604329, 0.4942983082176125, 0.48347854940560614, 0.4833815826551758, 0.4919258401776752, 0.47721509646325216, 0.47379500391709545, 0.4752723087359519, 0.4964332578391054, 0.48016681679843987, 0.4828241637153347, 0.47658152889161215, 0.47866693052062154, 0.4740869722662181, 0.49784298491303935, 0.4888496135708189, 0.48472750273934245, 0.47199899436783616, 0.4780525795734712, 0.4911647149681175, 0.4825079843510676, 0.4818333252503054, 0.48197731614982997, 0.48768681331272545, 0.49627865339717725, 0.4860260186404207, 0.48972489646751516, 0.48593782987037715]
val_losses_03_e5 = [0.8184201164837301, 0.7253768879131679, 0.7031607780143292, 0.6766917405337313, 0.6537731015769235, 0.6495978388473065, 0.636916814494307, 0.6293031660309674, 0.6280013592573848, 0.6218717933571252, 0.6122871611240136, 0.6118713930575517, 0.5997020832813569, 0.594473232318015, 0.5897982694806844, 0.5791568266649316, 0.5706710362956472, 0.5614088684537984, 0.5719305798955208, 0.554287750790589, 0.5470045322049273, 0.5411528557756521, 0.5524409093560964, 0.5317572326990809, 0.5295981310144828, 0.5299431194354148, 0.5320517122745514, 0.5135225694980065, 0.5213621445815929, 0.5168974055861034, 0.5169730008083538, 0.512568469465214, 0.5257633326262453, 0.5101028948369688, 0.5043028645271802, 0.5153951353400293, 0.507381825116429, 0.5033481680128696, 0.5062434120769919, 0.503864560249078, 0.5018460404698866, 0.5039660354165265, 0.5170396742594503, 0.5040134461256709, 0.49531953439225246, 0.5021574231829956, 0.5009359689089503, 0.4954150068933946, 0.4969608444367012, 0.49138692739236095, 0.49434730475836425, 0.4924737160658314, 0.49496322848500995, 0.49460432411980454, 0.49021323471173756, 0.49516941400340003, 0.48989392110031016, 0.4901541319206683, 0.4893772090873579, 0.4936502008107457, 0.4914219821021505, 0.48802952087708634, 0.4872884541532419, 0.48734231760902125, 0.49359358205412424, 0.4863736662116364, 0.48935919347470697, 0.48976531733561607, 0.4894164026218609, 0.4892006605646036, 0.48861591224252743, 0.48578963227515676, 0.4920431695280284, 0.48488708699706695, 0.4899433379190682, 0.4883510313764976, 0.4862857021554543, 0.48760280948485774, 0.48681380344133307, 0.49027794142709163, 0.48916466327479285, 0.48599132982483745, 0.48662321867733976, 0.4847728557830309, 0.4864814174871375, 0.4875059319238593, 0.4853560800534965, 0.4852571976880958, 0.4867483618920737, 0.4831344876846258, 0.48465347616341864, 0.48490988403341195, 0.4852902978441141, 0.4836530261231165, 0.4832952503305282, 0.4806854442088273, 0.4831821387701661, 0.47899487527617574, 0.4789877577419699, 0.4803242748671204]

plt.figure(figsize=(20, 6))
plt.plot(val_losses_03_e4[:100], label="Dropout: 03 LR: e-4")
plt.plot(val_losses_05_e4[:100], label="Dropout: 05 LR: e-4")
plt.plot(val_losses_03_e5[:100], label="Dropout: 03 LR: e-5")
plt.title("Validation Loss for the different hyperparameters")
plt.xlabel("Number of epochs")
plt.ylabel("Dice Loss")
plt.legend()
plt.show()
```
