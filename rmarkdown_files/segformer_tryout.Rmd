---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import albumentations as A

from datetime import datetime
from monai.losses import DiceLoss
from glob import glob
from torch.utils.data import DataLoader
from torch.optim import AdamW
from skimage.feature import peak_local_max
from torch.nn.functional import softmax, interpolate
from transformers import (
    SegformerForSemanticSegmentation,
    SegformerConfig,
    SegformerImageProcessor,
    get_polynomial_decay_schedule_with_warmup,
)

from src.utils.training import (
    run_training_segformer,
    run_validation_segformer,
    train,
)
from src.dataset import SegformerDataset

sns.set_theme()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")
```

## Data preprocessing

```{python}
data_dir = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
train_seg_files = glob(os.path.join(data_dir, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_dir, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_dir, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_dir, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_dir, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_dir, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
transforms = A.Compose(
    [
        A.GaussianBlur(blur_limit=(3, 7), p=0.5),
        A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),
        A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
        A.HorizontalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
    ]
)
image_processor = SegformerImageProcessor(do_resize=False, do_rescale=False)
```

```{python}
train_dataset = SegformerDataset(
    train_image_files,
    train_seg_files,
    transform=transforms,
    preprocessor=image_processor.preprocess,
)
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)

val_dataset = SegformerDataset(
    val_image_files,
    val_seg_files,
    preprocessor=image_processor.preprocess,
)
val_loader = DataLoader(val_dataset, batch_size=2)

test_dataset = SegformerDataset(
    test_image_files,
    test_seg_files,
    preprocessor=image_processor.preprocess,
)
test_loader = DataLoader(test_dataset, batch_size=2)
```

```{python}
it = iter(train_loader)
image_batch, label_batch = next(it)
image_batch, label_batch = image_batch.squeeze(), label_batch.squeeze()

print(image_batch.shape)
print(image_batch.unique())
```

```{python}
configuration = SegformerConfig(
  num_labels=3,
  num_channels=3,
)
model = SegformerForSemanticSegmentation(
  configuration
)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"Total Parameters: {total_params}")
print(f"Trainable Parameters: {trainable_params}")
```

```{python}
num_epochs = 5
optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_polynomial_decay_schedule_with_warmup(
    optimizer, num_warmup_steps=2, num_training_steps=num_epochs, power=1
)
loss_fn = DiceLoss(softmax=True, to_onehot_y=True)
current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
save_name = f"segformer_tryout_{current_time}"

train(
    num_epochs=num_epochs,
    train_dataloader=train_loader,
    val_dataloader=val_loader,
    model=model,
    loss_function=loss_fn,
    optimizer=optimizer,
    device=device,
    save_name=save_name,
    checkpoint_interval=5,
    break_after_one_iteration=True,
    scheduler=scheduler,
    training_func=run_training_segformer,
    validation_function=run_validation_segformer,
)
```

```{python}
image_batch, label_batch = next(iter(val_loader))
print(image_batch.shape)
```

```{python}
outputs = model(pixel_values=image_batch.to(device))
probabilities = softmax(outputs.logits, dim=1)
```

```{python}
print(image_batch.shape)
print(outputs.logits.shape)

argmaxed = probabilities[0].argmax(dim=0).detach().cpu()
print(argmaxed.shape)
print(argmaxed.unique())
```

```{python}
plt.imshow(argmaxed.numpy())
plt.show()
plt.imshow(val_dataset.get_image(0).permute(1, 2, 0).to(torch.uint8))
plt.show()
```

```{python}
from src.utils.metrics import calculate_f1_score_segformer
```

```{python}
configuration = SegformerConfig(
  num_labels=3,
  num_channels=3,
)
model = SegformerForSemanticSegmentation(
  configuration
)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model.load_state_dict(torch.load("outputs/models/segformer_tryout_20240211_133248_epochs-5.pth"))
model.to(device)
print()
```

```{python}
val_f1_score = calculate_f1_score_segformer(model, val_loader, device)
print(f"val f1 score: {val_f1_score}")
test_f1_score = calculate_f1_score_segformer(model, test_loader, device)
print(f"test f1 score: {test_f1_score}")
```
