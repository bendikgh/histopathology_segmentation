---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import albumentations as A
import matplotlib.pyplot as plt

from glob import glob
from monai.data import DataLoader
from monai.losses import DiceLoss
from torch.optim import Adam

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import TissueDataset, CellTissueDataset
from src.train_utils import train

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
```

```{python}
data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"

train_seg_files = glob(os.path.join(data_path, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_path, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_path, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_path, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_path, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_path, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
# remove_elements = ["392", "217", "008", "042", "053", "570", "558"]



train_tissue_predicted = glob(os.path.join(data_path, "annotations/train/pred_tissue/*"))

train_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_tissue_predicted
]
train_tissue_seg_files = [
    os.path.join(data_path, "annotations/train/tissue", image_number + ".png")
    for image_number in train_tissue_image_numbers
]
train_tissue_image_files = [
    os.path.join(data_path, "images/train/tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]


val_tissue_predicted = glob(os.path.join(data_path, "annotations/val/pred_tissue/*"))

val_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_tissue_predicted
]
val_tissue_seg_files = [
    os.path.join(data_path, "annotations/val/tissue", image_number + ".png")
    for image_number in val_tissue_image_numbers
]
val_tissue_image_files = [
    os.path.join(data_path, "images/val/tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]

test_tissue_predicted = glob(os.path.join(data_path, "annotations/test/pred_tissue/*"))

test_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_tissue_predicted
]
test_tissue_seg_files = [
    os.path.join(data_path, "annotations/test/tissue", image_number + ".png")
    for image_number in test_tissue_image_numbers
]
test_tissue_image_files = [
    os.path.join(data_path, "images/test/tissue", image_number + ".jpg")
    for image_number in test_tissue_image_numbers
]

```

```{python}
transforms = A.Compose([
    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # You can adjust the blur limit
    A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),  # Adjust var_limit for noise intensity
    A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
], additional_targets = {
    "mask1": "mask", 
    "mask2": "mask"
}
)
```

```{python}
# dataloader for tissue-model
train_tissue_dataset = TissueDataset(image_files=train_tissue_image_files, seg_files=train_tissue_seg_files, transform=transforms)
val_tissue_dataset = TissueDataset(image_files=val_tissue_image_files, seg_files=val_tissue_seg_files)
test_tissue_dataset = TissueDataset(image_files=test_tissue_image_files, seg_files=test_tissue_seg_files)

train_tissue_dataloader = DataLoader(dataset=train_tissue_dataset, batch_size=2, drop_last=True)
val_tissue_dataloader = DataLoader(dataset=val_tissue_dataset)
test_tissue_dataloader = DataLoader(dataset=test_tissue_dataset)
```

```{python}
# lst_image_seg = [(image, seg) for image, seg in iter(train_tissue_dataloader)]
image, seg = next(iter(train_tissue_dataloader))

```

```{python}
# image, seg = lst_image_seg[3]
```

```{python}
print(image.size())
print(seg.size())
```

```{python}
plt.imshow(image[0].permute(1, 2, 0))
plt.show()
plt.imshow(seg[0].permute(1, 2, 0))
plt.show()
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model_tissue = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_tissue.to(device)
print()
```

```{python}
from monai.metrics import DiceMetric
from monai.transforms import Compose, AsDiscrete

def calculate_dice_score(dataloader, model, device): 

    dice_metric = DiceMetric(include_background=True, reduction="mean")
    post_pred = Compose([AsDiscrete(argmax=True, dim=1, to_onehot=3)])

    model.eval()
    for (images, masks) in dataloader: 
        images, masks = images.to(device), masks.to(device)
        with torch.no_grad(): 
            outputs = model(images)
        outputs = post_pred(outputs)
        dice_metric(outputs, masks)

    dice_score = dice_metric.aggregate().item()
    dice_metric.reset()

    return dice_score
```

```{python}
loss_function = DiceLoss(softmax=True)
optimizer = Adam(model_tissue.parameters(), lr=1e-3)
```

num_epochs = 2
checkpoint_interval = 3

training_losses, validation_losses = train(
    num_epochs=num_epochs,
    train_dataloader=train_tissue_dataloader,
    val_dataloader=val_tissue_dataloader,
    model=model_tissue,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False,
    dropout_rate=dropout_rate, 
    backbone=backbone
)
print(training_losses)
print(validation_losses)

```{python}
on_idun = os.getcwd().startswith("/cluster")

if on_idun:
  data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
  print("Running on IDUN")
else: 
  data_path = "ocelot_data/"
  print("Running locally")
```

```{python}
model_tissue.load_state_dict(torch.load("outputs/models/2023-12-07_22-49-54_deeplabv3plus_cell_only_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_tissue_dataloader, model_tissue, device)
val_dice_score = calculate_dice_score(val_tissue_dataloader, model_tissue, device)
print("lr=0.0001, dropout=0.3, backbone=resnet50 (Baseline)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")
```

```{python}
model_tissue.eval()
# image, seg = lst_image_seg[6]
image, seg = image.to(device)[0].unsqueeze(0), seg.to(device)[0].unsqueeze(0)
with torch.no_grad():
    prediction = model_tissue(image).cpu()

prediction = torch.argmax(prediction, 1)
convert = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
prediction = convert[prediction]

plt.subplot(1, 3, 1)
plt.imshow(image[0].permute(1, 2, 0).cpu())

plt.subplot(1, 3, 2)
plt.imshow(seg[0].permute(1, 2, 0).cpu())

plt.subplot(1, 3, 3)
plt.imshow(prediction[0])

plt.show()

print(prediction[0].size())
```

```{python}
# Function for crop and scale tissue image
from src.utils import crop_and_upscale_tissue, get_metadata

def get_tissue_croped_scaled_tensor(tissue_tensor, image_file, data_path, image_size: int = 1024):

    data_id = image_file.split("/")[-1].split(".")[0]
    data_object = get_metadata(data_path)["sample_pairs"][data_id]

    offset_tensor = (
        torch.tensor([data_object["patch_x_offset"], data_object["patch_y_offset"]])
        * image_size
    )
    scaling_value = data_object["cell"]["resized_mpp_x"] / data_object["tissue"]["resized_mpp_x"]

    cropped_scaled = crop_and_upscale_tissue(
        tissue_tensor, offset_tensor, scaling_value
    )

    return cropped_scaled
```

from monai.data import ImageDataset
from torchvision.transforms import ToTensor
from PIL import Image
import numpy as np
from torch.nn.functional import softmax

class CellTissueDataset(ImageDataset):
    def __init__(self, image_files, seg_files, image_tissue_files, model_tissue, transform=None) -> None:
        self.image_files = image_files
        self.seg_files = seg_files
        self.to_tensor = ToTensor()
        self.image_tissue_files = image_tissue_files
        
        self.model_tissue = model_tissue
        self.transform = transform


    def __getitem__(self, idx):
        # Cell
        image_path = self.image_files[idx]
        seg_path = self.seg_files[idx]

        image = self.to_tensor(Image.open(image_path).convert("RGB"))
        seg = self.to_tensor(Image.open(seg_path).convert("RGB"))*255
        
        # tissue
        image_path = self.image_tissue_files[idx]
        image_tissue = self.to_tensor(Image.open(image_path).convert("RGB")).unsqueeze(0)
        image_tissue = image_tissue.to(device)

        image_tissue = model_tissue(image_tissue)
        
        image_tissue = image_tissue.detach().cpu().squeeze(0)

        # max_values, _ = image_tissue.max(0, keepdim=True)
        image_tissue = softmax(image_tissue, 0)

        # Scale and crop 
        image_tissue = get_tissue_croped_scaled_tensor(image_tissue, image_path, data_path)
        

        if self.transform:
            transformed = self.transform(
                image=np.array(image.permute((1, 2, 0))),
                mask1=np.array(seg.permute((1, 2, 0))),
                mask2=np.array(image_tissue.permute((1, 2, 0))),
            )
            image = torch.tensor(transformed["image"]).permute((2, 0, 1))
            cell_seg = torch.tensor(transformed["mask1"]).permute((2, 0, 1))
            tissue_seg = torch.tensor(transformed["mask2"]).permute((2, 0, 1))

            image = torch.cat((image, tissue_seg), dim=0)

        return image, seg

```{python}
# Dataloaders for cell-model
model_tissue.eval()
train_cell_tissue_dataset = CellTissueDataset(image_files=train_image_files, seg_files=train_seg_files, image_tissue_files=train_tissue_predicted, transform=transforms)
val_cell_tissue_dataset = CellTissueDataset(image_files=val_image_files, seg_files=val_seg_files, image_tissue_files=val_tissue_predicted)
test_cell_tissue_dataset = CellTissueDataset(image_files=test_image_files, seg_files=test_seg_files, image_tissue_files=test_tissue_predicted)

train_cell_tissue_dataloader = DataLoader(dataset=train_cell_tissue_dataset, batch_size=2, drop_last=True)
val_cell_tissue_dataloader = DataLoader(dataset=val_cell_tissue_dataset)
test_cell_tissue_dataloader = DataLoader(dataset=test_cell_tissue_dataset)
```

```{python}
images, labels = next(iter(train_cell_tissue_dataloader))

```

```{python}
# images, labels = next(iter(train_cell_tissue_dataloader))

# lst_image_seg = [(image, seg) for image, seg in iter(train_cell_tissue_dataloader)]
```

```{python}
# images, labels = lst_image_seg[2]
```

```{python}
cell_images = images[0, 0:3]
print(cell_images.size())

tissue_images = images[0, 3:]
print(tissue_images.size())

label_image = labels[0]
```

```{python}
# print(tissue_images)

tissue_images = torch.argmax(tissue_images, 0)
print(tissue_images.unique())
```

```{python}

convert = torch.tensor([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
tissue_images = convert[tissue_images]

print((tissue_images == 0).sum()/(tissue_images == 1).sum())
```

```{python}
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

plt.figure(figsize=(16, 8))  # Adjust the width and height as needed

plt.subplot(1, 3, 1)
plt.title("cell image")
plt.axis("off")
plt.imshow(cell_images.permute(1, 2, 0))

plt.subplot(1, 3, 2)
plt.title("tissue image")
plt.imshow(tissue_images)
plt.axis("off")

plt.subplot(1, 3, 3)
plt.title("val image")
plt.imshow(label_image.permute(1, 2, 0))
plt.axis("off")


plt.show()
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
model_cell = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate,
    num_channels=6
)
model_cell.to(device)
model_cell.train()
print()

loss_function = DiceLoss(softmax=True)
optimizer = Adam(model_cell.parameters(), lr=1e-3)
```

## Training cell model with tissue information

num_epochs = 2
checkpoint_interval = 3

training_losses, validation_losses = train(
    num_epochs=num_epochs,
    train_dataloader=train_cell_tissue_dataloader,
    val_dataloader=val_cell_tissue_dataloader,
    model=model_cell,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False, 
    dropout_rate=dropout_rate, 
    backbone=backbone
)
print(training_losses)
print(validation_losses)

```{python}
# outputs/models/2023-12-08_11-54-15_deeplabv3plus_tissue-cell_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-170.pth
model_cell.load_state_dict(torch.load("outputs/models/2023-12-12_10-35-57_deeplabv3plus_tissue-cell_lr-1e-05_dropout-0.3_backbone-resnet50_epochs-100.pth"))
test_dice_score = calculate_dice_score(test_cell_tissue_dataloader, model_cell, device)
val_dice_score = calculate_dice_score(val_cell_tissue_dataloader, model_cell, device)
print("lr=0.0001, dropout=0.3, backbone=resnet50 (Baseline)")
print(f"Dice score on test set: {test_dice_score}")
print(f"Dice score on validation set: {val_dice_score}")

# baseline: 0.3 e-4
# Dice score on test set: 0.58343505859375
# Dice score on validation set: 0.6106350421905518

# Dropout: 0.5
# Dice score on test set: 0.581584095954895
# Dice score on validation set: 0.6039111018180847

# LR: e-5
# Dice score on test set: 0.5805562138557434
# Dice score on validation set: 0.6140695810317993

```
