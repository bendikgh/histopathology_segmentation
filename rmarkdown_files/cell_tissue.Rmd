---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import albumentations as A

from glob import glob
from monai.data import DataLoader
from monai.losses import DiceLoss
from torch.optim import Adam

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import CellOnlyDataset
from src.train_utils import train

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
```

```{python}
data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"

train_seg_files = glob(os.path.join(data_path, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_path, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_path, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_path, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_path, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_path, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
train_tissue_seg_files = glob(os.path.join(data_path, "annotations/train/tissue/*"))

train_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_tissue_seg_files
]
train_tissue_image_files = [
    os.path.join(data_path, "images/train/tissue", image_number + ".jpg")
    for image_number in train_image_numbers
]


val_tissue_seg_files = glob(os.path.join(data_path, "annotations/val/tissue/*"))
val_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_tissue_image_files = [
    os.path.join(data_path, "images/val/tissue", image_number + ".jpg")
    for image_number in val_image_numbers
]



test_tissue_seg_files = glob(os.path.join(data_path, "annotations/test/tissue/*"))
test_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_tissue_image_files = [
    os.path.join(data_path, "images/test/tissue", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
transforms = A.Compose([
    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # You can adjust the blur limit
    A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),  # Adjust var_limit for noise intensity
    A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
    A.HorizontalFlip(p=0.5),
    A.RandomRotate90(p=0.5)
])
```

```{python}
# dataloader for tissue-model
train_tissue_dataset = CellOnlyDataset(image_files=train_tissue_image_files, seg_files=train_tissue_seg_files, transform=transforms)
val_tissue_dataset = CellOnlyDataset(image_files=val_tissue_image_files, seg_files=val_tissue_seg_files)
test_tissue_dataset = CellOnlyDataset(image_files=test_tissue_image_files, seg_files=test_tissue_seg_files)

train_tissue_dataloader = DataLoader(dataset=train_tissue_dataset, batch_size=2, drop_last=True)
val_tissue_dataloader = DataLoader(dataset=val_tissue_dataset)
test_tissue_dataloader = DataLoader(dataset=test_tissue_dataset)
```

```{python}
backbone = "resnet34"
dropout_rate = 0.3
model_tissue = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_tissue.to(device)
print()
```

```{python}
loss_function = DiceLoss(softmax=True)
optimizer = Adam(model_tissue.parameters(), lr=1e-3)
```

num_epochs = 2
checkpoint_interval = 3

training_losses, validation_losses = train(
    num_epochs=num_epochs,
    train_dataloader=train_tissue_dataloader,
    val_dataloader=val_tissue_dataloader,
    model=model_tissue,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False, 
    dropout_rate=dropout_rate, 
    backbone=backbone
)
print(training_losses)
print(validation_losses)

```{python}
on_idun = os.getcwd().startswith("/cluster")

if on_idun:
  data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
  print("Running on IDUN")
else: 
  data_path = "ocelot_data/"
  print("Running locally")
```

```{python}
# Function for crop and scale tissue image
from src.utils import crop_and_upscale_tissue, get_metadata

def get_tissue_croped_scaled_tensor(tissue_tensor, image_file, data_path, image_size: int = 1024):

    data_id = image_file.split("/")[-1].split(".")[0]
    data_object = get_metadata(data_path)["sample_pairs"][data_id]

    offset_tensor = (
        torch.tensor([data_object["patch_x_offset"], data_object["patch_y_offset"]])
        * image_size
    )
    scaling_value = data_object["cell"]["resized_mpp_x"] / data_object["tissue"]["resized_mpp_x"]

    cropped_scaled = crop_and_upscale_tissue(
        tissue_tensor, offset_tensor, scaling_value
    )

    return cropped_scaled
```

```{python}
from monai.data import ImageDataset
from torchvision.transforms import ToTensor
from PIL import Image
import numpy as np

class CellTissueDataset(ImageDataset):
    def __init__(self, image_files, seg_files, image_tissue_files, model_tissue, cell_transform=None, tissue_transform=None) -> None:
        self.image_files = image_files
        self.seg_files = seg_files
        self.to_tensor = ToTensor()
        self.cell_transform = cell_transform

        self.image_tissue_files = image_tissue_files
        self.model_tissue = model_tissue
        self.tissue_transform = tissue_transform


    def __getitem__(self, idx):
        # Cell
        image_path = self.image_files[idx]
        seg_path = self.seg_files[idx]

        image = self.to_tensor(Image.open(image_path).convert("RGB"))
        seg = self.to_tensor(Image.open(seg_path).convert("RGB"))*255

        if self.cell_transform:
            transformed = self.cell_transform(
                image=np.array(image.permute((1, 2, 0))),
                mask=np.array(seg.permute((1, 2, 0))),
            )
            image = torch.tensor(transformed["image"]).permute((2, 0, 1))
            seg = torch.tensor(transformed["mask"]).permute((2, 0, 1))

        
        # tissue
        image_path = self.image_tissue_files[idx]
        image_tissue = self.to_tensor(Image.open(image_path).convert("RGB")).unsqueeze(0)
        image_tissue = image_tissue.to(device)

        image_tissue = model_tissue(image_tissue)
        
        image_tissue = image_tissue.cpu().squeeze(0)


        # Scale and crop 
        image_tissue = get_tissue_croped_scaled_tensor(image_tissue, image_path, data_path)

        if self.tissue_transform:
            transformed = self.tissue_transform(
                image=np.array(image_tissue.permute((1, 2, 0))),
            )
            image_tissue = torch.tensor(transformed["image"]).permute((2, 0, 1))
        
        image = torch.cat([image, image_tissue], dim = 0)
            
        return image, seg
```

```{python}
# Dataloaders for cell-model
model_tissue.eval()
train_cell_tissue_dataset = CellTissueDataset(image_files=train_image_files, seg_files=train_seg_files, image_tissue_files=train_tissue_image_files, model_tissue=model_tissue, cell_transform=transforms, tissue_transform=transforms)
val_cell_tissue_dataset = CellTissueDataset(image_files=val_image_files, seg_files=val_seg_files, image_tissue_files=val_tissue_image_files, model_tissue=model_tissue)
test_cell_tissue_dataset = CellTissueDataset(image_files=test_image_files, seg_files=test_seg_files, image_tissue_files=test_tissue_image_files, model_tissue=model_tissue)

train_cell_tissue_dataloader = DataLoader(dataset=train_cell_tissue_dataset, batch_size=2, drop_last=True)
val_cell_tissue_dataloader = DataLoader(dataset=val_cell_tissue_dataset)
test_cell_tissue_dataloader = DataLoader(dataset=test_cell_tissue_dataset)
```

```{python}
backbone = "resnet34"
dropout_rate = 0.3
model_cell = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate
)
model_cell.to(device)
print()
```

```{python}
## Training cell model with tissue information

num_epochs = 2
checkpoint_interval = 3

training_losses, validation_losses = train(
    num_epochs=num_epochs,
    train_dataloader=train_cell_tissue_dataloader,
    val_dataloader=val_cell_tissue_dataloader,
    model=model_cell,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False, 
    dropout_rate=dropout_rate, 
    backbone=backbone
)
print(training_losses)
print(validation_losses)
```
