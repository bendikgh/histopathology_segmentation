---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import torch
import time

import matplotlib.pyplot as plt

from glob import glob
from tqdm import tqdm
from monai.data import ImageDataset, DataLoader
from monai.losses import DiceLoss
from torch.optim import Adam

from deeplabv3.network.modeling import _segm_resnet

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
```

```{python}
train_seg_files = glob("ocelot_data/annotations/train/segmented_cell/*")
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join("ocelot_data/images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob("ocelot_data/annotations/val/segmented_cell/*")
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join("ocelot_data/images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob("ocelot_data/annotations/test/segmented_cell/*")
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join("ocelot_data/images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
train_dataset = ImageDataset(image_files=train_image_files, seg_files=train_seg_files)
val_dataset = ImageDataset(image_files=val_image_files, seg_files=val_seg_files)
test_dataset = ImageDataset(image_files=test_image_files, seg_files=test_seg_files)

train_dataloader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)
val_dataloader = DataLoader(dataset=val_dataset)
test_dataloader = DataLoader(dataset=test_dataset)
```

```{python}
model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name="resnet50",
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
)
model.to(device)
print()
```

```{python}
loss_function = DiceLoss()
optimizer = Adam(model.parameters(), lr=1e-3)
```

```{python}
from src.train_utils import train
```

```{python}
num_epochs = 2
training_losses, validation_losses = train(
    num_epochs=num_epochs,
    train_dataloader=train_dataloader,
    val_dataloader=val_dataloader,
    model=model,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=1
)
print(training_losses)
print(validation_losses)
```
