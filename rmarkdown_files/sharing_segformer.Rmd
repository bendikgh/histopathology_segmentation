---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import cv2
import os
import sys
import time
import torch
import matplotlib.pyplot as plt 

import albumentations as A
import torch.nn as nn

from abc import ABC, abstractmethod
from datetime import datetime
from glob import glob
from monai.losses import DiceLoss, DiceCELoss
from torch.utils.data import DataLoader
from torch.optim import AdamW
from transformers import (
    get_polynomial_decay_schedule_with_warmup,
)
from typing import Union, Optional, List


sys.path.append(os.getcwd())

# Local imports
from ocelot23algo.user.inference import (
    Deeplabv3CellOnlyModel,
    Deeplabv3TissueCellModel,
    Deeplabv3TissueFromFile,
    EvaluationModel,
    SegformerCellOnlyModel,
    SegformerTissueFromFile,
)
from ocelot23algo.user.inference import (
    SegformerSharingModel as SegformerSharingModule,
    SegformerSharingSumModel as SegformerSharingSumModule,
)

from src.dataset import (
    CellOnlyDataset,
    CellTissueDataset,
    SegformerSharingDataset,
    TissueDataset,
)
from src.utils.constants import (
    CELL_IMAGE_MEAN,
    CELL_IMAGE_STD,
    IDUN_OCELOT_DATA_PATH,
)
from src.utils.metrics import (
    create_cellwise_evaluation_function,
    create_tissue_evaluation_function,
)
from src.utils.utils import (
    get_metadata_dict,
    get_metadata_with_offset,
    get_ocelot_files,
)
from src.utils import training
from src.utils.training import run_training_sharing2
from src.models import (
    CustomSegformerModel,
    DeepLabV3plusModel,
    SegformerSharingModel,
    SegformerSharingSumModel,
)
from src.loss import DiceLossWrapper
```

```{python}
test_cell_image_files, test_cell_target_files = get_ocelot_files(
    data_dir=IDUN_OCELOT_DATA_PATH,
    partition="test",
    zoom="cell",
    macenko=True,
)
test_tissue_image_files, test_tissue_target_files = get_ocelot_files(
    data_dir=IDUN_OCELOT_DATA_PATH,
    partition="test",
    zoom="tissue",
    macenko=True,
)

# Removing image numbers from tissue images to match cell and tissue
image_numbers = [x.split("/")[-1].split(".")[0] for x in test_cell_image_files]
test_tissue_image_files = [
    file
    for file in test_tissue_image_files
    if file.split("/")[-1].split(".")[0] in image_numbers
]
test_tissue_target_files = [
    file
    for file in test_tissue_target_files
    if file.split("/")[-1].split(".")[0] in image_numbers
]
len1 = len(test_cell_image_files)
len2 = len(test_cell_target_files)
len3 = len(test_tissue_image_files)
len4 = len(test_tissue_target_files)
assert len1 == len2 == len3 == len4

metadata = get_metadata_dict(data_dir=IDUN_OCELOT_DATA_PATH)

test_dataset = SegformerSharingDataset(
    cell_image_files=test_cell_image_files,
    cell_target_files=test_cell_target_files,
    tissue_image_files=test_tissue_image_files,
    tissue_target_files=test_tissue_target_files,
    metadata=metadata,
    transform=None,
)

test_dataloader = DataLoader(
    dataset=test_dataset,
    batch_size=2,
    shuffle=True,
    drop_last=True,
)
```

```{python}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = SegformerSharingSumModel(
    backbone_model="b3",
    pretrained_dataset="ade",
    output_image_size=1024,
    input_image_size=1024,
)
model.load_state_dict(torch.load("outputs/models/20240417_182303/Segformer_Sharing_backbone-b3_best.pth"))
model.to(device)
```

```{python}
it = iter(test_dataloader)
```

```{python}
next(it)
images, masks, offsets = next(it)
images, masks = images.to(device), masks.to(device)

outputs = model(images, offsets)
```

```{python}
def show_batch_predictions(images, masks, outputs): 
    batch_size = images.size()[0]

    outputs = torch.argmax(outputs, dim=1)
    for i in range(batch_size): 
        plt.figure(figsize=(16, 8))
        plt.subplot(1, 3, 1)
        plt.axis("off")
        plt.imshow((images[i]*255).cpu().permute(1, 2, 0).to(torch.uint8))

        plt.subplot(1, 3, 2)
        plt.axis("off")
        plt.imshow(masks[i].cpu().permute(1, 2, 0))

        plt.subplot(1, 3, 3)
        plt.axis("off")
        plt.imshow(outputs[i].detach().cpu().squeeze())
        plt.show()

show_batch_predictions(images[:, :3], masks[:, :3], outputs[0])
```
