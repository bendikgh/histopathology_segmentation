---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: master_project
    language: python
    name: python3
---

```{python}
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

## Load ViTMAE


python scripts/run_mae.py \
    --dataset_name "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data" \
    --train_dir "images/train/cell/*" \
    --output_dir "/cluster/home/bendikgh/master_project/outputs/ViTMAE" \
    --remove_unused_columns False \
    --label_names pixel_values \
    --do_train \
    --do_eval \
    --overwrite_output_dir \
    --image_processor_name "/cluster/home/bendikgh/master_project/config/preprocessor_config.json" \
    --config_name "/cluster/home/bendikgh/master_project/config/ViT_config" \
    --num_train_epochs 300


```{python}
from transformers import ViTMAEForPreTraining, AutoImageProcessor
```

```{python}
model = ViTMAEForPreTraining.from_pretrained("/cluster/home/bendikgh/master_project/outputs/ViTMAE/checkpoint-34000")
# image_processor = AutoImageProcessor.from_pretrained("/cluster/home/bendikgh/master_project/outputs/ViTMAE/checkpoint-34000")
```

## Make datasets and dataloaders for tissue

```{python}
import argparse
import os
import torch
import albumentations as A

from glob import glob
from monai.losses import DiceLoss
from torch.utils.data import DataLoader
from torch.optim import Adam
from torch.nn import MSELoss

from src.deeplabv3.network.modeling import _segm_resnet
from src.utils.utils_train import train
from src.dataset import TissueDataset
```

```{python}
data_dir = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"
```

```{python}
train_tissue_seg_files = glob(os.path.join(data_dir, "annotations/train/tissue/*"))
train_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_tissue_seg_files
]
train_tissue_image_files = [
    os.path.join(data_dir, "images/train/tissue", image_number + ".jpg")
    for image_number in train_tissue_image_numbers
]

val_tissue_seg_files = glob(os.path.join(data_dir, "annotations/val/tissue/*"))
val_tissue_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_tissue_seg_files
]
val_tissue_image_files = [
    os.path.join(data_dir, "images/val/tissue", image_number + ".jpg")
    for image_number in val_tissue_image_numbers
]
```

```{python}
batch_size = 1

train_tissue_dataset = TissueDataset(
    image_files=train_tissue_image_files,
    seg_files=train_tissue_seg_files,
)
val_tissue_dataset = TissueDataset(
    image_files=val_tissue_image_files, seg_files=val_tissue_seg_files
)

train_tissue_dataloader = DataLoader(
    dataset=train_tissue_dataset, batch_size=batch_size, drop_last=True, shuffle=True
)
val_tissue_dataloader = DataLoader(
    dataset=val_tissue_dataset, batch_size=batch_size, drop_last=True
)
```

```{python}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# image_processor = AutoImageProcessor.from_pretrained("facebook/vit-mae-base")
optimizer = Adam(model.parameters(), lr=1e-4)
loss_function = MSELoss()
num_epochs = 100
checkpoint_interval = 10,
```

```{python}
# Github implementation:
# https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining

# Model doc:
# https://huggingface.co/docs/transformers/model_doc/vit_mae#transformers.ViTMAEForPreTraining
```

## Try predicting images

```{python}
from transformers import ViTFeatureExtractor
import requests
from PIL import Image
```

```{python}
feature_extractor = ViTFeatureExtractor.from_pretrained("/cluster/home/bendikgh/master_project/outputs/ViTMAE/checkpoint-34000")
image_path = "/cluster/home/bendikgh/master_project/ocelot_data/images/train/tissue/001.jpg"
image = Image.open(image_path)
image
```

```{python}
pixel_values = feature_extractor(image, return_tensors="pt").pixel_values
```

```{python}
import torch
import numpy as np
import matplotlib.pyplot as plt

imagenet_mean = np.array(feature_extractor.image_mean)
imagenet_std = np.array(feature_extractor.image_std)

def show_image(image, title=''):
    # image is [H, W, 3]
    assert image.shape[2] == 3
    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())
    plt.title(title, fontsize=16)
    plt.axis('off')
    return

def visualize(pixel_values, model):
    # forward pass
    outputs = model(pixel_values)
    y = model.unpatchify(outputs.logits)
    y = torch.einsum('nchw->nhwc', y).detach().cpu()
    
    # visualize the mask
    mask = outputs.mask.detach()
    mask = mask.unsqueeze(-1).repeat(1, 1, model.config.patch_size**2 *3)  # (N, H*W, p*p*3)
    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping
    mask = torch.einsum('nchw->nhwc', mask).detach().cpu()
    
    x = torch.einsum('nchw->nhwc', pixel_values)

    # masked image
    im_masked = x * (1 - mask)

    # MAE reconstruction pasted with visible patches
    im_paste = x * (1 - mask) + y * mask

    # make the plt figure larger
    plt.rcParams['figure.figsize'] = [24, 24]

    plt.subplot(1, 4, 1)
    show_image(x[0], "original")

    plt.subplot(1, 4, 2)
    show_image(im_masked[0], "masked")

    plt.subplot(1, 4, 3)
    show_image(y[0], "reconstruction")

    plt.subplot(1, 4, 4)
    show_image(im_paste[0], "reconstruction + visible")

    plt.show()
```

```{python}
visualize(pixel_values, model)
```

## Training deeplabv3 with vitmae backbone

```{python}
from src.deeplabv3.network.modeling import _segm_vitmae

backbone_path = "/cluster/home/bendikgh/master_project/outputs/ViTMAE/checkpoint-34000"
learning_rate = 1e-4

model = _segm_vitmae(
    backbone_path=backbone_path,
    num_classes=3,
    output_stride=8,
)
model.to(device)

loss_function = DiceLoss(softmax=True)
optimizer = Adam(model.parameters(), lr=learning_rate)

train(
    num_epochs=num_epochs,
    train_dataloader=train_tissue_dataloader,
    val_dataloader=val_tissue_dataloader,
    model=model,
    loss_function=loss_function,
    optimizer=optimizer,
    device=device,
    checkpoint_interval=checkpoint_interval,
    break_after_one_iteration=False,
    backbone="ViT",
    model_name = "tissue_branch"
)
```
