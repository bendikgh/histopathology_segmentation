---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: specialization_project
    language: python
    name: python3
---

```{python}
# Fixing automatic autoreload
# %load_ext autoreload
# %autoreload 2
```

```{python}
import os 

# Making sure we are running the code from the root directory
current_directory = os.getcwd()
if current_directory.endswith("notebooks"):
    os.chdir("..")
    print("Changed directory to:", os.getcwd())
else:
    print("Directory was already correct, so did not change.")
```

```{python}
import albumentations as A
import cv2
import matplotlib.pyplot as plt
import torch
import numpy as np
import seaborn as sns

from glob import glob
from monai.data import DataLoader

from src.deeplabv3.network.modeling import _segm_resnet
from src.dataset import CellTissueDataset
from src.utils.metrics import calculate_f1_score
from torch.nn.functional import one_hot 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device: {device}")
sns.set_theme()
```

```{python}
data_path = "/cluster/projects/vc/data/mic/open/OCELOT/ocelot_data"

train_seg_files = glob(os.path.join(data_path, "annotations/train/segmented_cell/*"))
train_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in train_seg_files
]
train_image_files = [
    os.path.join(data_path, "images/train/cell", image_number + ".jpg")
    for image_number in train_image_numbers
]

val_seg_files = glob(os.path.join(data_path, "annotations/val/segmented_cell/*"))
val_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in val_seg_files
]
val_image_files = [
    os.path.join(data_path, "images/val/cell", image_number + ".jpg")
    for image_number in val_image_numbers
]

test_seg_files = glob(os.path.join(data_path, "annotations/test/segmented_cell/*"))
test_image_numbers = [
    file_name.split("/")[-1].split(".")[0] for file_name in test_seg_files
]
test_image_files = [
    os.path.join(data_path, "images/test/cell", image_number + ".jpg")
    for image_number in test_image_numbers
]
```

```{python}
val_tissue_seg = []

for img_path in val_seg_files:
    ending = img_path.split("/")[-1].split(".")[0]
    tissue_seg_path = glob(
        os.path.join(data_path, "annotations/val/cropped_tissue/" + ending + "*")
    )[0]
    input_img_path = glob(
        os.path.join(data_path, "images/val/cell/" + ending + "*")
    )[0]
    val_tissue_seg.append(tissue_seg_path)
```

```{python}
train_tissue_predicted = glob(os.path.join(data_path, "annotations/train/pred_tissue/*"))
val_tissue_predicted = glob(os.path.join(data_path, "annotations/val/pred_tissue/*"))
test_tissue_predicted = glob(os.path.join(data_path, "annotations/test/pred_tissue/*"))
```

```{python}
transforms = A.Compose(
    [
        A.GaussianBlur(blur_limit=(3, 7), p=0.5),
        A.GaussNoise(var_limit=(0.1, 0.3), p=0.5),
        A.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.2, hue=0.1, p=1),
        A.HorizontalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
    ],
    additional_targets={"mask1": "mask", "mask2": "mask"},
)
```

```{python}
batch_size = 3

train_cell_tissue_dataset = CellTissueDataset(
    cell_image_files=train_image_files,
    cell_target_files=train_seg_files,
    tissue_pred_files=train_tissue_predicted
)
val_cell_tissue_dataset = CellTissueDataset(
    cell_image_files=val_image_files,
    cell_target_files=val_seg_files,
    tissue_pred_files=val_tissue_predicted
)
test_cell_tissue_dataset = CellTissueDataset(
    cell_image_files=test_image_files,
    cell_target_files=test_seg_files,
    tissue_pred_files=test_tissue_predicted,
)

train_cell_tissue_dataloader = DataLoader(
    dataset=train_cell_tissue_dataset, batch_size=batch_size, drop_last=True
)
val_cell_tissue_dataloader = DataLoader(
    dataset=val_cell_tissue_dataset, batch_size=batch_size
)
test_cell_tissue_dataloader = DataLoader(
    dataset=test_cell_tissue_dataset, batch_size=batch_size
)
```

```{python}
val_tissue_dataset = CellTissueDataset(
    cell_image_files=val_image_files,
    cell_target_files=val_seg_files,
    tissue_pred_files=val_tissue_seg,
)
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
tissue_cell_model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate,
    num_channels=6,
)
tissue_cell_model.to(device)
tissue_cell_model.load_state_dict(
    torch.load(
        "outputs/models/20240218_223520_deeplabv3plus_cell_branch_lr-0.0001_dropout-0.3_backbone-resnet50_epochs-100.pth"
    )
)
tissue_cell_model.eval()
print()
```

```{python}
backbone = "resnet50"
dropout_rate = 0.3
tissue_model = _segm_resnet(
    name="deeplabv3plus",
    backbone_name=backbone,
    num_classes=3,
    output_stride=8,
    pretrained_backbone=True,
    dropout_rate=dropout_rate,
    num_channels=3,
)
tissue_model.to(device)
tissue_model.load_state_dict(
    torch.load(
        "outputs/models/20240221_212019_deeplabv3plus_tissue_branch_lr-0.0001_dropout-0.1_backbone-resnet50_epochs-50.pth"
    )
)
tissue_model.eval()
print()
```

```{python}
# val_score = calculate_f1_score(model=tissue_cell_model, dataloader=val_cell_tissue_dataloader, device=device)
# print(f"Validation score: {val_score}")
# test_score = calculate_f1_score(model=tissue_cell_model, dataloader=test_cell_tissue_dataloader, device=device)
# print(f"Test score: {test_score}")
```

```{python}
index = 2

image, label_cell = val_cell_tissue_dataset[index]

file_name = val_cell_tissue_dataset.cell_image_files[index]
num = file_name.split("/")[-1].split(".")[0]

val_tissue_image_path = os.path.join(data_path, "images", "val", "tissue", num + ".jpg")
val_tissue_ground_truth_path = os.path.join(data_path, "annotations", "val", "tissue", num + ".png")

tissue_ground_truth = torch.from_numpy(cv2.imread(val_tissue_ground_truth_path)).permute(2, 0, 1)
tissue_ground_truth[tissue_ground_truth == 255] = 3
tissue_ground_truth -= 1
tissue_ground_truth = tissue_ground_truth[0].to(torch.long)


tissue_ground_truth = one_hot(tissue_ground_truth, num_classes=3)
cell_image = image[:3]
tissue_pred_cropped = image[3:]
```

```{python}
print(cell_image.shape)
print(tissue_pred_cropped.shape)
print(label_cell.shape)
print(tissue_ground_truth.shape)
```

```{python}
converter = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])

tissue_image_input = cv2.imread(val_tissue_image_path).astype(np.float32)
tissue_image_input = cv2.cvtColor(tissue_image_input, cv2.COLOR_BGR2RGB)

tissue_image_input = torch.from_numpy(tissue_image_input).permute(2, 0, 1).to(device)
print(tissue_image_input.shape)
print(tissue_image_input.min())
print(tissue_image_input.max())
print(tissue_image_input.dtype)

outputs_tissue_model = tissue_model(tissue_image_input.unsqueeze(0)/255)
tissue_prediction = outputs_tissue_model[0].detach().cpu()
tissue_prediction = tissue_prediction.argmax(0)

tissue_prediction = converter[tissue_prediction]
print(tissue_prediction.shape)
```

```{python}
outputs = tissue_cell_model(image.unsqueeze(0).to(device))
output = outputs[0].cpu()

argmaxed_cell_prediction = output.argmax(0)
argmaxed_cell_prediction = converter[argmaxed_cell_prediction.cpu().detach()]
print(argmaxed_cell_prediction.shape)
```

```{python}
print(num)

plt.figure(figsize=(20, 20))
plt.axis("off")

plt.subplot(3, 3, 1)
plt.imshow(cell_image.permute(1, 2, 0))
plt.title("Cell image")
plt.axis("off")

plt.subplot(3, 3, 2)
plt.imshow(tissue_pred_cropped.permute(1, 2, 0))
plt.title("Tissue image prediction cropped")
plt.axis("off")

plt.subplot(3, 3, 3)
plt.imshow(255*label_cell.permute(1, 2, 0))
plt.title("Cell Label")
plt.axis("off")

plt.subplot(3, 3, 4)
plt.imshow(255*argmaxed_cell_prediction)
plt.title("Argmaxed Model Predictions")
plt.axis("off")

plt.subplot(3, 3, 5)
plt.imshow(255*tissue_ground_truth)
plt.title("Tissue label")
plt.axis("off")

plt.subplot(3, 3, 6)
plt.imshow(cv2.imread(val_tissue_image_path))
plt.title("Tissue image")
plt.axis("off")

plt.subplot(3, 3, 7)
plt.imshow(255*tissue_prediction)
plt.title("Tissue prediction")
plt.axis("off")
plt.grid(color="white", linestyle="-", linewidth=2)

plt.tight_layout()
plt.show()
```
